<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Small-Scale System for Autoregressive Program Synthesis Enabling Controlled Experimentation](https://arxiv.org/abs/2602.09112)
*Russ Webb,Jason Ramapuram*

Main category: cs.AI

TL;DR: Cadmus系统：一个低成本的小型模型训练平台，用于研究程序合成，相比大型语言模型提供更好的透明度和控制性，在特定任务上甚至超越GPT-5。


<details>
  <summary>Details</summary>
Motivation: 当前程序合成研究主要依赖大型语言模型，但存在诸多问题：难以确定数据分布边界、难以理解微调效果、难以分析分词影响、计算和存储成本高昂。需要一种更透明、可控且经济的研究平台。

Method: 开发Cadmus系统，包含整数虚拟机、多样化真实程序数据集，以及一个计算成本低于200美元的自回归Transformer模型。该系统允许研究者精细控制训练分布，并能检查和调试模型。

Result: Cadmus模型在完成正确的整数算术程序任务上达到100%准确率，而GPT-5只有95%。更重要的是，Cadmus提供了数据集与问题关系的透明度，而GPT-5在解决相同任务时引入了未知的先验知识。

Conclusion: 小型模型在复杂推理任务上能够实现大型模型难以进行的深度分析和调试，为程序合成研究提供了更透明、可控且经济的研究平台，特别适用于需要完全理解训练集与任务关系的研究场景。

Abstract: What research can be pursued with small models trained to complete true programs? Typically, researchers study program synthesis via large language models (LLMs) which introduce issues such as knowing what is in or out of distribution, understanding fine-tuning effects, understanding the effects of tokenization, and higher demand on compute and storage to carry out experiments. We present a system called Cadmus which includes an integer virtual machine (VM), a dataset composed of true programs of diverse tasks, and an autoregressive transformer model that is trained for under \$200 of compute cost. The system can be used to study program completion, out-of-distribution representations, inductive reasoning, and instruction following in a setting where researchers have effective and affordable fine-grained control of the training distribution and the ability to inspect and instrument models. Smaller models working on complex reasoning tasks enable instrumentation and investigations that may be prohibitively expensive on larger models. To demonstrate that these tasks are complex enough to be of interest, we show that these Cadmus models outperform GPT-5 (by achieving 100\% accuracy while GPT-5 has 95\% accuracy) even on a simple task of completing correct, integer arithmetic programs in our domain-specific language (DSL) while providing transparency into the dataset's relationship to the problem. We also show that GPT-5 brings unknown priors into its reasoning process when solving the same tasks, demonstrating a confounding factor that prevents the use of large-scale LLMs for some investigations where the training set relationship to the task needs to be fully understood.

</details>


### [2] [Uncertainty-Aware Multimodal Emotion Recognition through Dirichlet Parameterization](https://arxiv.org/abs/2602.09121)
*Rémi Grzeczkowicz,Eric Soriano,Ali Janati,Miyu Zhang,Gerard Comas-Quiles,Victor Carballo Araruna,Aneesh Jonelagadda*

Main category: cs.AI

TL;DR: 提出了一种轻量级、保护隐私的多模态情感识别框架，可在边缘设备部署，使用语音、文本和面部图像三种模态，引入基于Dempster-Shafer理论和Dirichlet证据的模型无关融合机制，在五个基准数据集上验证了竞争性精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 开发一个适用于边缘设备的轻量级、保护隐私的多模态情感识别框架，解决实际部署中的计算效率、隐私保护和不确定性处理问题，为医疗保健、人机交互等情感感知应用提供可行方案。

Method: 1. 采用模块化设计，支持语音（Emotion2Vec）、面部表情（ResNet-based）和文本（DistilRoBERTa）三种模态处理；2. 提出基于Dempster-Shafer理论和Dirichlet证据的模型无关融合机制，直接在模型logits上操作，无需额外训练或联合分布估计；3. 框架完全模块化，可扩展支持其他模态或任务。

Result: 在五个基准数据集（eNTERFACE05, MEAD, MELD, RAVDESS和CREMA-D）上验证，方法在保持计算效率的同时实现了竞争性精度，对模糊或缺失输入具有鲁棒性，证明了框架的实用性和有效性。

Conclusion: 提出的框架强调模块化、可扩展性和实际可行性，为医疗保健、人机交互等情感感知应用中的不确定性感知多模态系统铺平了道路，其模型无关的融合机制具有广泛适用性，不仅限于情感识别任务。

Abstract: In this work, we present a lightweight and privacy-preserving Multimodal Emotion Recognition (MER) framework designed for deployment on edge devices. To demonstrate framework's versatility, our implementation uses three modalities - speech, text and facial imagery. However, the system is fully modular, and can be extended to support other modalities or tasks. Each modality is processed through a dedicated backbone optimized for inference efficiency: Emotion2Vec for speech, a ResNet-based model for facial expressions, and DistilRoBERTa for text. To reconcile uncertainty across modalities, we introduce a model- and task-agnostic fusion mechanism grounded in Dempster-Shafer theory and Dirichlet evidence. Operating directly on model logits, this approach captures predictive uncertainty without requiring additional training or joint distribution estimation, making it broadly applicable beyond emotion recognition. Validation on five benchmark datasets (eNTERFACE05, MEAD, MELD, RAVDESS and CREMA-D) show that our method achieves competitive accuracy while remaining computationally efficient and robust to ambiguous or missing inputs. Overall, the proposed framework emphasizes modularity, scalability, and real-world feasibility, paving the way toward uncertainty-aware multimodal systems for healthcare, human-computer interaction, and other emotion-informed applications.

</details>


### [3] [PABU: Progress-Aware Belief Update for Efficient LLM Agents](https://arxiv.org/abs/2602.09138)
*Haitao Jiang,Lin Ge,Hengrui Cai,Rui Song*

Main category: cs.AI

TL;DR: PABU框架通过显式建模任务进度和选择性保留历史信息，减少LLM智能体中的冗余动作和推理成本，在多个环境中显著提升任务完成率和效率。


<details>
  <summary>Details</summary>
Motivation: 传统LLM智能体基于完整动作-观察历史进行决策，引入了大量任务无关信息，导致冗余动作和更高的推理成本。需要一种更紧凑的状态表示方法来提高效率。

Method: 提出Progress-Aware Belief Update (PABU)框架：1) 显式建模任务进度，预测相对进度变化；2) 选择性保留历史交互信息，仅基于保留的子集进行未来决策；3) 在每个时间步决定是否存储新遇到的交互。

Result: 在AgentGym基准的8个环境中，使用相同训练轨迹，PABU达到81.0%的任务完成率，比基于完整历史的SOTA模型提升23.9%。平均交互步数减少到9.5步，对应26.9%的减少。消融研究表明进度预测和选择性保留都是必要的。

Conclusion: PABU通过显式建模任务进度和选择性历史保留，为LLM智能体提供了更紧凑、高效的状态表示方法，显著提升了任务完成率和决策效率。

Abstract: Large Language Model (LLM) agents commonly condition actions on full action-observation histories, which introduce task-irrelevant information that easily leads to redundant actions and higher inference cost. We propose Progress-Aware Belief Update (PABU), a belief-state framework that compactly represents an agent's state by explicitly modeling task progress and selectively retaining past actions and observations. At each step, the agent predicts its relative progress since the previous round and decides whether the newly encountered interaction should be stored, conditioning future decisions only on the retained subset. Across eight environments in the AgentGym benchmark, and using identical training trajectories, PABU achieves an 81.0% task completion rate, outperforming previous State of the art (SoTA) models with full-history belief by 23.9%. Additionally, PABU's progress-oriented action selection improves efficiency, reducing the average number of interaction steps to 9.5, corresponding to a 26.9% reduction. Ablation studies show that both explicit progress prediction and selective retention are necessary for robust belief learning and performance gains.

</details>


### [4] [CoMMa: Contribution-Aware Medical Multi-Agents From A Game-Theoretic Perspective](https://arxiv.org/abs/2602.09159)
*Yichen Wu,Yujin Oh,Sangjoon Park,Kailong Fan,Dania Daye,Hana Farzaneh,Xiang Li,Raul Uppot,Quanzheng Li*

Main category: cs.AI

TL;DR: CoMMa是一个去中心化的多智能体框架，通过博弈论目标协调专科医生处理分区证据，使用确定性嵌入投影进行贡献感知信用分配，在肿瘤学决策支持任务中实现更高准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有大多数多智能体框架依赖基于随机叙事的推理，缺乏明确的证据归因和数学基础，在处理需要动态、异构患者数据的肿瘤学决策支持任务时存在稳定性和可解释性问题。

Method: 提出CoMMa框架：1）去中心化架构，专科医生在分区证据上操作；2）通过博弈论目标进行协调；3）使用确定性嵌入投影近似贡献感知信用分配；4）通过估计每个智能体的边际效用来实现明确的证据归因。

Result: 在多样化的肿瘤学基准测试（包括真实世界多学科肿瘤委员会数据集）上评估，CoMMa相比数据集中化和基于角色的多智能体基线方法，实现了更高的准确性和更稳定的性能。

Conclusion: CoMMa通过贡献感知信用分配和博弈论协调机制，为肿瘤学决策支持提供了可解释、数学基础扎实且性能稳定的多智能体框架，优于现有方法。

Abstract: Recent multi-agent frameworks have broadened the ability to tackle oncology decision support tasks that require reasoning over dynamic, heterogeneous patient data. We propose Contribution-Aware Medical Multi-Agents (CoMMa), a decentralized LLM-agent framework in which specialists operate on partitioned evidence and coordinate through a game-theoretic objective for robust decision-making. In contrast to most agent architectures relying on stochastic narrative-based reasoning, CoMMa utilizes deterministic embedding projections to approximate contribution-aware credit assignment. This yields explicit evidence attribution by estimating each agent's marginal utility, producing interpretable and mathematically grounded decision pathways with improved stability. Evaluated on diverse oncology benchmarks, including a real-world multidisciplinary tumor board dataset, CoMMa achieves higher accuracy and more stable performance than data-centralized and role-based multi-agents baselines.

</details>


### [5] [FlyAOC: Evaluating Agentic Ontology Curation of Drosophila Scientific Knowledge Bases](https://arxiv.org/abs/2602.09163)
*Xingjian Zhang,Sophia Moylan,Ziyang Xiong,Qiaozhu Mei,Yichen Luo,Jiaqi W. Ma*

Main category: cs.AI

TL;DR: FlyBench是一个评估AI智能体从科学文献中进行端到端本体论策展的基准测试，要求智能体基于基因符号搜索和阅读16,898篇全文论文，生成结构化注释，包括基因本体术语、表达模式和历史同义词。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试主要关注命名实体识别或关系提取等孤立子任务，无法捕捉科学知识库维护所需的端到端策展工作流程。需要评估AI智能体在实际科学文献策展中的综合能力。

Method: 开发了FlyBench基准测试，包含100个基因的7,397个专家策展注释，来自果蝇知识库FlyBase。评估了四种基线智能体架构：记忆化、固定流程、单智能体和多智能体，要求智能体从16,898篇全文论文中搜索和阅读信息。

Result: 架构选择显著影响性能，多智能体设计优于简单替代方案，但扩展骨干模型带来的收益递减。所有基线仍有很大改进空间。分析发现智能体主要使用检索来确认参数知识而非发现新信息。

Conclusion: FlyBench将推动检索增强科学推理能力的发展，这种能力在科学领域具有广泛应用前景。基准测试揭示了当前AI智能体在端到端科学文献策展方面的局限性，为未来研究提供了方向。

Abstract: Scientific knowledge bases accelerate discovery by curating findings from primary literature into structured, queryable formats for both human researchers and emerging AI systems. Maintaining these resources requires expert curators to search relevant papers, reconcile evidence across documents, and produce ontology-grounded annotations - a workflow that existing benchmarks, focused on isolated subtasks like named entity recognition or relation extraction, do not capture. We present FlyBench to evaluate AI agents on end-to-end agentic ontology curation from scientific literature. Given only a gene symbol, agents must search and read from a corpus of 16,898 full-text papers to produce structured annotations: Gene Ontology terms describing function, expression patterns, and historical synonyms linking decades of nomenclature. The benchmark includes 7,397 expert-curated annotations across 100 genes drawn from FlyBase, the Drosophila (fruit fly) knowledge base. We evaluate four baseline agent architectures: memorization, fixed pipeline, single-agent, and multi-agent. We find that architectural choices significantly impact performance, with multi-agent designs outperforming simpler alternatives, yet scaling backbone models yields diminishing returns. All baselines leave substantial room for improvement. Our analysis surfaces several findings to guide future development; for example, agents primarily use retrieval to confirm parametric knowledge rather than discover new information. We hope FlyBench will drive progress on retrieval-augmented scientific reasoning, a capability with broad applications across scientific domains.

</details>


### [6] [Measuring Dataset Diversity from a Geometric Perspective](https://arxiv.org/abs/2602.09340)
*Yang Ba,Mohammad Sadeq Abolhasani,Michelle V Mancenido,Rong Pan*

Main category: cs.AI

TL;DR: 提出基于拓扑数据分析（TDA）和持久性景观（PLs）的几何多样性度量框架PLDiv，超越传统熵和分布变异度量，捕捉数据集的几何结构特征


<details>
  <summary>Details</summary>
Motivation: 现有多样性度量（如特征空间离散度和度量空间幅度）主要捕捉分布变异或熵，但很大程度上忽略了数据集的几何结构，需要填补这一空白

Method: 基于拓扑数据分析和持久性景观框架，从数据中提取和量化几何特征，提供理论基础的多样性度量方法

Result: 通过跨多种模态的广泛实验证明，提出的PLDiv度量方法强大、可靠且可解释，直接将数据多样性与底层几何结构联系起来

Conclusion: PLDiv为数据集构建、增强和评估提供了基础工具，能够捕捉数据集的丰富几何和结构特性，超越传统的熵基多样性度量

Abstract: Diversity can be broadly defined as the presence of meaningful variation across elements, which can be viewed from multiple perspectives, including statistical variation and geometric structural richness in the dataset. Existing diversity metrics, such as feature-space dispersion and metric-space magnitude, primarily capture distributional variation or entropy, while largely neglecting the geometric structure of datasets. To address this gap, we introduce a framework based on topological data analysis (TDA) and persistence landscapes (PLs) to extract and quantify geometric features from data. This approach provides a theoretically grounded means of measuring diversity beyond entropy, capturing the rich geometric and structural properties of datasets. Through extensive experiments across diverse modalities, we demonstrate that our proposed PLs-based diversity metric (PLDiv) is powerful, reliable, and interpretable, directly linking data diversity to its underlying geometry and offering a foundational tool for dataset construction, augmentation, and evaluation.

</details>


### [7] [Auditing Multi-Agent LLM Reasoning Trees Outperforms Majority Vote and LLM-as-Judge](https://arxiv.org/abs/2602.09341)
*Wei Yang,Shixuan Li,Heng Ping,Peiyu Zhang,Paul Bogdan,Jesse Thomason*

Main category: cs.AI

TL;DR: AgentAuditor用推理树路径搜索替代多数投票，通过比较推理分支解决冲突，结合ACPO训练裁决器，在5个多智能体场景中比多数投票提升5%准确率


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统大多采用多数投票聚合智能体输出，这种方法丢弃了推理轨迹的证据结构，且在智能体存在相关偏见并收敛到相同错误推理时（共谋共识）表现脆弱

Method: 提出AgentAuditor框架，用推理树路径搜索替代投票，显式表示智能体轨迹间的共识与分歧；在关键分歧点比较推理分支，将全局裁决转化为局部验证；进一步提出反共识偏好优化（ACPO），在多数投票失败案例上训练裁决器，奖励基于证据的少数选择而非流行错误

Result: 在5个流行的多智能体设置中，AgentAuditor相比多数投票获得高达5%的绝对准确率提升，相比使用LLM-as-Judge提升高达3%

Conclusion: AgentAuditor通过显式建模推理分歧和局部验证，有效解决了多智能体系统中的共谋共识问题，显著提升了推理准确率，且框架与具体多智能体设置无关

Abstract: Multi-agent systems (MAS) can substantially extend the reasoning capacity of large language models (LLMs), yet most frameworks still aggregate agent outputs with majority voting. This heuristic discards the evidential structure of reasoning traces and is brittle under the confabulation consensus, where agents share correlated biases and converge on the same incorrect rationale. We introduce AgentAuditor, which replaces voting with a path search over a Reasoning Tree that explicitly represents agreements and divergences among agent traces. AgentAuditor resolves conflicts by comparing reasoning branches at critical divergence points, turning global adjudication into efficient, localized verification. We further propose Anti-Consensus Preference Optimization (ACPO), which trains the adjudicator on majority-failure cases and rewards evidence-based minority selections over popular errors. AgentAuditor is agnostic to MAS setting, and we find across 5 popular settings that it yields up to 5% absolute accuracy improvement over a majority vote, and up to 3% over using LLM-as-Judge.

</details>


### [8] [Image Quality in the Era of Artificial Intelligence](https://arxiv.org/abs/2602.09347)
*Jana G. Delfino,Jason L. Granstedt,Frank W. Samuelson,Robert Ochs,Krishna Juluru*

Main category: cs.AI

TL;DR: AI在放射学图像重建和增强中应用迅速，虽然能提升图像质量和效率，但也引入了新的失败模式和图像感知质量与信息内容之间的脱节风险，需要了解其局限性以确保安全有效使用。


<details>
  <summary>Details</summary>
Motivation: AI在放射学中快速部署，虽然能显著改善图像质量、加快采集速度并提高临床医生审查效率，但也带来了新的失败模式，并可能加剧图像感知质量与信息内容之间的脱节。为了确保AI技术的安全有效使用，需要理解AI图像重建和增强的局限性。

Method: 本文是一篇通讯文章，旨在通过分析讨论的方式，提高人们对AI在放射学图像重建和增强中局限性的认识，而不是提出具体的技术方法。

Result: 通过本文的分析，强调了AI在放射学图像处理中的双重性：一方面能显著改善图像质量和工作效率，另一方面也引入了新的风险，特别是图像感知质量与实际信息内容可能不一致的问题。

Conclusion: 了解AI图像重建和增强的局限性对于安全有效地使用该技术至关重要。本文的目的是提高人们对这些局限性的认识，使使用者能够在享受AI技术益处的同时，最大限度地降低风险。

Abstract: Artificial intelligence (AI) is being deployed within radiology at a rapid pace. AI has proven an excellent tool for reconstructing and enhancing images that appear sharper, smoother, and more detailed, can be acquired more quickly, and allowing clinicians to review them more rapidly. However, incorporation of AI also introduces new failure modes and can exacerbate the disconnect between perceived quality of an image and information content of that image. Understanding the limitations of AI-enabled image reconstruction and enhancement is critical for safe and effective use of the technology. Hence, the purpose of this communication is to bring awareness to limitations when AI is used to reconstruct or enhance a radiological image, with the goal of enabling users to reap benefits of the technology while minimizing risks.

</details>


### [9] [Bridging Efficiency and Transparency: Explainable CoT Compression in Multimodal Large Reasoning Models](https://arxiv.org/abs/2602.09485)
*Yizhi Wang,Linan Yue,Min-Ling Zhang*

Main category: cs.AI

TL;DR: XMCC：一种可解释的多模态思维链压缩器，通过强化学习将压缩建模为序列决策过程，在缩短推理轨迹的同时保持关键推理步骤和答案正确性，并提供压缩决策的自然语言解释。


<details>
  <summary>Details</summary>
Motivation: 长思维链在多模态推理中被广泛使用，但往往过于冗长且包含冗余推理步骤，影响推理效率。现有压缩方法面临两个主要挑战：1）可能破坏视觉-文本推理的完整性，移除关键对齐线索；2）压缩过程缺乏可解释性，难以判断哪些信息是关键的。

Method: 提出XMCC（可解释多模态思维链压缩器），将压缩建模为序列决策过程，通过强化学习进行优化。该方法能够有效缩短推理轨迹，同时保留关键推理步骤和答案正确性，并生成压缩决策的自然语言解释。

Result: 在代表性多模态推理基准上的大量实验表明，XMCC不仅减少了推理长度，还提供了可解释的解释，验证了其有效性。

Conclusion: XMCC解决了长思维链压缩中的关键挑战，在保持推理完整性的同时提高效率，并通过可解释的压缩决策增强了方法的透明度和可信度。

Abstract: Long chains of thought (Long CoTs) are widely employed in multimodal reasoning models to tackle complex tasks by capturing detailed visual information. However, these Long CoTs are often excessively lengthy and contain redundant reasoning steps, which can hinder inference efficiency. Compressing these long CoTs is a natural solution, yet existing approaches face two major challenges: (1) they may compromise the integrity of visual-textual reasoning by removing essential alignment cues, and (2) the compression process lacks explainability, making it difficult to discern which information is critical. To address these problems, we propose XMCC, an eXplainable Multimodal CoT Compressor that formulates compression as a sequential decision-making process optimized via reinforcement learning. XMCC can effectively shorten reasoning trajectories while preserving key reasoning steps and answer correctness, and simultaneously generates natural-language explanations for its compression decisions. Extensive experiments on representative multimodal reasoning benchmarks demonstrate that XMCC not only reduces reasoning length but also provides explainable explanations, validating its effectiveness.

</details>


### [10] [Computing Conditional Shapley Values Using Tabular Foundation Models](https://arxiv.org/abs/2602.09489)
*Lars Henry Berge Olsen,Dennis Christensen*

Main category: cs.AI

TL;DR: 使用TabPFN等表格基础模型高效计算Shapley值，相比传统方法在保持准确性的同时大幅降低计算时间


<details>
  <summary>Details</summary>
Motivation: Shapley值是解释性AI的核心工具，但计算成本高昂，特别是在特征相关的情况下。传统方法需要大量条件期望的近似计算，而深度学习回归方法由于需要为每个条件期望重新训练而效率低下。表格基础模型如TabPFN通过上下文学习克服了这一计算障碍。

Method: 使用TabPFN的多个变体计算Shapley值，并与最先进方法在模拟和真实数据集上进行比较。TabPFN利用上下文学习能力，无需重新训练即可近似每个条件期望。

Result: 在大多数情况下，TabPFN表现最佳；即使不是最佳，也仅略逊于最佳方法，但运行时间仅为其他方法的一小部分。

Conclusion: 表格基础模型为Shapley值计算提供了高效解决方案，未来可以通过专门针对条件Shapley值估计的改进进一步优化性能。

Abstract: Shapley values have become a cornerstone of explainable AI, but they are computationally expensive to use, especially when features are dependent. Evaluating them requires approximating a large number of conditional expectations, either via Monte Carlo integration or regression. Until recently it has not been possible to fully exploit deep learning for the regression approach, because retraining for each conditional expectation takes too long. Tabular foundation models such as TabPFN overcome this computational hurdle by leveraging in-context learning, so each conditional expectation can be approximated without any re-training. In this paper, we compute Shapley values with multiple variants of TabPFN and compare their performance with state-of-the-art methods on both simulated and real datasets. In most cases, TabPFN yields the best performance; where it does not, it is only marginally worse than the best method, at a fraction of the runtime. We discuss further improvements and how tabular foundation models can be better adapted specifically for conditional Shapley value estimation.

</details>


### [11] [FLINGO -- Instilling ASP Expressiveness into Linear Integer Constraints](https://arxiv.org/abs/2602.09620)
*Jorge Fandinno,Pedro Cabalar,Philipp Wanko,Torsten Schaub*

Main category: cs.AI

TL;DR: FLINGO语言扩展了约束答案集编程，将ASP的丰富表达特性（如默认值、非确定性赋值等）整合到数值约束中，解决了传统CASP表达性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统CASP在数值约束表达方面存在局限性，一旦切换到基于约束的表示，就会失去ASP的许多重要特性，如默认值声明、属性未定义、非确定性赋值和聚合值使用等，而这些特性在许多实际应用中非常重要。

Method: 提出了FLINGO语言和工具，将ASP的丰富表达特性整合到数值约束中，并提供了从FLINGO语法到标准CASP程序（遵循CLINGCON输入格式）的翻译方法。

Result: FLINGO成功地将ASP的表达能力扩展到了约束处理领域，通过多个示例展示了其应用，并建立了从FLINGO到常规CASP程序的语义转换基础。

Conclusion: FLINGO语言填补了CASP表达性方面的空白，使得在保持ASP丰富特性的同时进行数值约束处理成为可能，为实际应用提供了更强大的建模工具。

Abstract: Constraint Answer Set Programming (CASP) is a hybrid paradigm that enriches Answer Set Programming (ASP) with numerical constraint processing, something required in many real-world applications. The usual specification of constraints in most CASP solvers is closer to the numerical back-end expressiveness and semantics, rather than to standard specification in ASP. In the latter, numerical attributes are represented with predicates and this allows declaring default values, leaving the attribute undefined, making non-deterministic assignments with choice rules or using aggregated values. In CASP, most (if not all) of these features are lost once we switch to a constraint-based representation of those same attributes. In this paper, we present the FLINGO language (and tool) that incorporates the aforementioned expressiveness inside the numerical constraints and we illustrate its use with several examples. Based on previous work that established its semantic foundations, we also present a translation from the newly introduced FLINGO syntax to regular CASP programs following the CLINGCON input format.

</details>


### [12] [ClinAlign: Scaling Healthcare Alignment from Clinician Preference](https://arxiv.org/abs/2602.09653)
*Shiwei Lyu,Xidong Wang,Lei Liu,Hao Zhu,Chaohe Zhang,Jian Wang,Jinjie Gu,Benyou Wang,Yue Shen*

Main category: cs.AI

TL;DR: 该研究提出了一个两阶段框架，通过医生验证的偏好数据集和可扩展的临床原则，解决LLM在医疗领域输出与临床医生细粒度偏好对齐的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型展现出专家级医学知识，但其开放式输出与临床医生的细粒度偏好对齐仍然困难。现有方法通常依赖粗略目标或不可靠的自动评估，缺乏专业指南的坚实基础。

Method: 提出两阶段框架：1) 创建HealthRubrics数据集（7,034个医生验证的偏好示例），临床医生完善LLM起草的评分标准以满足严格医学标准；2) 将这些评分标准提炼为HealthPrinciples（119个广泛可重用、基于临床的原则），按临床维度组织，实现超越手动标注的可扩展监督。

Result: 使用该框架训练的30B参数模型（推理时仅激活3B参数）在HealthBench-Hard上达到33.4%，超越了包括Deepseek-R1和o3在内的更大模型，为临床对齐建立了资源高效的基线。

Conclusion: 该研究通过医生验证的数据集和可扩展的临床原则框架，有效解决了LLM医疗输出与临床医生偏好对齐的挑战，为资源高效的临床对齐提供了新方法。

Abstract: Although large language models (LLMs) demonstrate expert-level medical knowledge, aligning their open-ended outputs with fine-grained clinician preferences remains challenging. Existing methods often rely on coarse objectives or unreliable automated judges that are weakly grounded in professional guidelines. We propose a two-stage framework to address this gap. First, we introduce HealthRubrics, a dataset of 7,034 physician-verified preference examples in which clinicians refine LLM-drafted rubrics to meet rigorous medical standards. Second, we distill these rubrics into HealthPrinciples: 119 broadly reusable, clinically grounded principles organized by clinical dimensions, enabling scalable supervision beyond manual annotation. We use HealthPrinciples for (1) offline alignment by synthesizing rubrics for unlabeled queries and (2) an inference-time tool for guided self-revision. A 30B parameter model that activates only 3B parameters at inference trained with our framework achieves 33.4% on HealthBench-Hard, outperforming much larger models including Deepseek-R1 and o3, establishing a resource-efficient baseline for clinical alignment.

</details>


### [13] [GHS-TDA: A Synergistic Reasoning Framework Integrating Global Hypothesis Space with Topological Data Analysis](https://arxiv.org/abs/2602.09794)
*Jiaquan Zhang,Chaoning Zhang,Shuxu Chen,Xudong Wang,Zhenzhen Huang,Pengcheng Zheng,Shuai Yuan,Sheng Zheng,Qigan Sun,Jie Zou,Lik-Hang Lee,Yang Yang*

Main category: cs.AI

TL;DR: GHS-TDA通过构建全局假设图和拓扑数据分析来解决传统CoT方法的两个核心问题：早期错误传播和缺乏结构化分析，实现自适应收敛并提升推理准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法存在两个根本性局限：1）推理过程对早期决策高度敏感，一旦引入初始错误会传播放大且难以纠正；2）缺乏结构化分析技术来过滤冗余推理和提取关键特征，导致推理过程不稳定且可解释性有限。

Method: 提出GHS-TDA方法：首先构建语义丰富的全局假设图来聚合、对齐和协调多个候选推理路径，为局部推理失败时提供全局修正路径；然后应用基于持久同调的拓扑数据分析来捕获稳定的多尺度结构，去除冗余和不一致，提取更可靠的推理骨架。

Result: 通过联合利用推理多样性和拓扑稳定性，GHS-TDA实现了自适应收敛，产生高置信度和可解释的推理路径，在多个推理基准测试中在准确性和鲁棒性方面均优于强基线方法。

Conclusion: GHS-TDA通过全局协调和拓扑分析有效解决了传统CoT方法的局限性，显著提升了大型语言模型在复杂任务上的推理准确性和稳定性。

Abstract: Chain-of-Thought (CoT) has been shown to significantly improve the reasoning accuracy of large language models (LLMs) on complex tasks. However, due to the autoregressive, step-by-step generation paradigm, existing CoT methods suffer from two fundamental limitations. First, the reasoning process is highly sensitive to early decisions: once an initial error is introduced, it tends to propagate and amplify through subsequent steps, while the lack of a global coordination and revision mechanism makes such errors difficult to correct, ultimately leading to distorted reasoning chains. Second, current CoT approaches lack structured analysis techniques for filtering redundant reasoning and extracting key reasoning features, resulting in unstable reasoning processes and limited interpretability. To address these issues, we propose GHS-TDA. GHS-TDA first constructs a semantically enriched global hypothesis graph to aggregate, align, and coordinate multiple candidate reasoning paths, thereby providing alternative global correction routes when local reasoning fails. It then applies topological data analysis based on persistent homology to capture stable multi-scale structures, remove redundancy and inconsistencies, and extract a more reliable reasoning skeleton. By jointly leveraging reasoning diversity and topological stability, GHS-TDA achieves self-adaptive convergence, produces high-confidence and interpretable reasoning paths, and consistently outperforms strong baselines in terms of both accuracy and robustness across multiple reasoning benchmarks.

</details>


### [14] [Would a Large Language Model Pay Extra for a View? Inferring Willingness to Pay from Subjective Choices](https://arxiv.org/abs/2602.09802)
*Manon Reusens,Sofie Goethals,Toon Calders,David Martens*

Main category: cs.AI

TL;DR: 研究大型语言模型在旅行助手场景中的主观决策能力，通过选择困境实验分析模型隐含支付意愿，并与人类基准值比较，发现模型存在系统性偏差且倾向于高估人类支付意愿。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在旅行助手、购物支持等应用中部署，它们经常需要在没有客观正确答案的场景中为用户做出主观选择。研究旨在评估LLMs在这种主观决策环境中的表现，特别是它们能否准确反映人类偏好。

Method: 在旅行助手情境中向模型呈现选择困境，使用多项logit模型分析响应以推导隐含支付意愿估计。除了基线设置外，还考察了更现实条件下的模型行为，包括提供用户历史选择信息和基于角色的提示。

Result: 较大型LLMs可以推导出有意义的WTP值，但在属性层面存在系统性偏差；模型倾向于整体高估人类WTP，特别是当引入昂贵选项或商务导向角色时；基于先前对便宜选项偏好的条件设定能产生更接近人类基准的估值。

Conclusion: 研究结果既显示了使用LLMs进行主观决策支持的潜力，也揭示了其局限性，强调了在实际部署此类系统时仔细选择模型、设计提示和用户表征的重要性。

Abstract: As Large Language Models (LLMs) are increasingly deployed in applications such as travel assistance and purchasing support, they are often required to make subjective choices on behalf of users in settings where no objectively correct answer exists. We study LLM decision-making in a travel-assistant context by presenting models with choice dilemmas and analyzing their responses using multinomial logit models to derive implied willingness to pay (WTP) estimates. These WTP values are subsequently compared to human benchmark values from the economics literature. In addition to a baseline setting, we examine how model behavior changes under more realistic conditions, including the provision of information about users' past choices and persona-based prompting. Our results show that while meaningful WTP values can be derived for larger LLMs, they also display systematic deviations at the attribute level. Additionally, they tend to overestimate human WTP overall, particularly when expensive options or business-oriented personas are introduced. Conditioning models on prior preferences for cheaper options yields valuations that are closer to human benchmarks. Overall, our findings highlight both the potential and the limitations of using LLMs for subjective decision support and underscore the importance of careful model selection, prompt design, and user representation when deploying such systems in practice.

</details>


### [15] [Chain of Mindset: Reasoning with Adaptive Cognitive Modes](https://arxiv.org/abs/2602.10063)
*Tianyi Jiang,Arctanx An,Hengyi Feng,Naixin Zhai,Haodong Li,Xiaomin Yu,Jiahui Liu,Hanwen Du,Shuo Zhang,Zhi Yang,Jie Huang,Yuhua Li,Yongxin Ni,Huacan Wang,Ronghao Chen*

Main category: cs.AI

TL;DR: CoM框架通过动态协调四种不同思维模式（空间、收敛、发散、算法）来解决LLM推理中的单一思维模式问题，在多个基准测试中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理方法存在"单一思维模式"问题，即在解决同一问题的不同阶段都使用相同的固定思维模式，而人类问题解决实际上是多种思维模式的动态整合。这种单一思维假设阻碍了模型达到更高水平的智能。

Method: 提出Chain of Mindset (CoM)框架：1) 将推理分解为四种功能异构的思维模式：空间思维、收敛思维、发散思维、算法思维；2) 元智能体根据推理状态动态选择最优思维模式；3) 双向上下文门控机制过滤跨模块信息流以保持效果和效率。

Result: 在数学、代码生成、科学问答和空间推理等六个挑战性基准测试中，CoM在Qwen3-VL-32B-Instruct和Gemini-2.0-Flash上分别实现了4.96%和4.72%的总体准确率提升，达到SOTA性能，同时平衡了推理效率。

Conclusion: CoM框架通过动态协调多种思维模式，突破了LLM推理中的单一思维限制，实现了更接近人类的问题解决方式，为下一代智能系统提供了有前景的方向。

Abstract: Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single-minded assumption prevents models from reaching the next level of intelligence. To address this limitation, we propose Chain of Mindset (CoM), a training-free agentic framework that enables step-level adaptive mindset orchestration. CoM decomposes reasoning into four functionally heterogeneous mindsets: Spatial, Convergent, Divergent, and Algorithmic. A Meta-Agent dynamically selects the optimal mindset based on the evolving reasoning state, while a bidirectional Context Gate filters cross-module information flow to maintain effectiveness and efficiency. Experiments across six challenging benchmarks spanning mathematics, code generation, scientific QA, and spatial reasoning demonstrate that CoM achieves state-of-the-art performance, outperforming the strongest baseline by 4.96\% and 4.72\% in overall accuracy on Qwen3-VL-32B-Instruct and Gemini-2.0-Flash, while balancing reasoning efficiency. Our code is publicly available at \href{https://github.com/QuantaAlpha/chain-of-mindset}{https://github.com/QuantaAlpha/chain-of-mindset}.

</details>


### [16] [Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.10090)
*Zhaoyang Wang,Canwen Xu,Boyi Liu,Yite Wang,Siwei Han,Zhewei Yao,Huaxiu Yao,Yuxiong He*

Main category: cs.AI

TL;DR: 提出Agent World Model（AWM）——一个完全合成的环境生成管道，用于大规模训练多轮工具使用智能体，解决了真实环境稀缺和不可靠的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型驱动的自主智能体需要与工具和环境进行多轮交互来完成复杂任务，但智能体训练的扩展受到缺乏多样且可靠环境的限制。

Method: 提出AWM合成环境生成管道，生成1000个覆盖日常场景的代码驱动环境，每个环境平均配备35个工具，由数据库支持提供可靠的状态转换。

Result: 实验表明，仅在合成环境中训练（而非基准特定环境）能够实现强大的分布外泛化能力，在三个基准测试中表现优异。

Conclusion: AWM为大规模多轮工具使用智能体训练提供了高质量、可扩展的合成环境解决方案，解决了真实环境稀缺和不可靠的问题，促进了智能体训练的可扩展性。

Abstract: Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale to 1,000 environments covering everyday scenarios, in which agents can interact with rich toolsets (35 tools per environment on average) and obtain high-quality observations. Notably, these environments are code-driven and backed by databases, providing more reliable and consistent state transitions than environments simulated by LLMs. Moreover, they enable more efficient agent interaction compared with collecting trajectories from realistic environments. To demonstrate the effectiveness of this resource, we perform large-scale reinforcement learning for multi-turn tool-use agents. Thanks to the fully executable environments and accessible database states, we can also design reliable reward functions. Experiments on three benchmarks show that training exclusively in synthetic environments, rather than benchmark-specific ones, yields strong out-of-distribution generalization. The code is available at https://github.com/Snowflake-Labs/agent-world-model.

</details>
