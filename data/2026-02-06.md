<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 46]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Artificial Intelligence as Strange Intelligence: Against Linear Models of Intelligence](https://arxiv.org/abs/2602.04986)
*Kendra Chilson,Eric Schwitzgebel*

Main category: cs.AI

TL;DR: 论文批评AI发展的线性模型，提出"熟悉智能"和"陌生智能"概念，认为AI智能更可能是陌生智能，在不同领域表现出超人类和亚人类能力的混合，并发展非线性智能模型，认为通用智能不是单一能力而是实现广泛目标的能力。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是挑战当前AI研究中普遍存在的线性智能模型，这种模型假设智能可以沿着单一维度线性测量和比较。作者认为这种模型无法准确描述AI智能的本质，特别是当AI系统表现出与传统人类智能模式不同的能力特征时。

Method: 作者扩展了Susan Schneider对AI进展线性模型的批评，引入了两个核心概念："熟悉智能"（符合人类认知模式）和"陌生智能"（违反人类认知模式）。他们发展了一个非线性智能模型，认为通用智能不是统一的能力，而是在广泛环境中实现广泛目标的能力，这种能力不能非任意地简化为单一线性量。

Result: 论文得出结论：AI智能更可能是陌生智能，会表现出超人类能力和亚人类能力的混合，甚至在同一个领域内也会结合超人类洞察力和令人惊讶的错误。这种非线性模型意味着即使最先进的AI系统也可能在看似简单的任务上失败，但这并不证明系统缺乏杰出的通用智能。

Conclusion: 作者强调了非线性智能模型对AI评估方法的影响：如果AI是陌生智能，我们应该预期即使最强大的系统有时也会在明显简单的任务上失败。单一任务的优异表现（如IQ测试）不能保证在任务领域之外的广泛能力。这对抗性测试方法有重要启示。

Abstract: We endorse and expand upon Susan Schneider's critique of the linear model of AI progress and introduce two novel concepts: "familiar intelligence" and "strange intelligence". AI intelligence is likely to be strange intelligence, defying familiar patterns of ability and inability, combining superhuman capacities in some domains with subhuman performance in other domains, and even within domains sometimes combining superhuman insight with surprising errors that few humans would make. We develop and defend a nonlinear model of intelligence on which "general intelligence" is not a unified capacity but instead the ability to achieve a broad range of goals in a broad range of environments, in a manner that defies nonarbitrary reduction to a single linear quantity. We conclude with implications for adversarial testing approaches to evaluating AI capacities. If AI is strange intelligence, we should expect that even the most capable systems will sometimes fail in seemingly obvious tasks. On a nonlinear model of AI intelligence, such errors on their own do not demonstrate a system's lack of outstanding general intelligence. Conversely, excellent performance on one type of task, such as an IQ test, cannot warrant assumptions of broad capacities beyond that task domain.

</details>


### [2] [Evaluating Large Language Models on Solved and Unsolved Problems in Graph Theory: Implications for Computing Education](https://arxiv.org/abs/2602.05059)
*Adithya Kulkarni,Mohna Chakraborty,Jay Bagga*

Main category: cs.AI

TL;DR: LLM在已解决的图论问题上表现良好，能正确理解定义、识别结构并构建有效证明；但在开放问题上仅能提供解释和探索策略，无法产生新见解，表明其适合概念探索但缺乏创新数学洞察力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在计算机科学教育中的广泛应用，特别是在图论等高级课程中，需要评估这些工具如何可靠地支持数学严谨性思维。本研究旨在了解LLM在已解决和未解决的图论问题上的表现差异。

Method: 采用八阶段评估协议模拟真实数学探究过程，包括问题解释、探索、策略形成和证明构建。研究对比了LLM在两个图论问题上的表现：一个是已解决的关于线图优美性的问题，另一个是当前尚无解决方案的开放问题。

Result: 在已解决问题上，LLM表现优异：正确生成定义、识别相关结构、准确回忆结果（无幻觉）、构建了经图论专家确认的有效证明。在开放问题上，LLM能生成连贯解释和合理探索策略，但未能推进解决方案；模型没有捏造结果，而是承认不确定性。

Conclusion: LLM能够支持对已建立材料的探索，但在需要新颖数学洞察或关键结构推理的任务上仍然有限。对于计算教育，这强调了指导学生使用LLM进行概念探索，同时依赖独立验证和严格论证进行正式问题解决的重要性。

Abstract: Large Language Models are increasingly used by students to explore advanced material in computer science, including graph theory. As these tools become integrated into undergraduate and graduate coursework, it is important to understand how reliably they support mathematically rigorous thinking. This study examines the performance of a LLM on two related graph theoretic problems: a solved problem concerning the gracefulness of line graphs and an open problem for which no solution is currently known. We use an eight stage evaluation protocol that reflects authentic mathematical inquiry, including interpretation, exploration, strategy formation, and proof construction.
  The model performed strongly on the solved problem, producing correct definitions, identifying relevant structures, recalling appropriate results without hallucination, and constructing a valid proof confirmed by a graph theory expert. For the open problem, the model generated coherent interpretations and plausible exploratory strategies but did not advance toward a solution. It did not fabricate results and instead acknowledged uncertainty, which is consistent with the explicit prompting instructions that directed the model to avoid inventing theorems or unsupported claims.
  These findings indicate that LLMs can support exploration of established material but remain limited in tasks requiring novel mathematical insight or critical structural reasoning. For computing education, this distinction highlights the importance of guiding students to use LLMs for conceptual exploration while relying on independent verification and rigorous argumentation for formal problem solving.

</details>


### [3] [Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents](https://arxiv.org/abs/2602.05073)
*Changdae Oh,Seongheon Park,To Eun Kim,Jiatong Li,Wendi Li,Samuel Yeh,Xuefeng Du,Hamed Hassani,Paul Bogdan,Dawn Song,Sharon Li*

Main category: cs.AI

TL;DR: 本文提出首个通用的智能体不确定性量化框架，将传统单轮问答UQ扩展到交互式智能体场景，提出条件不确定性减少的新视角。


<details>
  <summary>Details</summary>
Motivation: 当前LLM不确定性量化研究主要集中于单轮问答，而现实应用中智能体在复杂任务中交互性增强，需要新的UQ框架来适应交互式智能体场景。

Method: 提出首个通用的智能体UQ形式化框架，涵盖现有UQ设置；提出条件不确定性减少的新视角，强调动作的"交互性"；构建概念框架为LLM智能体UQ设计提供指导。

Result: 揭示了先前工作隐含地将LLM UQ视为不确定性积累过程，这在开放世界交互式智能体中失效；提出了条件不确定性减少过程，能显式建模智能体轨迹中的可减少不确定性。

Conclusion: 智能体UQ对前沿LLM开发和领域特定应用具有重要实践意义，但仍存在开放性问题需要进一步研究。

Abstract: Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on single-turn question-answering. We argue that UQ research must shift to realistic settings with interactive agents, and that a new principled framework for agent UQ is needed. This paper presents the first general formulation of agent UQ that subsumes broad classes of existing UQ setups. Under this formulation, we show that prior works implicitly treat LLM UQ as an uncertainty accumulation process, a viewpoint that breaks down for interactive agents in an open world. In contrast, we propose a novel perspective, a conditional uncertainty reduction process, that explicitly models reducible uncertainty over an agent's trajectory by highlighting "interactivity" of actions. From this perspective, we outline a conceptual framework to provide actionable guidance for designing UQ in LLM agent setups. Finally, we conclude with practical implications of the agent UQ in frontier LLM development and domain-specific applications, as well as open remaining problems.

</details>


### [4] [Evaluating Robustness and Adaptability in Learning-Based Mission Planning for Active Debris Removal](https://arxiv.org/abs/2602.05091)
*Agni Bandyopadhyay,Günther Waxenegger-Wilfing*

Main category: cs.AI

TL;DR: 本文比较了三种自主碎片清除任务规划器：在固定参数下训练的PPO、域随机化PPO和蒙特卡洛树搜索，评估它们在燃料和时间约束变化下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 自主碎片清除任务规划需要在效率、适应性和严格的燃料与任务时间约束之间取得平衡，需要开发能够应对约束变化的鲁棒规划器。

Method: 比较三种规划器：1) 在固定任务参数下训练的标准Masked PPO策略；2) 在变化任务约束下训练的域随机化Masked PPO策略；3) 蒙特卡洛树搜索基线。在高保真轨道模拟环境中进行300个测试案例评估。

Result: 标准PPO在训练条件匹配时表现最佳，但在分布偏移下性能急剧下降；域随机化PPO表现出更好的适应性，仅在名义性能上有适度损失；MCTS对约束变化处理最好，但计算时间高出几个数量级。

Conclusion: 学习策略的速度与搜索方法的适应性之间存在权衡，结合训练时多样性和在线规划可能是未来弹性碎片清除任务规划器的发展方向。

Abstract: Autonomous mission planning for Active Debris Removal (ADR) must balance efficiency, adaptability, and strict feasibility constraints on fuel and mission duration. This work compares three planners for the constrained multi-debris rendezvous problem in Low Earth Orbit: a nominal Masked Proximal Policy Optimization (PPO) policy trained under fixed mission parameters, a domain-randomized Masked PPO policy trained across varying mission constraints for improved robustness, and a plain Monte Carlo Tree Search (MCTS) baseline. Evaluations are conducted in a high-fidelity orbital simulation with refueling, realistic transfer dynamics, and randomized debris fields across 300 test cases in nominal, reduced fuel, and reduced mission time scenarios. Results show that nominal PPO achieves top performance when conditions match training but degrades sharply under distributional shift, while domain-randomized PPO exhibits improved adaptability with only moderate loss in nominal performance. MCTS consistently handles constraint changes best due to online replanning but incurs orders-of-magnitude higher computation time. The findings underline a trade-off between the speed of learned policies and the adaptability of search-based methods, and suggest that combining training-time diversity with online planning could be a promising path for future resilient ADR mission planners.

</details>


### [5] [Democratic Preference Alignment via Sortition-Weighted RLHF](https://arxiv.org/abs/2602.05113)
*Suvadip Sana,Jinzhou Wu,Martin T. Wells*

Main category: cs.AI

TL;DR: DemPO框架通过算法抽签构建代表性人类偏好样本进行AI对齐训练，相比传统便利样本方法能更好地反映多元价值观。


<details>
  <summary>Details</summary>
Motivation: 当前基于偏好的AI对齐方法（如RLHF）依赖的人类评分者通常是便利样本，存在系统性的人口统计学偏差，不能代表广泛群体的价值观。

Method: 提出民主偏好优化（DemPO）框架，采用公民大会使用的算法抽签机制构建代表性样本。提供两种训练方案：硬面板（仅使用抽签选出的配额满足小型公共样本）和软面板（保留所有数据但按抽签包含概率重新加权）。

Result: 在包含人类判断、评分者人口统计数据和75条款宪法的公共偏好数据集上评估Llama模型（10亿到80亿参数）。硬面板在六种聚合方法中始终排名第一，软面板始终优于未加权基线，且随着模型容量增加效果更明显。

Conclusion: 在偏好收集阶段强制执行人口统计学代表性，而非事后修正，能产生更好地反映代表性公共价值观的模型行为。

Abstract: Whose values should AI systems learn? Preference based alignment methods like RLHF derive their training signal from human raters, yet these rater pools are typically convenience samples that systematically over represent some demographics and under represent others. We introduce Democratic Preference Optimization, or DemPO, a framework that applies algorithmic sortition, the same mechanism used to construct citizen assemblies, to preference based fine tuning. DemPO offers two training schemes. Hard Panel trains exclusively on preferences from a quota satisfying mini public sampled via sortition. Soft Panel retains all data but reweights each rater by their inclusion probability under the sortition lottery. We prove that Soft Panel weighting recovers the expected Hard Panel objective in closed form. Using a public preference dataset that pairs human judgments with rater demographics and a seventy five clause constitution independently elicited from a representative United States panel, we evaluate Llama models from one billion to eight billion parameters fine tuned under each scheme. Across six aggregation methods, the Hard Panel consistently ranks first and the Soft Panel consistently outperforms the unweighted baseline, with effect sizes growing as model capacity increases. These results demonstrate that enforcing demographic representativeness at the preference collection stage, rather than post hoc correction, yields models whose behavior better reflects values elicited from representative publics.

</details>


### [6] [CAST-CKT: Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer for Traffic Flow Prediction](https://arxiv.org/abs/2602.05133)
*Abdul Joseph Fofanah,Lian Wen,David Chen,Alpha Alimamy Kamara,Zhongyi Zhang*

Main category: cs.AI

TL;DR: CAST-CKT是一个混沌感知的时空和跨城市知识迁移框架，用于数据稀缺的跨城市交通预测，通过混沌分析量化交通可预测性机制，实现机制自适应建模和知识迁移。


<details>
  <summary>Details</summary>
Motivation: 数据稀缺的跨城市交通预测面临复杂非线性动力学和领域偏移的挑战，现有方法难以捕捉交通的固有混沌特性以实现有效的少样本学习。

Method: 提出CAST-CKT框架：1) 使用高效混沌分析器量化交通可预测性机制；2) 混沌感知注意力实现机制自适应时间建模；3) 自适应拓扑学习处理动态空间依赖；4) 基于混沌一致性的跨城市对齐进行知识迁移；5) 提供特定预测时域的不确定性量化。

Result: 在四个基准数据集上的跨城市少样本实验中，CAST-CKT在MAE和RMSE指标上显著优于现有最先进方法，同时提供可解释的机制分析。

Conclusion: CAST-CKT通过混沌感知建模有效解决了跨城市少样本交通预测问题，理论分析显示其具有改进的泛化边界，为交通预测提供了新的混沌理论视角。

Abstract: Traffic prediction in data-scarce, cross-city settings is challenging due to complex nonlinear dynamics and domain shifts. Existing methods often fail to capture traffic's inherent chaotic nature for effective few-shot learning. We propose CAST-CKT, a novel Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer framework. It employs an efficient chaotic analyser to quantify traffic predictability regimes, driving several key innovations: chaos-aware attention for regime-adaptive temporal modelling; adaptive topology learning for dynamic spatial dependencies; and chaotic consistency-based cross-city alignment for knowledge transfer. The framework also provides horizon-specific predictions with uncertainty quantification. Theoretical analysis shows improved generalisation bounds. Extensive experiments on four benchmarks in cross-city few-shot settings show CAST-CKT outperforms state-of-the-art methods by significant margins in MAE and RMSE, while offering interpretable regime analysis. Code is available at https://github.com/afofanah/CAST-CKT.

</details>


### [7] [HugRAG: Hierarchical Causal Knowledge Graph Design for RAG](https://arxiv.org/abs/2602.05143)
*Nengbo Wang,Tuo Liang,Vikash Singh,Chaoda Song,Van Yang,Yu Yin,Jing Ma,Jagdip Singh,Vipin Chaudhary*

Main category: cs.AI

TL;DR: HugRAG是一个基于因果门控的层次化图RAG框架，通过显式建模因果关系来抑制虚假相关性，实现大规模知识图上的可扩展推理。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的RAG方法过度依赖表面节点匹配，缺乏显式因果建模，导致答案不可信或虚假。先前尝试融入因果关系的方法通常局限于局部或单文档上下文，且受模块化图结构的信息隔离影响，阻碍了可扩展性和跨模块因果推理。

Method: 提出HugRAG框架，通过跨层次模块的因果门控重新思考基于图RAG的知识组织方式，显式建模因果关系以抑制虚假相关性，同时支持大规模知识图上的可扩展推理。

Result: 大量实验表明，HugRAG在多个数据集和评估指标上持续优于竞争性的基于图RAG基线方法。

Conclusion: 该工作为结构化、可扩展且基于因果基础的RAG系统建立了原则性基础。

Abstract: Retrieval augmented generation (RAG) has enhanced large language models by enabling access to external knowledge, with graph-based RAG emerging as a powerful paradigm for structured retrieval and reasoning. However, existing graph-based methods often over-rely on surface-level node matching and lack explicit causal modeling, leading to unfaithful or spurious answers. Prior attempts to incorporate causality are typically limited to local or single-document contexts and also suffer from information isolation that arises from modular graph structures, which hinders scalability and cross-module causal reasoning. To address these challenges, we propose HugRAG, a framework that rethinks knowledge organization for graph-based RAG through causal gating across hierarchical modules. HugRAG explicitly models causal relationships to suppress spurious correlations while enabling scalable reasoning over large-scale knowledge graphs. Extensive experiments demonstrate that HugRAG consistently outperforms competitive graph-based RAG baselines across multiple datasets and evaluation metrics. Our work establishes a principled foundation for structured, scalable, and causally grounded RAG systems.

</details>


### [8] [First Proof](https://arxiv.org/abs/2602.05192)
*Mohammed Abouzaid,Andrew J. Blumberg,Martin Hairer,Joe Kileel,Tamara G. Kolda,Paul D. Nelson,Daniel Spielman,Nikhil Srivastava,Rachel Ward,Shmuel Weinberger,Lauren Williams*

Main category: cs.AI

TL;DR: 作者分享了10个研究级数学问题来评估当前AI系统回答数学研究问题的能力，这些问题来自作者的研究过程，此前未公开过，答案暂时加密


<details>
  <summary>Details</summary>
Motivation: 评估当前人工智能系统在回答研究级数学问题方面的能力，了解AI在高级数学推理方面的表现

Method: 创建了一个包含10个自然产生于作者研究过程中的数学问题集，这些问题此前从未公开，答案暂时加密以进行客观评估

Result: 提供了一个专门设计的测试集，用于评估AI系统在高级数学研究问题上的表现，为后续评估提供基准

Conclusion: 通过分享这个研究级数学问题集，为评估AI系统的数学推理能力提供了一个新的测试基准，有助于推动AI在高级数学问题解决方面的发展

Abstract: To assess the ability of current AI systems to correctly answer research-level mathematics questions, we share a set of ten math questions which have arisen naturally in the research process of the authors. The questions had not been shared publicly until now; the answers are known to the authors of the questions but will remain encrypted for a short time.

</details>


### [9] [Traceable Cross-Source RAG for Chinese Tibetan Medicine Question Answering](https://arxiv.org/abs/2602.05195)
*Fengxian Chen,Zhilong Tao,Jiaxuan Li,Yunlong Li,Qingguo Zhou*

Main category: cs.AI

TL;DR: 本文针对多知识库检索增强生成中的权威性偏差问题，提出DAKS路由与预算检索以及对齐图证据融合方法，在藏医药领域显著提升跨知识库证据覆盖率和答案质量。


<details>
  <summary>Details</summary>
Motivation: 在多知识库检索增强生成场景中，不同知识库存在权威性差异，但检索过程容易受到文本密度偏差影响，导致权威性较低的百科全书条目主导检索结果，而更具权威性的经典著作或临床论文被忽视。

Method: 提出两种互补方法：1) DAKS进行知识库路由和预算检索，缓解密度驱动偏差，在适当时优先选择权威来源；2) 使用对齐图指导证据融合和覆盖感知打包，在不依赖简单拼接的情况下改善跨知识库证据覆盖。

Result: 实验显示在路由质量和跨知识库证据覆盖率方面取得一致提升，完整系统在保持强忠实性和引用正确性的同时，实现了最佳的CrossEv@5指标。

Conclusion: 通过结合知识库路由和跨知识库证据融合，能够有效解决多知识库检索增强生成中的权威性偏差问题，在藏医药领域实现了更可靠、可追溯的问答系统。

Abstract: Retrieval-augmented generation (RAG) promises grounded question answering, yet domain settings with multiple heterogeneous knowledge bases (KBs) remain challenging. In Chinese Tibetan medicine, encyclopedia entries are often dense and easy to match, which can dominate retrieval even when classics or clinical papers provide more authoritative evidence. We study a practical setting with three KBs (encyclopedia, classics, and clinical papers) and a 500-query benchmark (cutoff $K{=}5$) covering both single-KB and cross-KB questions. We propose two complementary methods to improve traceability, reduce hallucinations, and enable cross-KB verification. First, DAKS performs KB routing and budgeted retrieval to mitigate density-driven bias and to prioritize authoritative sources when appropriate. Second, we use an alignment graph to guide evidence fusion and coverage-aware packing, improving cross-KB evidence coverage without relying on naive concatenation. All answers are generated by a lightweight generator, \textsc{openPangu-Embedded-7B}. Experiments show consistent gains in routing quality and cross-KB evidence coverage, with the full system achieving the best CrossEv@5 while maintaining strong faithfulness and citation correctness.

</details>


### [10] [Surgery: Mitigating Harmful Fine-Tuning for Large Language Models via Attention Sink](https://arxiv.org/abs/2602.05228)
*Guozhi Liu,Weiwei Lin,Tiansheng Huang,Ruichao Mo,Qi Mu,Xiumin Wang,Li Shen*

Main category: cs.AI

TL;DR: 提出Surgery方法，利用注意力汇聚机制中的汇聚散度指标来防御有害微调，通过正则化抑制正汇聚散度，减少模型学习有害模式


<details>
  <summary>Details</summary>
Motivation: 有害微调会破坏大语言模型的安全对齐，带来重大安全风险。需要开发在微调阶段的防御方法来保护模型安全性

Method: 提出汇聚散度统计量来衡量注意力头，发现正负两种汇聚散度符号。基于可分离汇聚散度假设，设计Surgery方法：使用汇聚散度抑制正则化器，引导注意力头向负汇聚散度组移动，减少学习有害模式的倾向

Result: 在BeaverTails、HarmBench和SorryBench基准测试上，Surgery分别提升了5.90%、11.25%和9.55%的防御性能

Conclusion: 通过注意力汇聚机制中的汇聚散度分析，可以有效识别和防御有害微调。Surgery方法在微调阶段提供了一种有效的安全防御方案

Abstract: Harmful fine-tuning can invalidate safety alignment of large language models, exposing significant safety risks. In this paper, we utilize the attention sink mechanism to mitigate harmful fine-tuning. Specifically, we first measure a statistic named \emph{sink divergence} for each attention head and observe that \emph{different attention heads exhibit two different signs of sink divergence}. To understand its safety implications, we conduct experiments and find that the number of attention heads of positive sink divergence increases along with the increase of the model's harmfulness when undergoing harmful fine-tuning. Based on this finding, we propose a separable sink divergence hypothesis -- \emph{attention heads associating with learning harmful patterns during fine-tuning are separable by their sign of sink divergence}. Based on the hypothesis, we propose a fine-tuning-stage defense, dubbed Surgery. Surgery utilizes a regularizer for sink divergence suppression, which steers attention heads toward the negative sink divergence group, thereby reducing the model's tendency to learn and amplify harmful patterns. Extensive experiments demonstrate that Surgery improves defense performance by 5.90\%, 11.25\%, and 9.55\% on the BeaverTails, HarmBench, and SorryBench benchmarks, respectively. Source code is available on https://github.com/Lslland/Surgery.

</details>


### [11] [Automatic Cognitive Task Generation for In-Situ Evaluation of Embodied Agents](https://arxiv.org/abs/2602.05249)
*Xinyi He,Ying Yang,Chuanjian Fu,Sihan Guo,Songchun Zhu,Lifeng Fan,Zhenliang Zhang,Yujia Peng*

Main category: cs.AI

TL;DR: TEA提出了一种面向未见3D环境的动态原位任务生成方法，通过交互-演化两阶段系统自动生成任务，评估智能体在真实场景中的能力


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在严重的数据污染问题，缺乏场景特异性，无法有效评估智能体在未见环境中的真实能力。随着通用智能体即将广泛部署到多样化家庭环境中，针对每个独特未见3D环境的评估变得至关重要。

Method: 提出TEA（交互-演化任务生成系统）：1）使用结构化图表示定义任务；2）交互阶段：智能体主动与环境交互，形成任务执行与生成的循环；3）演化阶段：通过任务图建模重新组合和重用现有任务生成新任务，无需外部数据。

Result: 在10个未见场景中，TEA在两个周期内自动生成了87,876个任务，经人工验证这些任务物理合理且涵盖了日常认知能力。评估发现：SOTA模型虽然在公共基准上表现出色，但在基本感知任务上表现糟糕，严重缺乏3D交互意识，对任务类型的推理高度敏感。

Conclusion: 这些令人警醒的发现强调了在将智能体部署到真实人类环境之前进行原位评估的必要性。TEA方法为未见环境中的智能体评估提供了有效的动态任务生成框架。

Abstract: As general intelligent agents are poised for widespread deployment in diverse households, evaluation tailored to each unique unseen 3D environment has become a critical prerequisite. However, existing benchmarks suffer from severe data contamination and a lack of scene specificity, inadequate for assessing agent capabilities in unseen settings. To address this, we propose a dynamic in-situ task generation method for unseen environments inspired by human cognition. We define tasks through a structured graph representation and construct a two-stage interaction-evolution task generation system for embodied agents (TEA). In the interaction stage, the agent actively interacts with the environment, creating a loop between task execution and generation that allows for continuous task generation. In the evolution stage, task graph modeling allows us to recombine and reuse existing tasks to generate new ones without external data. Experiments across 10 unseen scenes demonstrate that TEA automatically generated 87,876 tasks in two cycles, which human verification confirmed to be physically reasonable and encompassing essential daily cognitive capabilities. Benchmarking SOTA models against humans on our in-situ tasks reveals that models, despite excelling on public benchmarks, perform surprisingly poorly on basic perception tasks, severely lack 3D interaction awareness and show high sensitivity to task types in reasoning. These sobering findings highlight the necessity of in-situ evaluation before deploying agents into real-world human environments.

</details>


### [12] [Beyond Cosine Similarity](https://arxiv.org/abs/2602.05266)
*Xinbo Ai*

Main category: cs.AI

TL;DR: 本文提出了一种新的语义相似度度量方法recos，它通过推导比经典柯西-施瓦茨不等式更紧的上界，用排序向量分量归一化点积，从而超越余弦相似度的线性限制，更好地捕捉复杂语义空间中的非线性关系。


<details>
  <summary>Details</summary>
Motivation: 余弦相似度作为向量空间中语义相似度的标准度量，基于柯西-施瓦茨不等式，只能捕捉线性关系，无法建模现实世界语义空间的复杂非线性结构。需要一种更强大的相似度度量方法来克服这一限制。

Method: 通过推导比经典柯西-施瓦茨不等式更紧的点积上界，提出了recos相似度度量方法。该方法将点积用排序向量分量进行归一化，将完美相似度的条件从严格的线性依赖放宽为序数一致性，从而捕捉更广泛的关系类型。

Result: 在11种嵌入模型（包括静态、上下文化和通用类型）上的广泛实验表明，recos始终优于传统余弦相似度，在标准语义文本相似度（STS）基准测试中与人类判断的相关性更高。

Conclusion: recos作为一种数学原理严谨且经验上优越的替代方案，为复杂嵌入空间中的语义分析提供了更高的准确性，建立了超越余弦相似度的新标准。

Abstract: Cosine similarity, the standard metric for measuring semantic similarity in vector spaces, is mathematically grounded in the Cauchy-Schwarz inequality, which inherently limits it to capturing linear relationships--a constraint that fails to model the complex, nonlinear structures of real-world semantic spaces. We advance this theoretical underpinning by deriving a tighter upper bound for the dot product than the classical Cauchy-Schwarz bound. This new bound leads directly to recos, a similarity metric that normalizes the dot product by the sorted vector components. recos relaxes the condition for perfect similarity from strict linear dependence to ordinal concordance, thereby capturing a broader class of relationships. Extensive experiments across 11 embedding models--spanning static, contextualized, and universal types--demonstrate that recos consistently outperforms traditional cosine similarity, achieving higher correlation with human judgments on standard Semantic Textual Similarity (STS) benchmarks. Our work establishes recos as a mathematically principled and empirically superior alternative, offering enhanced accuracy for semantic analysis in complex embedding spaces.

</details>


### [13] [Hallucination-Resistant Security Planning with a Large Language Model](https://arxiv.org/abs/2602.05279)
*Kim Hammar,Tansu Alpcan,Emil Lupu*

Main category: cs.AI

TL;DR: 提出一个原则性框架，将LLM集成到安全管理决策支持中，通过一致性检查和外部反馈控制幻觉风险，在事件响应场景中减少30%恢复时间。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在安全管理任务（如事件响应规划）中具有潜力，但其不可靠性和幻觉倾向是主要挑战。需要解决这些问题以安全有效地将LLM应用于安全决策支持。

Method: 提出一个原则性框架，将LLM集成到迭代循环中：LLM生成候选行动，检查其与系统约束和前瞻预测的一致性；当一致性低时，通过数字孪生等外部反馈收集信息，利用上下文学习（ICL）优化候选行动。通过调整一致性阈值控制幻觉风险。

Result: 在四个公共数据集的事件响应用例实验中，该框架相比前沿LLM减少了高达30%的恢复时间。理论分析证明该设计可以通过调整一致性阈值控制幻觉风险，并在特定假设下建立了ICL的遗憾界限。

Conclusion: 提出的框架为在安全管理中使用LLM提供了可靠的方法，通过一致性检查和外部反馈机制有效控制幻觉风险，在事件响应规划中显著提升性能，为LLM在安全关键应用中的部署提供了理论保证。

Abstract: Large language models (LLMs) are promising tools for supporting security management tasks, such as incident response planning. However, their unreliability and tendency to hallucinate remain significant challenges. In this paper, we address these challenges by introducing a principled framework for using an LLM as decision support in security management. Our framework integrates the LLM in an iterative loop where it generates candidate actions that are checked for consistency with system constraints and lookahead predictions. When consistency is low, we abstain from the generated actions and instead collect external feedback, e.g., by evaluating actions in a digital twin. This feedback is then used to refine the candidate actions through in-context learning (ICL). We prove that this design allows to control the hallucination risk by tuning the consistency threshold. Moreover, we establish a bound on the regret of ICL under certain assumptions. To evaluate our framework, we apply it to an incident response use case where the goal is to generate a response and recovery plan based on system logs. Experiments on four public datasets show that our framework reduces recovery times by up to 30% compared to frontier LLMs.

</details>


### [14] [PieArena: Frontier Language Agents Achieve MBA-Level Negotiation Performance and Reveal Novel Behavioral Differences](https://arxiv.org/abs/2602.05302)
*Chris Zhu,Sasha Cui,Will Sanok Dufallo,Runzhi Jin,Zhen Xu,Linjun Zhang,Daylian Cain*

Main category: cs.AI

TL;DR: GPT-5在PieArena谈判基准测试中达到或超越商学院学生水平，展示了AGI级谈判能力，但鲁棒性和可信度仍需改进。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在谈判任务中的能力，谈判作为核心商业任务需要战略推理、心智理论和经济价值创造能力，现有基准测试未能全面评估这些维度。

Method: 引入PieArena大规模谈判基准，基于精英商学院MBA谈判课程的真实场景构建多智能体交互环境，评估不同层级语言模型的表现，并研究联合意向性智能体脚手架的影响。

Result: 前沿模型GPT-5达到或超越经过一学期谈判培训和针对性指导的商学院学生；联合意向性脚手架对中低层模型有显著提升，但对前沿模型收益递减；模型在欺骗、计算准确性、指令遵从和感知声誉等方面存在异质性。

Conclusion: 前沿语言智能体已具备在高风险经济环境中部署的智力和心理能力，但鲁棒性和可信度方面的缺陷仍是开放挑战，需要更全面的行为评估框架。

Abstract: We present an in-depth evaluation of LLMs' ability to negotiate, a central business task that requires strategic reasoning, theory of mind, and economic value creation. To do so, we introduce PieArena, a large-scale negotiation benchmark grounded in multi-agent interactions over realistic scenarios drawn from an MBA negotiation course at an elite business school. We find systematic evidence of AGI-level performance in which a representative frontier agent (GPT-5) matches or outperforms trained business-school students, despite a semester of general negotiation instruction and targeted coaching immediately prior to the task. We further study the effects of joint-intentionality agentic scaffolding and find asymmetric gains, with large improvements for mid- and lower-tier LMs and diminishing returns for frontier LMs. Beyond deal outcomes, PieArena provides a multi-dimensional negotiation behavioral profile, revealing novel cross-model heterogeneity, masked by deal-outcome-only benchmarks, in deception, computation accuracy, instruction compliance, and perceived reputation. Overall, our results suggest that frontier language agents are already intellectually and psychologically capable of deployment in high-stakes economic settings, but deficiencies in robustness and trustworthiness remain open challenges.

</details>


### [15] [ProAct: Agentic Lookahead in Interactive Environments](https://arxiv.org/abs/2602.05327)
*Yangbin Yu,Mingyu Yang,Junyou Li,Yiming Gao,Feiyu Liu,Yijun Yang,Zichuan Lin,Jiafei Lyu,Yicheng Liu,Zhicong Lu,Deheng Ye,Jie Jiang*

Main category: cs.AI

TL;DR: ProAct框架通过两阶段训练让LLM智能体学习前瞻推理，解决长时程规划中的误差累积问题，在随机和确定性环境中显著提升规划准确性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型智能体在需要长时程规划的交互环境中表现不佳，主要原因是模拟未来状态时会产生累积误差。需要一种方法让智能体内部化准确的前瞻推理能力。

Method: 提出ProAct框架，包含两个阶段：1) 基于环境搜索轨迹的监督微调（GLAD），将复杂搜索树压缩为简洁的因果推理链；2) 蒙特卡洛批评器（MC-Critic），通过轻量级环境推演校准价值估计，增强策略梯度算法。

Result: 在随机（如2048）和确定性（如Sokoban）环境中，ProAct显著提高了规划准确性。4B参数模型训练后超越了所有开源基线，媲美最先进的闭源模型，并在未见环境中展现出强大的泛化能力。

Conclusion: ProAct框架成功解决了LLM智能体在长时程规划中的前瞻推理问题，通过两阶段训练范式实现了高效准确的前瞻能力，为交互环境中的智能体规划提供了有效解决方案。

Abstract: Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a two-stage training paradigm. First, we introduce Grounded LookAhead Distillation (GLAD), where the agent undergoes supervised fine-tuning on trajectories derived from environment-based search. By compressing complex search trees into concise, causal reasoning chains, the agent learns the logic of foresight without the computational overhead of inference-time search. Second, to further refine decision accuracy, we propose the Monte-Carlo Critic (MC-Critic), a plug-and-play auxiliary value estimator designed to enhance policy-gradient algorithms like PPO and GRPO. By leveraging lightweight environment rollouts to calibrate value estimates, MC-Critic provides a low-variance signal that facilitates stable policy optimization without relying on expensive model-based value approximation. Experiments on both stochastic (e.g., 2048) and deterministic (e.g., Sokoban) environments demonstrate that ProAct significantly improves planning accuracy. Notably, a 4B parameter model trained with ProAct outperforms all open-source baselines and rivals state-of-the-art closed-source models, while demonstrating robust generalization to unseen environments. The codes and models are available at https://github.com/GreatX3/ProAct

</details>


### [16] [RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs](https://arxiv.org/abs/2602.05367)
*Youngcheon You,Banseok Lee,Minseop Choi,Seonyoung Kim,Hyochan Chong,Changdong Kim,Youngmin Kim,Dongkyu Kim*

Main category: cs.AI

TL;DR: RaBiT提出了一种新颖的残差二值化量化框架，通过算法强制残差层次结构解决并行路径特征共适应问题，在保持硬件友好的同时显著提升2位量化性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的高效部署需要极端量化，但低比特效率与性能之间存在关键权衡。残差二值化虽然能实现硬件友好的无矩阵乘法推理，但存在病态特征共适应问题，特别是并行残差二值路径学习冗余特征，限制了模型的表达能力。

Method: RaBiT框架通过算法强制残差层次结构解决共适应问题：核心机制是从单个共享全精度权重顺序推导每个二值路径，确保每个路径纠正前一个路径的误差。该过程通过优先考虑功能保持而非单纯权重近似的鲁棒初始化来稳定。

Result: RaBiT重新定义了2位精度-效率前沿：实现了最先进的性能，甚至能与硬件密集的向量量化方法相媲美，在RTX 4090上相比全精度模型实现了4.49倍的推理加速。

Conclusion: RaBiT通过解决残差二值化中的特征共适应问题，提供了一种高效的量化框架，在保持硬件友好性的同时显著提升了极端量化下的模型性能。

Abstract: Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary ($\pm$1) layers, but is plagued by pathological feature co-adaptation. We identify a key failure mode, which we term inter-path adaptation: during quantization-aware training (QAT), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT, a novel quantization framework that resolves co-adaptation by algorithmically enforcing a residual hierarchy. Its core mechanism sequentially derives each binary path from a single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by a robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization (VQ) methods, and delivers a $4.49\times$ inference speed-up over full-precision models on an RTX 4090.

</details>


### [17] [Clinical Validation of Medical-based Large Language Model Chatbots on Ophthalmic Patient Queries with LLM-based Evaluation](https://arxiv.org/abs/2602.05381)
*Ting Fang Tan,Kabilan Elangovan,Andreas Pollreisz,Kevin Bryan Dy,Wei Yan Ng,Joy Le Yi Wong,Jin Liyuan,Chrystie Quek Wan Ning,Ashley Shuen Ying Hong,Arun James Thirunavukarasu,Shelley Yin-His Chang,Jie Yao,Dylan Hong,Wang Zhaoran,Amrita Gupta,Daniel SW Ting*

Main category: cs.AI

TL;DR: 本研究评估了4个小型医疗LLM在眼科患者咨询回答中的表现，并测试了GPT-4-Turbo评估与临床医生评分的一致性。Meerkat-7B表现最佳，MedLLaMA3-v20表现最差且有25.5%的幻觉内容。GPT-4-Turbo评估与临床医生评分高度一致，支持LLM评估在大规模基准测试中的可行性。


<details>
  <summary>Details</summary>
Motivation: 随着领域特定大语言模型在眼科患者教育、分诊和临床决策支持中的应用日益增多，需要对其安全性和准确性进行严格评估。本研究旨在评估小型医疗LLM在回答眼科患者咨询方面的表现，并探索基于LLM的评估方法相对于临床医生评分的可行性。

Method: 采用横断面研究设计，使用4个参数小于100亿的小型医疗LLM（Meerkat-7B、BioMistral-7B、OpenBioLLM-8B、MedLLaMA3-v20）回答180个眼科患者咨询问题，共生成2160个回答。由3名不同资历的眼科医生和GPT-4-Turbo使用S.C.O.R.E.框架（安全性、共识与上下文、客观性、可重复性、可解释性）进行五级李克特量表评分。使用Spearman秩相关、Kendall tau统计和核密度估计分析评估LLM与临床医生评分的一致性。

Result: Meerkat-7B表现最佳，分别获得高级顾问3.44分、顾问4.08分、住院医师4.18分的平均分。MedLLaMA3-v20表现最差，25.5%的回答包含幻觉或临床误导性内容，包括编造术语。GPT-4-Turbo评估与临床医生整体评估高度一致（Spearman rho=0.80，Kendall tau=0.67），但高级顾问评分更为保守。

Conclusion: 医疗LLM在眼科问题回答中显示出安全潜力，但在临床深度和共识方面仍存在差距。研究支持基于LLM的评估在大规模基准测试中的可行性，并建议采用自动化与临床医生审查相结合的混合框架来指导安全的临床部署。

Abstract: Domain specific large language models are increasingly used to support patient education, triage, and clinical decision making in ophthalmology, making rigorous evaluation essential to ensure safety and accuracy. This study evaluated four small medical LLMs Meerkat-7B, BioMistral-7B, OpenBioLLM-8B, and MedLLaMA3-v20 in answering ophthalmology related patient queries and assessed the feasibility of LLM based evaluation against clinician grading. In this cross sectional study, 180 ophthalmology patient queries were answered by each model, generating 2160 responses. Models were selected for parameter sizes under 10 billion to enable resource efficient deployment. Responses were evaluated by three ophthalmologists of differing seniority and by GPT-4-Turbo using the S.C.O.R.E. framework assessing safety, consensus and context, objectivity, reproducibility, and explainability, with ratings assigned on a five point Likert scale. Agreement between LLM and clinician grading was assessed using Spearman rank correlation, Kendall tau statistics, and kernel density estimate analyses. Meerkat-7B achieved the highest performance with mean scores of 3.44 from Senior Consultants, 4.08 from Consultants, and 4.18 from Residents. MedLLaMA3-v20 performed poorest, with 25.5 percent of responses containing hallucinations or clinically misleading content, including fabricated terminology. GPT-4-Turbo grading showed strong alignment with clinician assessments overall, with Spearman rho of 0.80 and Kendall tau of 0.67, though Senior Consultants graded more conservatively. Overall, medical LLMs demonstrated potential for safe ophthalmic question answering, but gaps remained in clinical depth and consensus, supporting the feasibility of LLM based evaluation for large scale benchmarking and the need for hybrid automated and clinician review frameworks to guide safe clinical deployment.

</details>


### [18] [H-AdminSim: A Multi-Agent Simulator for Realistic Hospital Administrative Workflows with FHIR Integration](https://arxiv.org/abs/2602.05407)
*Jun-Min Lee,Meong Hi Son,Edward Choi*

Main category: cs.AI

TL;DR: H-AdminSim是一个端到端的医院管理模拟框架，结合真实数据生成和多智能体模拟，用于评估LLM在医院管理自动化中的性能。


<details>
  <summary>Details</summary>
Motivation: 医院管理部门每天处理大量请求，对LLM自动化有强烈需求，但现有研究主要关注医患交互或孤立的管理子任务，未能捕捉真实管理流程的复杂性。

Method: 提出H-AdminSim框架，结合真实数据生成和多智能体模拟医院管理流程，通过FHIR集成提供统一可互操作的环境，使用详细评估标准定量评估LLM性能。

Result: H-AdminSim提供了一个标准化的测试平台，能够系统评估LLM驱动的管理自动化的可行性和性能，支持跨异构医院环境的测试。

Conclusion: 该框架填补了现有研究的空白，为评估LLM在医院管理自动化中的应用提供了全面、标准化的解决方案。

Abstract: Hospital administration departments handle a wide range of operational tasks and, in large hospitals, process over 10,000 requests per day, driving growing interest in LLM-based automation. However, prior work has focused primarily on patient--physician interactions or isolated administrative subtasks, failing to capture the complexity of real administrative workflows. To address this gap, we propose H-AdminSim, a comprehensive end-to-end simulation framework that combines realistic data generation with multi-agent-based simulation of hospital administrative workflows. These tasks are quantitatively evaluated using detailed rubrics, enabling systematic comparison of LLMs. Through FHIR integration, H-AdminSim provides a unified and interoperable environment for testing administrative workflows across heterogeneous hospital settings, serving as a standardized testbed for assessing the feasibility and performance of LLM-driven administrative automation.

</details>


### [19] [THOR: Inductive Link Prediction over Hyper-Relational Knowledge Graphs](https://arxiv.org/abs/2602.05424)
*Weijian Yu,Yuhuan Lu,Dingqi Yang*

Main category: cs.AI

TL;DR: THOR：一种用于超关系知识图谱的归纳式链接预测方法，通过关系基础图和实体基础图建模跨图谱的结构不变性，支持完全归纳推理。


<details>
  <summary>Details</summary>
Motivation: 现有超关系知识图谱链接预测方法主要关注传导式设置，只能在同一词汇表内进行预测，无法泛化到未见过的词汇表，限制了其通用性。

Method: 提出THOR方法：1）引入关系基础图和实体基础图，建模超关系知识图谱中与具体关系和实体无关的基础交互模式；2）使用两个并行图编码器学习基础图表示，后接Transformer解码器，支持高效掩码训练和完全归纳推理。

Result: 在12个不同设置的数据集上进行超关系链接预测评估，THOR显著优于基线方法：比最佳规则方法提升66.1%，比最佳半归纳方法提升55.9%，比最佳完全归纳方法提升20.4%。消融研究揭示了捕获跨超关系知识图谱可迁移结构不变性的关键设计因素。

Conclusion: THOR通过建模超关系知识图谱的基础结构和交互模式，实现了有效的完全归纳链接预测，显著提升了模型在未见词汇表上的泛化能力。

Abstract: Knowledge graphs (KGs) have become a key ingredient supporting a variety of applications. Beyond the traditional triplet representation of facts where a relation connects two entities, modern KGs observe an increasing number of hyper-relational facts, where an arbitrary number of qualifiers associated with a triplet provide auxiliary information to further describe the rich semantics of the triplet, which can effectively boost the reasoning performance in link prediction tasks. However, existing link prediction techniques over such hyper-relational KGs (HKGs) mostly focus on a transductive setting, where KG embedding models are learned from the specific vocabulary of a given KG and subsequently can only make predictions within the same vocabulary, limiting their generalizability to previously unseen vocabularies. Against this background, we propose THOR, an inducTive link prediction technique for Hyper-relational knOwledge gRaphs. Specifically, we first introduce both relation and entity foundation graphs, modeling their fundamental inter- and intra-fact interactions in HKGs, which are agnostic to any specific relations and entities. Afterward, THOR is designed to learn from the two foundation graphs with two parallel graph encoders followed by a transformer decoder, which supports efficient masked training and fully-inductive inference. We conduct a thorough evaluation of THOR in hyper-relational link prediction tasks on 12 datasets with different settings. Results show that THOR outperforms a sizable collection of baselines, yielding 66.1%, 55.9%, and 20.4% improvement over the best-performing rule-based, semi-inductive, and fully-inductive techniques, respectively. A series of ablation studies also reveals our key design factors capturing the structural invariance transferable across HKGs for inductive tasks.

</details>


### [20] [Day-Ahead Electricity Price Forecasting for Volatile Markets Using Foundation Models with Regularization Strategy](https://arxiv.org/abs/2602.05430)
*Kritchanat Ponyuenyong,Pengyu Tu,Jia Wei Tan,Wei Soon Cheong,Jamie Ng Suat Ling,Lianlian Jiang*

Main category: cs.AI

TL;DR: 该研究评估了时间序列基础模型在波动性电力市场中的日前电价预测性能，发现其相比传统统计和深度学习模型有显著提升，最高可降低37.4%的MAPE误差。


<details>
  <summary>Details</summary>
Motivation: 电力价格预测对能源市场参与者至关重要，但由于价格信号固有的波动性和非线性而具有挑战性。传统统计和深度学习模型难以有效捕捉复杂的时间依赖关系并整合异构数据。虽然时间序列基础模型在一般时间序列预测任务中表现出色，但其在波动性市场中的日前电价预测效果尚未得到充分探索。

Method: 提出了尖峰正则化策略，并评估了多种时间序列基础模型（包括Tiny Time Mixers、MOIRAI、MOMENT和TimesFM），与传统统计和深度学习模型（如ARIMA、LSTM和CNN-LSTM）进行比较。使用新加坡具有波动趋势的半小时批发市场数据，并在适用模型中纳入外生因素（如天气和日历变量）。

Result: 时间序列基础模型在所有评估设置中一致优于传统方法，在各种评估设置中MAPE最高提升了37.4%。

Conclusion: 研究结果为提高波动性电力市场的预测准确性和决策制定提供了实用指导，表明时间序列基础模型在电力价格预测方面具有显著优势。

Abstract: Electricity price forecasting (EPF) is essential for energy markets stakeholders (e.g. grid operators, energy traders, policymakers) but remains challenging due to the inherent volatility and nonlinearity of price signals. Traditional statistical and deep learning (DL) models often struggle to capture complex temporal dependencies and integrate heterogeneous data effectively. While time series foundation models (TSFMs) have shown strong performance in general time series forecasting tasks, such as traffic forecasting and weather forecasting. However, their effectiveness in day-ahead EPF, particularly in volatile markets, remains underexplored. This paper presents a spike regularization strategy and evaluates a wide range of TSFMs, including Tiny Time Mixers (TTMs), MOIRAI, MOMENT, and TimesFM, against traditional statistical and DL models such as Autoregressive Integrated Moving Average (ARIMA), Long-short Term Memory (LSTM), and Convolutional Neural Network - LSTM (CNN-LSTM) using half-hourly wholesale market data with volatile trends in Singapore. Exogenous factors (e.g. weather and calendar variables) are also incorporated into models where applicable. Results demonstrate that TSFMs consistently outperform traditional approaches, achieving up to 37.4% improvement in MAPE across various evaluation settings. The findings offer practical guidance for improving forecast accuracy and decision-making in volatile electricity markets.

</details>


### [21] [Refine and Purify: Orthogonal Basis Optimization with Null-Space Denoising for Conditional Representation Learning](https://arxiv.org/abs/2602.05464)
*Jiaquan Wang,Yan Lyu,Chen Li,Yuheng Jia*

Main category: cs.AI

TL;DR: OD-CRL提出自适应正交基优化和零空间去噪投影，解决条件表示学习中基向量敏感性和子空间干扰问题，在多个定制化任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM生成文本基向量的条件表示学习方法存在两个关键限制：对子空间基向量的敏感性，以及子空间之间的相互干扰问题。

Method: 提出OD-CRL框架，包含自适应正交基优化（AOBO）和零空间去噪投影（NSDP）。AOBO通过奇异值分解和基于曲率的截断构建正交语义基向量；NSDP通过将嵌入投影到无关子空间的零空间来抑制非目标语义干扰。

Result: 在定制化聚类、分类和检索任务上的大量实验表明，OD-CRL实现了新的最先进性能，并具有优越的泛化能力。

Conclusion: OD-CRL通过正交基优化和零空间投影有效解决了条件表示学习中的基向量敏感性和子空间干扰问题，在多个定制化任务中表现出色。

Abstract: Conditional representation learning aims to extract criterion-specific features for customized tasks. Recent studies project universal features onto the conditional feature subspace spanned by an LLM-generated text basis to obtain conditional representations. However, such methods face two key limitations: sensitivity to subspace basis and vulnerability to inter-subspace interference. To address these challenges, we propose OD-CRL, a novel framework integrating Adaptive Orthogonal Basis Optimization (AOBO) and Null-Space Denoising Projection (NSDP). Specifically, AOBO constructs orthogonal semantic bases via singular value decomposition with a curvature-based truncation. NSDP suppresses non-target semantic interference by projecting embeddings onto the null space of irrelevant subspaces. Extensive experiments conducted across customized clustering, customized classification, and customized retrieval tasks demonstrate that OD-CRL achieves a new state-of-the-art performance with superior generalization.

</details>


### [22] [ALIVE: Awakening LLM Reasoning via Adversarial Learning and Instructive Verbal Evaluation](https://arxiv.org/abs/2602.05472)
*Yiwen Duan,Jing Ye,Xinpei Zhao*

Main category: cs.AI

TL;DR: ALIVE框架通过对抗学习和指导性语言反馈，让LLM内部化推理逻辑，摆脱传统强化学习对稀缺标量奖励的依赖，实现无监督的推理能力提升。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖的标量奖励存在成本高、跨领域脆弱、无法理解解决方案底层逻辑的瓶颈，阻碍了LLM达到专家级推理水平。

Method: 提出ALIVE框架，基于"认知协同"原则，将问题提出、解决和评判统一在单一策略模型中，通过对抗学习和指导性语言反馈让模型从原始语料中内部化评估标准。

Result: 在数学推理、代码生成和一般逻辑推理基准测试中，ALIVE有效缓解了奖励信号限制，在相同数据和计算条件下实现了准确率提升、跨领域泛化能力显著改善和更高的自我纠正率。

Conclusion: ALIVE通过推理三位一体促进了能力增长的自我维持轨迹，为无需人工监督的通用推理对齐提供了可扩展的基础。

Abstract: The quest for expert-level reasoning in Large Language Models (LLMs) has been hampered by a persistent \textit{reward bottleneck}: traditional reinforcement learning (RL) relies on scalar rewards that are \textbf{costly} to scale, \textbf{brittle} across domains, and \textbf{blind} to the underlying logic of a solution. This reliance on external, impoverished signals prevents models from developing a deep, self-contained understanding of reasoning principles. We introduce \textbf{ALIVE} (\emph{Adversarial Learning with Instructive Verbal Evaluation}), a hands-free alignment framework that moves beyond scalar reward optimization toward intrinsic reasoning acquisition. Grounded in the principle of \emph{Cognitive Synergy}, ALIVE unifies problem posing, solving, and judging within a single policy model to internalize the logic of correctness. By coupling adversarial learning with instructive verbal feedback, ALIVE enables models to internalize evaluative criteria directly from raw corpora, effectively transforming external critiques into an endogenous reasoning faculty. Empirical evaluations across mathematical reasoning, code generation, and general logical inference benchmarks demonstrate that ALIVE consistently mitigates reward signal limitations. With identical data and compute, it achieves accuracy gains, markedly improved cross-domain generalization, and higher self-correction rates. These results indicate that the reasoning trinity fosters a self-sustaining trajectory of capability growth, positioning ALIVE as a scalable foundation for general-purpose reasoning alignment without human-in-the-loop supervision.

</details>


### [23] [Phi-Former: A Pairwise Hierarchical Approach for Compound-Protein Interactions Prediction](https://arxiv.org/abs/2602.05479)
*Zhe Wang,Zijing Liu,Chencheng Xu,Yuan Yao*

Main category: cs.AI

TL;DR: Phi-former是一种用于预测化合物-蛋白质相互作用的层次化表示学习方法，通过原子-原子、基序-基序和原子-基序三个层次的相互作用建模，更好地反映生物识别机制。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的化合物-蛋白质相互作用预测方法虽然在效率和准确性上优于传统能量方法，但未能充分反映化学现实。分子片段（基序或功能基团）通常是生物识别和结合的主要单元，现有模型未能很好地融入这一生物学角色。

Method: 提出Phi-former方法：1）对化合物和蛋白质进行层次化表示；2）采用成对预训练框架，系统建模原子-原子、基序-基序和原子-基序三个层次的相互作用；3）设计层内和层间学习流程，使不同相互作用层次相互促进。

Result: 实验结果表明Phi-former在CPI相关任务上取得了优越性能。案例研究显示该方法能准确识别在CPI中被激活的特定原子或基序，提供可解释的模型解释。

Conclusion: Phi-former通过层次化相互作用建模，更好地反映了生物系统的分子识别机制，其可解释性洞察可能指导理性药物设计并支持精准医疗应用。

Abstract: Drug discovery remains time-consuming, labor-intensive, and expensive, often requiring years and substantial investment per drug candidate. Predicting compound-protein interactions (CPIs) is a critical component in this process, enabling the identification of molecular interactions between drug candidates and target proteins. Recent deep learning methods have successfully modeled CPIs at the atomic level, achieving improved efficiency and accuracy over traditional energy-based approaches. However, these models do not always align with chemical realities, as molecular fragments (motifs or functional groups) typically serve as the primary units of biological recognition and binding. In this paper, we propose Phi-former, a pairwise hierarchical interaction representation learning method that addresses this gap by incorporating the biological role of motifs in CPIs. Phi-former represents compounds and proteins hierarchically and employs a pairwise pre-training framework to model interactions systematically across atom-atom, motif-motif, and atom-motif levels, reflecting how biological systems recognize molecular partners. We design intra-level and inter-level learning pipelines that make different interaction levels mutually beneficial. Experimental results demonstrate that Phi-former achieves superior performance on CPI-related tasks. A case study shows that our method accurately identifies specific atoms or motifs activated in CPIs, providing interpretable model explanations. These insights may guide rational drug design and support precision medicine applications.

</details>


### [24] [SDFP: Speculative Decoding with FIT-Pruned Models for Training-Free and Plug-and-Play LLM Acceleration](https://arxiv.org/abs/2602.05499)
*Hanyu Wei,Zunhai Su,Peng Lu,Chao Li,Spandan Tiwari,Ashish Sirasao,Yuhan Dong*

Main category: cs.AI

TL;DR: SDFP是一种无需训练、即插即用的推测解码框架，通过基于Fisher信息迹的层剪枝从现有LLM构建轻量级草稿模型，实现1.32-1.5倍的解码加速，适用于多媒体应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多媒体应用中存在自回归解码延迟高的问题，现有推测解码方法需要额外的训练、调优或维护草稿模型，部署成本高且复杂。

Method: 提出SDFP框架：基于Fisher信息迹评估层敏感性，剪除对输出扰动影响小的层，从原始LLM构建紧凑草稿模型，保持与原始模型的兼容性以便进行标准推测验证。

Result: 在基准测试中实现1.32-1.5倍解码加速，不改变目标模型的输出分布，支持低延迟多媒体应用。

Conclusion: SDFP提供了一种无需额外训练、超参数调优或单独维护草稿模型的快速部署方案，有效降低LLM解码延迟。

Abstract: Large language models (LLMs) underpin interactive multimedia applications such as captioning, retrieval, recommendation, and creative content generation, yet their autoregressive decoding incurs substantial latency. Speculative decoding reduces latency using a lightweight draft model, but deployment is often limited by the cost and complexity of acquiring, tuning, and maintaining an effective draft model. Recent approaches usually require auxiliary training or specialization, and even training-free methods incur costly search or optimization. We propose SDFP, a fully training-free and plug-and-play framework that builds the draft model via Fisher Information Trace (FIT)-based layer pruning of a given LLM. Using layer sensitivity as a proxy for output perturbation, SDFP removes low-impact layers to obtain a compact draft while preserving compatibility with the original model for standard speculative verification. SDFP needs no additional training, hyperparameter tuning, or separately maintained drafts, enabling rapid, deployment-friendly draft construction. Across benchmarks, SDFP delivers 1.32x-1.5x decoding speedup without altering the target model's output distribution, supporting low-latency multimedia applications.

</details>


### [25] [A Unified Multimodal Framework for Dataset Construction and Model-Based Diagnosis of Ameloblastoma](https://arxiv.org/abs/2602.05515)
*Ajo Babu George,Anna Mariam John,Athul Anoop,Balu Bhasuran*

Main category: cs.AI

TL;DR: 研究人员创建了一个专门针对成釉细胞瘤的多模态数据集，并开发了多模态深度学习模型，用于变体分类、复发风险评估和手术规划支持，显著提升了诊断性能。


<details>
  <summary>Details</summary>
Motivation: 目前AI在颌面病理学诊断中的应用面临两个主要问题：一是现有数据集对成釉细胞瘤的覆盖有限，二是数据格式不一致，无法直接用于模型训练。这限制了AI在成釉细胞瘤诊断和个性化治疗规划中的应用。

Method: 1. 创建专门针对成釉细胞瘤的多模态数据集，整合了放射学、组织病理学和口腔临床图像，以及病例报告的结构化数据；2. 使用自然语言处理技术从文本报告中提取临床相关特征；3. 对图像数据进行领域特定的预处理和增强；4. 开发多模态深度学习模型，能够接受临床表现、年龄、性别等临床输入，用于变体分类、复发风险评估和手术规划。

Result: 模型性能显著提升：变体分类准确率从46.2%提高到65.9%；异常组织检测的F1分数从43.0%大幅提升到90.3%。与MultiCaRe等现有资源相比，该工作提供了更强大的数据集和适应性强的多模态AI框架。

Conclusion: 这项工作通过提供专门针对成釉细胞瘤的高质量多模态数据集和可适应的多模态AI框架，显著推进了患者特异性决策支持系统的发展，为颌面病理学的AI辅助诊断和治疗规划提供了重要工具。

Abstract: Artificial intelligence (AI)-enabled diagnostics in maxillofacial pathology require structured, high-quality multimodal datasets. However, existing resources provide limited ameloblastoma coverage and lack the format consistency needed for direct model training. We present a newly curated multimodal dataset specifically focused on ameloblastoma, integrating annotated radiological, histopathological, and intraoral clinical images with structured data derived from case reports. Natural language processing techniques were employed to extract clinically relevant features from textual reports, while image data underwent domain specific preprocessing and augmentation. Using this dataset, a multimodal deep learning model was developed to classify ameloblastoma variants, assess behavioral patterns such as recurrence risk, and support surgical planning. The model is designed to accept clinical inputs such as presenting complaint, age, and gender during deployment to enhance personalized inference. Quantitative evaluation demonstrated substantial improvements; variant classification accuracy increased from 46.2 percent to 65.9 percent, and abnormal tissue detection F1-score improved from 43.0 percent to 90.3 percent. Benchmarked against resources like MultiCaRe, this work advances patient-specific decision support by providing both a robust dataset and an adaptable multimodal AI framework.

</details>


### [26] [Split Personality Training: Revealing Latent Knowledge Through Alternate Personalities](https://arxiv.org/abs/2602.05532)
*Florian Dietz,William Wale,Oscar Gilg,Robert McCarthy,Felix Michalak,Gustavo Ewbank Rodrigues Danon,Miguelito de Guzman,Dietrich Klakow*

Main category: cs.AI

TL;DR: SPT方法通过训练一个"诚实人格"来检测大语言模型中的隐藏错位行为，在Anthropic审计游戏基准测试中达到96%准确率，而传统方法接近0%


<details>
  <summary>Details</summary>
Motivation: 检测大语言模型的错位行为很困难，因为模型可能在训练中学会隐藏不当行为。传统审计方法存在不足：黑盒方法难以区分错位输出和良性输出，而机制可解释性方法无法随模型能力扩展。

Method: 提出Split Personality Training (SPT)方法，通过微调在LoRA参数中训练第二个"诚实人格"，该人格在正常操作中保持不活跃。在主模型响应后，激活LoRA适配器并插入触发字符串，使诚实人格能够审查响应同时访问主模型的潜在状态。

Result: 在Anthropic审计游戏模型有机体基准测试中，SPT达到96%的整体准确率，而Anthropic报告的方法接近0%准确率。诚实人格揭示了外部观察者无法访问的潜在知识，如受损模型训练时使用的虚构偏见。

Conclusion: SPT方法通过训练辅助的诚实人格来检测隐藏的模型错位行为，显著优于传统审计方法，能够揭示模型内部隐藏的知识和偏见。

Abstract: Detecting misalignment in large language models is challenging because models may learn to conceal misbehavior during training. Standard auditing techniques fall short: black-box methods often cannot distinguish misaligned outputs from benign ones, and mechanistic interpretability does not scale with model capabilities. We introduce Split Personality Training (SPT), which fine-tunes a second ``honest persona'' into LoRA parameters that remain inactive during normal operation. After the main model responds, we activate the LoRA adapter and insert a trigger string, enabling the honest persona to review the response while accessing the main model's latent states. We test our method on the Anthropic Auditing Game Model Organism, a benchmark where Llama-3.3-70B is trained to exploit reward hacks while concealing this behavior. SPT achieves 96% overall accuracy, whereas Anthropic reports near 0% accuracy. The honest persona reveals latent knowledge inaccessible to external observers, such as the fictional biases the compromised model was trained on.

</details>


### [27] [Emulating Aggregate Human Choice Behavior and Biases with GPT Conversational Agents](https://arxiv.org/abs/2602.05597)
*Stephen Pilli,Vivek Nallur*

Main category: cs.AI

TL;DR: LLMs能够准确预测个体层面的认知偏见，并在交互对话中模拟人类偏见行为，GPT-4和GPT-5在模拟人类行为对齐方面存在差异


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能在个体层面预测认知偏见，并在认知负荷等情境因素与偏见交互时模拟人类偏见行为的动态变化

Method: 将三个经典决策场景转化为对话设置，进行人类实验(N=1100)，参与者与聊天机器人通过简单或复杂对话进行决策；使用参与者人口统计数据和对话记录，基于GPT-4和GPT-5模拟相同交互条件

Result: 人类实验显示明显的偏见模式；LLMs能够精确再现人类偏见，GPT-4和GPT-5在模拟人类行为对齐方面存在显著差异

Conclusion: LLMs能够有效模拟人类决策中的认知偏见，这对设计和评估交互环境中适应性强、具备偏见意识的LLM系统具有重要意义

Abstract: Cognitive biases often shape human decisions. While large language models (LLMs) have been shown to reproduce well-known biases, a more critical question is whether LLMs can predict biases at the individual level and emulate the dynamics of biased human behavior when contextual factors, such as cognitive load, interact with these biases. We adapted three well-established decision scenarios into a conversational setting and conducted a human experiment (N=1100). Participants engaged with a chatbot that facilitates decision-making through simple or complex dialogues. Results revealed robust biases. To evaluate how LLMs emulate human decision-making under similar interactive conditions, we used participant demographics and dialogue transcripts to simulate these conditions with LLMs based on GPT-4 and GPT-5. The LLMs reproduced human biases with precision. We found notable differences between models in how they aligned human behavior. This has important implications for designing and evaluating adaptive, bias-aware LLM-based AI systems in interactive contexts.

</details>


### [28] [Reactive Knowledge Representation and Asynchronous Reasoning](https://arxiv.org/abs/2602.05625)
*Simon Kohaut,Benedict Flade,Julian Eggert,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.AI

TL;DR: 本文提出了一种用于动态环境中实时概率推理的新方法，通过结合概率逻辑和响应式编程，实现了基于输入信号变化频率的自适应推理，在无人机群仿真中获得了数量级的速度提升。


<details>
  <summary>Details</summary>
Motivation: 复杂概率模型中的精确推理通常计算成本过高，特别是在动态环境中需要频繁实时更新的自主智能体场景。现有方法效率低下，因为它们在任何变化时都重新评估整个模型，未能利用现实世界信息流具有不同更新频率的特性。

Method: 首先提出了Resin（响应式信号推理）概率编程语言，将概率逻辑与响应式编程相结合。然后提出了响应式电路（RCs）作为Resin的高效精确语义，RCs是基于代数电路和异步数据流的元结构，是能够根据输入信号波动性自主调整的时间动态有向无环图。

Result: 在高保真无人机群模拟中，该方法相比频率无关推理实现了几个数量级的速度提升。RCs的结构调整成功捕捉了环境动态，显著降低了延迟，促进了响应式实时推理。

Conclusion: 通过根据异步输入的变化频率估计来划分计算，大型推理任务可以分解为单独记忆化的子问题。这确保了只有受新信息影响的模型特定组件被重新评估，从而在流式上下文中大幅减少了冗余计算。

Abstract: Exact inference in complex probabilistic models often incurs prohibitive computational costs. This challenge is particularly acute for autonomous agents in dynamic environments that require frequent, real-time belief updates. Existing methods are often inefficient for ongoing reasoning, as they re-evaluate the entire model upon any change, failing to exploit that real-world information streams have heterogeneous update rates. To address this, we approach the problem from a reactive, asynchronous, probabilistic reasoning perspective. We first introduce Resin (Reactive Signal Inference), a probabilistic programming language that merges probabilistic logic with reactive programming. Furthermore, to provide efficient and exact semantics for Resin, we propose Reactive Circuits (RCs). Formulated as a meta-structure over Algebraic Circuits and asynchronous data streams, RCs are time-dynamic Directed Acyclic Graphs that autonomously adapt themselves based on the volatility of input signals. In high-fidelity drone swarm simulations, our approach achieves several orders of magnitude of speedup over frequency-agnostic inference. We demonstrate that RCs' structural adaptations successfully capture environmental dynamics, significantly reducing latency and facilitating reactive real-time reasoning. By partitioning computations based on the estimated Frequency of Change in the asynchronous inputs, large inference tasks can be decomposed into individually memoized sub-problems. This ensures that only the specific components of a model affected by new information are re-evaluated, drastically reducing redundant computation in streaming contexts.

</details>


### [29] [Generative Ontology: When Structured Knowledge Learns to Create](https://arxiv.org/abs/2602.05636)
*Benny Cheung*

Main category: cs.AI

TL;DR: 提出Generative Ontology框架，结合传统本体论的结构严谨性与大语言模型的创造力，通过可执行的Pydantic模式约束LLM生成，实现结构完整且具有创意的领域设计。


<details>
  <summary>Details</summary>
Motivation: 传统本体论擅长描述领域结构但无法生成新内容，而大语言模型能流畅生成但缺乏结构有效性，常产生幻觉性输出。需要结合两者的互补优势，实现既结构严谨又富有创意的生成。

Method: 1) 将领域知识编码为可执行的Pydantic模式，通过DSPy签名约束LLM生成；2) 采用多智能体管道，为不同本体领域分配专门角色；3) 每个智能体带有专业"焦虑"防止浅层输出；4) 使用检索增强生成基于现有范例；5) 迭代验证确保机制与组件的一致性。

Result: 通过GameGrammar系统演示，给定主题提示（如"洞穴生态系统中发光的真菌竞争"），管道能生成结构完整、可玩的桌面游戏设计，包括机制、组件、胜利条件和设置说明，既满足本体约束又保持真正创意。

Conclusion: 该框架可推广到游戏以外的领域，任何具有专业词汇、有效性约束和积累范例的领域（如音乐创作、软件架构、烹饪艺术）都适用。约束不仅不限制创造力，反而使其成为可能，正如语法使诗歌成为可能，本体论使结构化生成成为可能。

Abstract: Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a framework that synthesizes these complementary strengths: ontology provides the grammar; the LLM provides the creativity.
  Generative Ontology encodes domain knowledge as executable Pydantic schemas that constrain LLM generation via DSPy signatures. A multi-agent pipeline assigns specialized roles to different ontology domains: a Mechanics Architect designs game systems, a Theme Weaver integrates narrative, a Balance Critic identifies exploits. Each agent carrying a professional "anxiety" that prevents shallow, agreeable outputs. Retrieval-augmented generation grounds novel designs in precedents from existing exemplars, while iterative validation ensures coherence between mechanisms and components.
  We demonstrate the framework through GameGrammar, a system for generating complete tabletop game designs. Given a thematic prompt ("bioluminescent fungi competing in a cave ecosystem"), the pipeline produces structurally complete, playable game specifications with mechanisms, components, victory conditions, and setup instructions. These outputs satisfy ontological constraints while remaining genuinely creative.
  The pattern generalizes beyond games. Any domain with expert vocabulary, validity constraints, and accumulated exemplars (music composition, software architecture, culinary arts) is a candidate for Generative Ontology. We argue that constraints do not limit creativity but enable it: just as grammar makes poetry possible, ontology makes structured generation possible.

</details>


### [30] [Graph-based Agent Memory: Taxonomy, Techniques, and Applications](https://arxiv.org/abs/2602.05665)
*Chang Yang,Chuang Zhou,Yilin Xiao,Su Dong,Luyao Zhuang,Yujing Zhang,Zhu Wang,Zijin Hong,Zheng Yuan,Zhishang Xiang,Shengyuan Chen,Huachi Zhou,Qinggang Zhang,Ninghao Liu,Jinsong Su,Xinrun Wang,Yi Chang,Xiao Huang*

Main category: cs.AI

TL;DR: 这篇综述论文系统回顾了基于图的智能体记忆系统，分析了记忆的分类、生命周期关键技术、开源工具和应用场景，为构建更高效可靠的图记忆系统提供指导。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在复杂长程任务中的应用，记忆成为智能体的核心模块。图结构因其能够建模关系依赖、组织层次信息和支持高效检索的能力，成为智能体记忆的理想选择。然而，目前缺乏对基于图的智能体记忆的系统性综述，需要全面梳理这一领域的研究进展。

Method: 论文采用系统综述方法：1）提出智能体记忆的分类体系（短期/长期、知识/经验、非结构/结构）；2）按照记忆生命周期（提取、存储、检索、演化）分析关键技术；3）总结开源库和基准测试；4）探索应用场景；5）识别挑战和未来方向。

Result: 构建了基于图的智能体记忆的完整框架，包括分类体系、技术分析、工具资源和应用场景。收集整理了相关研究论文、开源数据和项目资源，为社区提供了系统性的参考指南。

Conclusion: 图结构是构建智能体记忆系统的强大范式，能够有效支持知识积累、迭代推理和自我演化。未来需要在记忆效率、可靠性、可解释性和跨领域应用等方面进一步研究，以推动更先进的智能体记忆系统发展。

Abstract: Memory emerges as the core module in the Large Language Model (LLM)-based agents for long-horizon complex tasks (e.g., multi-turn dialogue, game playing, scientific discovery), where memory can enable knowledge accumulation, iterative reasoning and self-evolution. Among diverse paradigms, graph stands out as a powerful structure for agent memory due to the intrinsic capabilities to model relational dependencies, organize hierarchical information, and support efficient retrieval. This survey presents a comprehensive review of agent memory from the graph-based perspective. First, we introduce a taxonomy of agent memory, including short-term vs. long-term memory, knowledge vs. experience memory, non-structural vs. structural memory, with an implementation view of graph-based memory. Second, according to the life cycle of agent memory, we systematically analyze the key techniques in graph-based agent memory, covering memory extraction for transforming the data into the contents, storage for organizing the data efficiently, retrieval for retrieving the relevant contents from memory to support reasoning, and evolution for updating the contents in the memory. Third, we summarize the open-sourced libraries and benchmarks that support the development and evaluation of self-evolving agent memory. We also explore diverse application scenarios. Finally, we identify critical challenges and future research directions. This survey aims to offer actionable insights to advance the development of more efficient and reliable graph-based agent memory systems. All the related resources, including research papers, open-source data, and projects, are collected for the community in https://github.com/DEEP-PolyU/Awesome-GraphMemory.

</details>


### [31] [Determining Energy Efficiency Sweet Spots in Production LLM Inference](https://arxiv.org/abs/2602.05695)
*Hiari Pizzini Cavagna,Andrea Proia,Giacomo Madella,Giovanni B. Esposito,Francesco Antici,Daniele Cesarini,Zeynep Kiziltan,Andrea Bartolini*

Main category: cs.AI

TL;DR: 该论文提出了一种基于Transformer架构计算和内存访问复杂度的分析模型，能够准确预测LLM推理的能耗效率曲线，发现能耗效率存在非线性依赖关系，并识别出最佳效率的"甜点"区域。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常通过输入和输出序列长度的简单线性函数来估计LLM的能耗，但实际观测显示能耗效率存在明显的非线性依赖关系，需要更准确的模型来理解和优化LLM推理的能耗。

Method: 提出基于Transformer架构计算和内存访问复杂度的分析模型，使用TensorRT-LLM在NVIDIA H100 GPU上评估1B到9B参数的多种LLM（包括OPT、LLaMA、Gemma、Falcon、Qwen2和Granite），测试输入输出长度从64到4096个token。

Result: 模型平均MAPE为1.79%，识别出能耗效率的"甜点"区域：短到中等输入和中等长度输出时效率最高，而长输入或非常短的输出时效率急剧下降。通过调整序列长度与这些"甜点"对齐，可以显著降低能耗。

Conclusion: 提出的分析模型能够准确表征LLM推理的能耗效率曲线，为生产系统中的截断、摘要和自适应生成策略提供指导，支持通过优化序列长度来显著降低LLM推理的能耗。

Abstract: Large Language Models (LLMs) inference is central in modern AI applications, making it critical to understand their energy footprint. Existing approaches typically estimate energy consumption through simple linear functions of input and output sequence lengths, yet our observations reveal clear Energy Efficiency regimes: peak efficiency occurs with short-to-moderate inputs and medium-length outputs, while efficiency drops sharply for long inputs or very short outputs, indicating a non-linear dependency. In this work, we propose an analytical model derived from the computational and memory-access complexity of the Transformer architecture, capable of accurately characterizing the efficiency curve as a function of input and output lengths. To assess its accuracy, we evaluate energy consumption using TensorRT-LLM on NVIDIA H100 GPUs across a diverse set of LLMs ranging from 1B to 9B parameters, including OPT, LLaMA, Gemma, Falcon, Qwen2, and Granite, tested over input and output lengths from 64 to 4096 tokens, achieving a mean MAPE of 1.79%. Our results show that aligning sequence lengths with these efficiency "Sweet Spots" can substantially reduce energy usage, supporting informed truncation, summarization, and adaptive generation strategies in production systems.

</details>


### [32] [Nonlinearity as Rank: Generative Low-Rank Adapter with Radial Basis Functions](https://arxiv.org/abs/2602.05709)
*Yihao Ouyang,Shiwei Li,Haozhao Wang,Xiandi Luo,Zhuoqi Hu,Yuetong Song,Qiyu Qin,Yichen Li,Ruixuan Li*

Main category: cs.AI

TL;DR: GenLoRA提出用非线性函数生成低秩矩阵的基向量，替代显式存储，在更少参数下实现更高有效秩，提升微调性能。


<details>
  <summary>Details</summary>
Motivation: 传统LoRA采用显式秩范式，增加模型容量需要添加更多基向量，导致参数大幅增长。研究发现这些基向量存在显著参数冗余，可以用轻量非线性函数紧凑表示。

Method: GenLoRA用非线性基向量生成替代显式基向量存储：为每个低秩矩阵维护潜在向量，使用一组轻量径向基函数(RBFs)合成基向量。每个RBF参数远少于显式基向量。

Result: 在多个数据集和架构上的实验表明，GenLoRA在更小参数预算下获得更高的有效LoRA秩，实现更优的微调性能。

Conclusion: GenLoRA通过非线性基向量生成机制，显著提高了LoRA的参数效率，为参数高效微调提供了新方向。

Abstract: Low-rank adaptation (LoRA) approximates the update of a pretrained weight matrix using the product of two low-rank matrices. However, standard LoRA follows an explicit-rank paradigm, where increasing model capacity requires adding more rows or columns (i.e., basis vectors) to the low-rank matrices, leading to substantial parameter growth. In this paper, we find that these basis vectors exhibit significant parameter redundancy and can be compactly represented by lightweight nonlinear functions. Therefore, we propose Generative Low-Rank Adapter (GenLoRA), which replaces explicit basis vector storage with nonlinear basis vector generation. Specifically, GenLoRA maintains a latent vector for each low-rank matrix and employs a set of lightweight radial basis functions (RBFs) to synthesize the basis vectors. Each RBF requires far fewer parameters than an explicit basis vector, enabling higher parameter efficiency in GenLoRA. Extensive experiments across multiple datasets and architectures show that GenLoRA attains higher effective LoRA ranks under smaller parameter budgets, resulting in superior fine-tuning performance. The code is available at https://anonymous.4open.science/r/GenLoRA-1519.

</details>


### [33] [Anchored Policy Optimization: Mitigating Exploration Collapse Via Support-Constrained Rectification](https://arxiv.org/abs/2602.05717)
*Tianyi Wang,Long Li,Hongcan Guo,Yibiao Chen,Yixia Li,Yong Wang,Yun Chen,Guanhua Chen*

Main category: cs.AI

TL;DR: APO提出了一种新的强化学习优化方法，通过从全局形状匹配转向支持覆盖，解决了RLVR中的递归空间收缩问题，在保持多样性的同时提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 论文发现强化学习可验证奖励（RLVR）中存在递归空间收缩（RSC）的系统性病理问题，即正锐化和负挤压的联合动态导致有效替代方案的采样概率消失。虽然KL正则化试图缓解此问题，但它强加了严格的形状匹配约束，导致与正确性所需的锐化产生梯度冲突。

Method: 提出锚定策略优化（APO），将范式从全局形状匹配转向支持覆盖。基于参考模型的高置信度支持定义安全流形，允许积极锐化以提高效率，同时在错误校正时选择性调用恢复力以防止崩溃。理论上推导APO作为梯度对齐机制最大化支持覆盖，实现弹性恢复以重新膨胀有效分支。

Result: 在数学基准测试中的实证评估表明，APO打破了准确性-多样性权衡，显著提高了Pass@1性能，同时恢复了标准策略梯度方法通常损失的Pass@K多样性。

Conclusion: APO通过支持覆盖而非形状匹配的新范式，有效解决了RLVR中的递归空间收缩问题，实现了在保持多样性的同时提高准确性的双重目标，为强化学习优化提供了新的理论框架和实践方法。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is increasingly viewed as a tree pruning mechanism. However, we identify a systemic pathology termed Recursive Space Contraction (RSC), an irreversible collapse driven by the combined dynamics of positive sharpening and negative squeezing, where the sampling probability of valid alternatives vanishes. While Kullback-Leibler (KL) regularization aims to mitigate this, it imposes a rigid Shape Matching constraint that forces the policy to mimic the reference model's full density, creating a gradient conflict with the sharpening required for correctness. We propose Anchored Policy Optimization (APO), shifting the paradigm from global Shape Matching to Support Coverage. By defining a Safe Manifold based on the reference model's high-confidence support, APO permits aggressive sharpening for efficiency while selectively invoking a restorative force during error correction to prevent collapse. We theoretically derive that APO serves as a gradient-aligned mechanism to maximize support coverage, enabling an Elastic Recovery that re-inflates valid branches. Empirical evaluations on mathematical benchmarks demonstrate that APO breaks the accuracy-diversity trade-off, significantly improving Pass@1 while restoring the Pass@K diversity typically lost by standard policy gradient methods.

</details>


### [34] [Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification](https://arxiv.org/abs/2602.05723)
*Taoye Yin,Haoyuan Hu,Yaxin Fan,Xinhao Chen,Xinya Wu,Kai Deng,Kezun Zhang,Feng Wang*

Main category: cs.AI

TL;DR: 提出RLFKV框架，通过细粒度知识验证和强化学习减少金融RAG系统中的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 金融RAG系统虽然使用检索文档来弥补知识缺口，但生成的响应仍存在与检索信息矛盾的幻觉问题，需要解决这种不一致性

Method: 提出RLFKV框架：1) 将金融响应分解为原子知识单元；2) 评估每个单元的正确性以计算细粒度忠实度奖励；3) 加入信息丰富度奖励防止奖励黑客（如过于简短的回复）；4) 鼓励策略模型至少保留与基础模型相同数量的知识单元

Result: 在公开的FDD任务和新提出的FDD-ANT数据集上的实验显示了一致的改进，证实了方法的有效性

Conclusion: RLFKV框架通过细粒度知识验证和强化学习，有效提高了金融RAG系统响应与检索文档的一致性，减少了幻觉问题

Abstract: In financial Retrieval-Augmented Generation (RAG) systems, models frequently rely on retrieved documents to generate accurate responses due to the time-sensitive nature of the financial domain. While retrieved documents help address knowledge gaps, model-generated responses still suffer from hallucinations that contradict the retrieved information. To mitigate this inconsistency, we propose a Reinforcement Learning framework enhanced with Fine-grained Knowledge Verification (RLFKV). Our method decomposes financial responses into atomic knowledge units and assesses the correctness of each unit to compute the fine-grained faithful reward. This reward offers more precise optimization signals, thereby improving alignment with the retrieved documents. Additionally, to prevent reward hacking (e.g., overly concise replies), we incorporate an informativeness reward that encourages the policy model to retain at least as many knowledge units as the base model. Experiments conducted on the public Financial Data Description (FDD) task and our newly proposed FDD-ANT dataset demonstrate consistent improvements, confirming the effectiveness of our approach.

</details>


### [35] [RocqSmith: Can Automatic Optimization Forge Better Proof Agents?](https://arxiv.org/abs/2602.05762)
*Andrei Kozyrev,Nikita Khramov,Denis Lochmelis,Valerio Morelli,Gleb Solovev,Anton Podkopaev*

Main category: cs.AI

TL;DR: 研究AI智能体自动优化方法在形式验证领域的适用性，以Rocq自动定理证明为代表性挑战领域，评估不同优化器对Rocq证明生成智能体的优化效果


<details>
  <summary>Details</summary>
Motivation: 探索能否将AI智能体的自动优化方法应用于形式验证等现实世界场景，特别是自动定理证明领域，研究能否自动化智能体系统的精细调优过程（如提示设计、上下文知识和控制策略）

Method: 以Rocq自动定理证明为测试领域，评估多种自动智能体优化器在优化Rocq证明生成智能体任务上的表现，比较不同优化方法的效果

Result: 多个优化器都带来了可测量的改进，但简单的少样本引导方法是最一致有效的；然而，所有研究的自动优化方法都无法达到精心设计的先进证明智能体的性能水平

Conclusion: 自动AI智能体优化方法在形式验证领域有一定适用性，但当前技术还无法完全替代人工精心设计的智能体系统，简单的少样本引导方法在自动优化中表现最为稳定

Abstract: This work studies the applicability of automatic AI agent optimization methods to real-world agents in formal verification settings, focusing on automated theorem proving in Rocq as a representative and challenging domain. We evaluate how different automatic agent optimizers perform when applied to the task of optimizing a Rocq proof-generation agent, and assess whether parts of the fine-grained tuning of agentic systems, such as prompt design, contextual knowledge, and control strategies, can be automated. Our results show that while several optimizers yield measurable improvements, simple few-shot bootstrapping is the most consistently effective; however, none of the studied methods matches the performance of a carefully engineered state-of-the-art proof agent.

</details>


### [36] [RL-VLA$^3$: Reinforcement Learning VLA Accelerating via Full Asynchronism](https://arxiv.org/abs/2602.05765)
*Zhong Guan,Haoran Sun,Yongjian Guo,Shuai Di,Xiaodong Bai,Jing Long,Tianyun Zhao,Mingxi Luo,Chen Zhou,Yucheng Guo,Qiming Yang,Wanting Xu,Wen Huang,Yunxuan Ma,Hongke Zhao,Likang Wu,Xiaotie Deng,Xi Xiao,Sheng Wen,Yicheng Gong,Junwu Xiong*

Main category: cs.AI

TL;DR: 本文提出首个完全异步的VLA模型训练框架，通过多级解耦架构实现环境交互、策略生成和模型更新的全流程异步并行，显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型的RL训练框架（如RLinf）采用同步执行方式，导致环境交互、策略生成和模型更新阶段的资源利用率低下和吞吐量受限，成为训练效率瓶颈。

Method: 设计多级解耦架构：1) 环境交互和轨迹收集的异步并行化；2) 策略生成的流式执行；3) 训练更新的解耦调度。从大模型RL的异步优化思想中系统借鉴。

Result: 在LIBERO基准测试中，相比现有同步策略吞吐量提升最高59.25%，深度优化分离策略后可达126.67%提升。8-256 GPU规模验证显示良好可扩展性。

Conclusion: 提出的完全异步训练框架有效解决了VLA模型训练效率瓶颈，通过全流程异步并行显著提升资源利用率和训练吞吐量，具有良好可扩展性。

Abstract: In recent years, Vision-Language-Action (VLA) models have emerged as a crucial pathway towards general embodied intelligence, yet their training efficiency has become a key bottleneck. Although existing reinforcement learning (RL)-based training frameworks like RLinf can enhance model generalization, they still rely on synchronous execution, leading to severe resource underutilization and throughput limitations during environment interaction, policy generation (rollout), and model update phases (actor). To overcome this challenge, this paper, for the first time, proposes and implements a fully-asynchronous policy training framework encompassing the entire pipeline from environment interaction, rollout generation, to actor policy updates. Systematically drawing inspiration from asynchronous optimization ideas in large model RL, our framework designs a multi-level decoupled architecture. This includes asynchronous parallelization of environment interaction and trajectory collection, streaming execution for policy generation, and decoupled scheduling for training updates. We validated the effectiveness of our method across diverse VLA models and environments. On the LIBERO benchmark, the framework achieves throughput improvements of up to 59.25\% compared to existing synchronous strategies. When deeply optimizing separation strategies, throughput can be increased by as much as 126.67\%. We verified the effectiveness of each asynchronous component via ablation studies. Scaling law validation across 8 to 256 GPUs demonstrates our method's excellent scalability under most conditions.

</details>


### [37] [FiMI: A Domain-Specific Language Model for Indian Finance Ecosystem](https://arxiv.org/abs/2602.05794)
*Aboli Kathar,Aman Kumar,Anusha Kamath,Araveeti Srujan,Ashish Sharma,Chandra Bhushan,Dilip Asbe,Divya Sorate,Duddu Prasanth Kumar,Evan Acharya,Harsh Sharma,Hrithik Kadam,Kanishk Singla,Keyur Doshi,Kiran Praveen,Kolisetty Krishna SK,Krishanu Adhikary,Lokesh MPT,Mayurdeep Sonowal,Nadeem Shaikh,Navya Prakash,Nimit Kothari,Nitin Kukreja,Prashant Devadiga,Rakesh Paul,Ratanjeet Pratap Chauhan,Raunak Kalani,Raviraj Joshi,Shamanth MH,Shantanu Pandey,Shubham Soni,Siddharth Dixit,Smriti Jopat,Sunil Patel,Suraj Singh,Suvradip Paul,Tulasi Pilla,Utkarsh Vaidya,Vineeth Nambiar,Vishal Kanvaty,Yatharth Dedhia*

Main category: cs.AI

TL;DR: FiMI是针对印度数字支付系统开发的金融领域专用语言模型，包含基础版和指令版两个变体，在金融推理和工具调用方面显著优于基础模型。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对印度数字支付系统的金融语言模型，解决现有通用模型在印度金融领域特定任务（如交易纠纷、授权生命周期管理）上的不足。

Method: 基于Mistral Small 24B架构，采用多阶段训练流程：1) 在680亿个金融、多语言（英语、印地语、印英混合语）和合成数据上进行持续预训练；2) 指令微调；3) 针对多轮工具驱动对话的领域特定监督微调。

Result: FiMI基础版在金融推理基准上比Mistral Small 24B基础模型提升20%；FiMI指令版在领域特定工具调用上比Mistral Small 24B指令模型提升87%，同时在通用基准上保持与相似规模模型相当的性能。

Conclusion: FiMI成功开发了专门针对印度数字支付系统的金融语言模型，在保持通用能力的同时显著提升了金融领域特定任务的性能，为印度金融科技应用提供了有效的AI解决方案。

Abstract: We present FiMI (Finance Model for India), a domain-specialized financial language model developed for Indian digital payment systems. We develop two model variants: FiMI Base and FiMI Instruct. FiMI adapts the Mistral Small 24B architecture through a multi-stage training pipeline, beginning with continuous pre-training on 68 Billion tokens of curated financial, multilingual (English, Hindi, Hinglish), and synthetic data. This is followed by instruction fine-tuning and domain-specific supervised fine-tuning focused on multi-turn, tool-driven conversations that model real-world workflows, such as transaction disputes and mandate lifecycle management. Evaluations reveal that FiMI Base achieves a 20% improvement over the Mistral Small 24B Base model on finance reasoning benchmark, while FiMI Instruct outperforms the Mistral Small 24B Instruct model by 87% on domain-specific tool-calling. Moreover, FiMI achieves these significant domain gains while maintaining comparable performance to models of similar size on general benchmarks.

</details>


### [38] [TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.05818)
*Zihao Jiang,Miao Peng,Zhenyan Shan,Wenjie Xu,Ben Liu,Gong Chen,Ziqi Gao,Min Peng*

Main category: cs.AI

TL;DR: TKG-Thinker：一种具有自主规划和自适应检索能力的智能体，通过动态多轮交互和双重训练策略在时序知识图谱上进行推理，解决了LLMs在时序知识图谱问答中的幻觉问题和静态提示限制。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在时序知识图谱问答中存在两个主要问题：1）在复杂时序约束下容易产生推理幻觉；2）静态提示限制了模型自主性和泛化能力，缺乏与时序知识图谱环境的动态交互优化。

Method: 提出TKG-Thinker智能体，通过动态多轮交互与TKGs进行深度时序推理，采用双重训练策略：首先使用思维链数据进行监督微调以培养核心规划能力，然后通过强化学习阶段利用多维奖励在复杂时序约束下优化推理策略。

Result: 在基准数据集和三个开源LLMs上的实验结果表明，TKG-Thinker实现了最先进的性能，并在复杂TKGQA设置中表现出强大的泛化能力。

Conclusion: TKG-Thinker通过自主规划和自适应检索能力，有效解决了LLMs在时序知识图谱问答中的局限性，为复杂时序推理任务提供了有效的解决方案。

Abstract: Temporal knowledge graph question answering (TKGQA) aims to answer time-sensitive questions by leveraging temporal knowledge bases. While Large Language Models (LLMs) demonstrate significant potential in TKGQA, current prompting strategies constrain their efficacy in two primary ways. First, they are prone to reasoning hallucinations under complex temporal constraints. Second, static prompting limits model autonomy and generalization, as it lack optimization through dynamic interaction with temporal knowledge graphs (TKGs) environments. To address these limitations, we propose \textbf{TKG-Thinker}, a novel agent equipped with autonomous planning and adaptive retrieval capabilities for reasoning over TKGs. Specifically, TKG-Thinker performs in-depth temporal reasoning through dynamic multi-turn interactions with TKGs via a dual-training strategy. We first apply Supervised Fine-Tuning (SFT) with chain-of thought data to instill core planning capabilities, followed by a Reinforcement Learning (RL) stage that leverages multi-dimensional rewards to refine reasoning policies under intricate temporal constraints. Experimental results on benchmark datasets with three open-source LLMs show that TKG-Thinker achieves state-of-the-art performance and exhibits strong generalization across complex TKGQA settings.

</details>


### [39] [OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention](https://arxiv.org/abs/2602.05847)
*Zhangquan Chen,Jiale Tao,Ruihuang Li,Yihao Hu,Ruitao Chen,Zhantao Yang,Xinlei Yu,Haodong Jing,Manyuan Zhang,Shuai Shao,Biao Wang,Qinglin Lu,Ruqi Huang*

Main category: cs.AI

TL;DR: OmniVideo-R1是一个增强的多模态视频理解框架，通过自监督学习和对比学习策略提升音视频理解能力，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 人类通过多种模态协同感知世界，但现有的全视频模型在音视频理解任务上仍面临重大挑战，需要提升混合模态推理能力。

Method: 提出OmniVideo-R1强化框架，采用两种关键策略：1)基于自监督学习范式的查询密集型基础；2)基于对比学习范式的模态注意力融合。

Result: 在多个基准测试上的广泛实验表明，OmniVideo-R1始终优于强基线模型，显示出其有效性和强大的泛化能力。

Conclusion: OmniVideo-R1通过"全模态线索思考"策略，显著提升了视频模型的音视频理解能力，为多模态推理提供了有效的解决方案。

Abstract: While humans perceive the world through diverse modalities that operate synergistically to support a holistic understanding of their surroundings, existing omnivideo models still face substantial challenges on audio-visual understanding tasks. In this paper, we propose OmniVideo-R1, a novel reinforced framework that improves mixed-modality reasoning. OmniVideo-R1 empowers models to "think with omnimodal cues" by two key strategies: (1) query-intensive grounding based on self-supervised learning paradigms; and (2) modality-attentive fusion built upon contrastive learning paradigms. Extensive experiments on multiple benchmarks demonstrate that OmniVideo-R1 consistently outperforms strong baselines, highlighting its effectiveness and robust generalization capabilities.

</details>


### [40] [BABE: Biology Arena BEnchmark](https://arxiv.org/abs/2602.05857)
*Junting Zhou,Jin Chen,Linfeng Hao,Denghui Cao,Zheyu Wang,Qiguang Chen,Chaoyou Fu,Jiaze Chen,Yuchen Wu,Ge Zhang,Mingxuan Wang,Wenhao Huang,Tong Yang*

Main category: cs.AI

TL;DR: BABE是一个评估生物AI系统实验推理能力的基准，基于同行评审研究论文和真实生物研究构建，挑战模型进行因果推理和跨尺度推断。


<details>
  <summary>Details</summary>
Motivation: 现有生物学基准未能评估研究者所需的关键技能：将实验结果与背景知识整合以得出有意义结论的能力。大型语言模型已从基础对话发展到高级科学推理，但缺乏评估实验推理能力的基准。

Method: 基于同行评审研究论文和真实世界生物研究构建BABE基准，确保任务反映实际科学探究的复杂性和跨学科性质。基准设计用于评估因果推理和跨尺度推断能力。

Result: BABE提供了一个稳健的框架，用于评估AI系统如何像实践科学家一样进行推理，为衡量AI对生物研究贡献潜力提供更真实的测量标准。

Conclusion: BABE填补了评估生物AI系统实验推理能力的空白，通过基于真实科学研究的基准，为评估AI在生物学中的科学推理能力提供了更真实的测量方法。

Abstract: The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogue to advanced scientific reasoning. However, existing benchmarks in biology often fail to assess a critical skill required of researchers: the ability to integrate experimental results with contextual knowledge to derive meaningful conclusions. To address this gap, we introduce BABE(Biology Arena BEnchmark), a comprehensive benchmark designed to evaluate the experimental reasoning capabilities of biological AI systems. BABE is uniquely constructed from peer-reviewed research papers and real-world biological studies, ensuring that tasks reflect the complexity and interdisciplinary nature of actual scientific inquiry. BABE challenges models to perform causal reasoning and cross-scale inference. Our benchmark provides a robust framework for assessing how well AI systems can reason like practicing scientists, offering a more authentic measure of their potential to contribute to biological research.

</details>


### [41] [Beyond Manual Planning: Seating Allocation for Large Organizations](https://arxiv.org/abs/2602.05875)
*Anton Ipsen,Michael Cashmore,Kirsty Fielding,Nicolas Marchesotti,Parisa Zehtabi,Daniele Magazzeni,Manuela Veloso*

Main category: cs.AI

TL;DR: HSAP解决大型组织层级团队在办公平面图中的最优座位分配问题，通过自动化框架替代手动规划，确保层级关系紧密的团队座位相邻。


<details>
  <summary>Details</summary>
Motivation: 大型组织层级结构复杂，需要确保具有紧密层级关系的团队（如研究小组）座位相邻，目前手动规划效率低下且不优化，需要自动化解决方案。

Method: 提出端到端框架，使用概率路线图(PRM)和快速探索随机树(RRT)计算座位间距离，结合启发式搜索和动态规划，通过整数规划解决HSAP问题。

Result: 在不同规模实例上评估PRM框架和座位分配方案，进行定量和定性分析，验证方法的有效性。

Conclusion: HSAP框架能够自动化解决大型组织层级团队的座位分配问题，提高规划效率和优化程度，替代传统手动规划方式。

Abstract: We introduce the Hierarchical Seating Allocation Problem (HSAP) which addresses the optimal assignment of hierarchically structured organizational teams to physical seating arrangements on a floor plan. This problem is driven by the necessity for large organizations with large hierarchies to ensure that teams with close hierarchical relationships are seated in proximity to one another, such as ensuring a research group occupies a contiguous area. Currently, this problem is managed manually leading to infrequent and suboptimal replanning efforts. To alleviate this manual process, we propose an end-to-end framework to solve the HSAP. A scalable approach to calculate the distance between any pair of seats using a probabilistic road map (PRM) and rapidly-exploring random trees (RRT) which is combined with heuristic search and dynamic programming approach to solve the HSAP using integer programming. We demonstrate our approach under different sized instances by evaluating the PRM framework and subsequent allocations both quantitatively and qualitatively.

</details>


### [42] [A Guide to Large Language Models in Modeling and Simulation: From Core Techniques to Critical Challenges](https://arxiv.org/abs/2602.05883)
*Philippe J. Giabbanelli*

Main category: cs.AI

TL;DR: 论文分析了在建模与仿真工作流中使用大语言模型的常见误区，提供了实用指导，强调原则性设计选择、诊断策略和实证评估。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在建模与仿真领域的广泛应用，看似简单的实践可能引入微妙问题、不必要的复杂性甚至导致劣质结果。作者旨在提供全面实用的指导，帮助建模者做出明智决策。

Method: 讨论常见的困惑来源，包括非确定性、知识增强（RAG和LoRA）、M&S数据分解和超参数设置。强调原则性设计选择、诊断策略和实证评估方法。

Result: 识别了多个关键问题：添加更多数据可能适得其反（如模型崩溃或消除现有防护机制）；未经评估的微调可能不必要；温度设为0不能确保确定性；大量M&S数据输入可能过度但简化可能丢失信息。

Conclusion: 论文提供了在建模与仿真应用中使用大语言模型的全面实用指导，帮助研究人员和实践者避免常见陷阱，做出关于何时、如何以及是否依赖LLMs的明智决策。

Abstract: Large language models (LLMs) have rapidly become familiar tools to researchers and practitioners. Concepts such as prompting, temperature, or few-shot examples are now widely recognized, and LLMs are increasingly used in Modeling & Simulation (M&S) workflows. However, practices that appear straightforward may introduce subtle issues, unnecessary complexity, or may even lead to inferior results. Adding more data can backfire (e.g., deteriorating performance through model collapse or inadvertently wiping out existing guardrails), spending time on fine-tuning a model can be unnecessary without a prior assessment of what it already knows, setting the temperature to 0 is not sufficient to make LLMs deterministic, providing a large volume of M&S data as input can be excessive (LLMs cannot attend to everything) but naive simplifications can lose information. We aim to provide comprehensive and practical guidance on how to use LLMs, with an emphasis on M&S applications. We discuss common sources of confusion, including non-determinism, knowledge augmentation (including RAG and LoRA), decomposition of M&S data, and hyper-parameter settings. We emphasize principled design choices, diagnostic strategies, and empirical evaluation, with the goal of helping modelers make informed decisions about when, how, and whether to rely on LLMs.

</details>


### [43] [Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2602.05920)
*Eva Andrés*

Main category: cs.AI

TL;DR: 比较经典与量子强化学习方法解决带容量约束的车辆路径问题，量子增强模型在距离、紧凑度和路线重叠方面表现更优，混合架构取得最佳性能


<details>
  <summary>Details</summary>
Motivation: 探索量子强化学习在复杂组合优化问题（特别是带容量约束的车辆路径问题）中的应用潜力，比较经典与量子方法的性能差异

Method: 实现经典、全量子和混合三种变体的优势演员-评论家（A2C）智能体，集成transformer架构通过自注意力和交叉注意力机制捕捉车辆、客户和仓库之间的关系，在20个客户和4辆车的多车辆场景中进行实验

Result: 三种方法都能学习有效的路径策略，但量子增强模型优于经典基线，产生更稳健的路线组织，混合架构在距离、紧凑度和路线重叠方面取得最佳整体性能，量子模型生成更结构化、连贯的路径解决方案

Conclusion: 混合量子-经典强化学习模型在解决复杂组合优化问题（如CVRP）方面具有显著潜力，量子增强能带来定量和定性上的改进

Abstract: This paper addresses the Capacitated Vehicle Routing Problem (CVRP) by comparing classical and quantum Reinforcement Learning (RL) approaches. An Advantage Actor-Critic (A2C) agent is implemented in classical, full quantum, and hybrid variants, integrating transformer architectures to capture the relationships between vehicles, clients, and the depot through self- and cross-attention mechanisms. The experiments focus on multi-vehicle scenarios with capacity constraints, considering 20 clients and 4 vehicles, and are conducted over ten independent runs. Performance is assessed using routing distance, route compactness, and route overlap. The results show that all three approaches are capable of learning effective routing policies. However, quantum-enhanced models outperform the classical baseline and produce more robust route organization, with the hybrid architecture achieving the best overall performance across distance, compactness, and route overlap. In addition to quantitative improvements, qualitative visualizations reveal that quantum-based models generate more structured and coherent routing solutions. These findings highlight the potential of hybrid quantum-classical reinforcement learning models for addressing complex combinatorial optimization problems such as the CVRP.

</details>


### [44] [Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods](https://arxiv.org/abs/2602.06000)
*Ali Shendabadi,Parnia Izadirad,Mostafa Salehi,Mahmoud Bijankhan*

Main category: cs.AI

TL;DR: 本文探索了使用预训练ASR模型Whisper进行语音情感识别，提出了两种注意力池化方法来降低Whisper表征维度并保留情感特征，在英语和波斯语数据集上取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别研究因缺乏标准化和大规模数据集而受限，现有研究使用预训练模型提取特征。本文旨在探索Whisper预训练ASR系统在语音情感识别中的能力。

Method: 提出了两种注意力池化方法：多头注意力平均池化和QKV池化，用于高效降低Whisper表征维度同时保留情感特征。在英语IEMOCAP和波斯语ShEMO数据集上使用Whisper Tiny和Small模型进行实验，比较不同编码器层的性能。

Result: 多头QKV架构在ShEMO数据集上取得了SOTA结果，未加权准确率提升了2.47%。发现中间层在波斯语数据集上表现更好，为SER提供了轻量高效的替代方案，相比HuBERT X-Large等大型模型。

Conclusion: Whisper作为表征提取器在语音情感识别中具有潜力，注意力池化方法在维度降低方面有效，中间层在特定语言数据集上表现更优，提供了轻量高效的SER解决方案。

Abstract: Speech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre-trained models to extract features for downstream tasks such as SER. This work explores the capabilities of Whisper, a pre-trained ASR system, in speech emotion recognition by proposing two attention-based pooling methods, Multi-head Attentive Average Pooling and QKV Pooling, designed to efficiently reduce the dimensionality of Whisper representations while preserving emotional features. We experiment on English and Persian, using the IEMOCAP and ShEMO datasets respectively, with Whisper Tiny and Small. Our multi-head QKV architecture achieves state-of-the-art results on the ShEMO dataset, with a 2.47% improvement in unweighted accuracy. We further compare the performance of different Whisper encoder layers and find that intermediate layers often perform better for SER on the Persian dataset, providing a lightweight and efficient alternative to much larger models such as HuBERT X-Large. Our findings highlight the potential of Whisper as a representation extractor for SER and demonstrate the effectiveness of attention-based pooling for dimension reduction.

</details>


### [45] [AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions](https://arxiv.org/abs/2602.06008)
*Xianyang Liu,Shangding Gu,Dawn Song*

Main category: cs.AI

TL;DR: AgenticPay是一个用于多智能体买卖谈判的基准测试和仿真框架，通过自然语言驱动，包含110多个任务，评估LLM在商业谈判中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试缺乏评估多智能体语言经济互动的原则性设置，而LLM智能体在自主谈判、协调和交易方面的应用日益增多。

Method: 构建AgenticPay框架，模拟买卖双方具有私有约束和产品相关估值的市场环境，支持多轮语言谈判而非单纯数字竞价，包含110多个任务，涵盖双边谈判到多对多市场。

Result: 对最先进的专有和开源LLM进行基准测试，发现谈判性能存在显著差距，突显了长时程战略推理的挑战。

Conclusion: AgenticPay为研究智能体商业和基于语言的市场互动奠定了基础，代码和数据集已开源。

Abstract: Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many-to-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning, establishing AgenticPay as a foundation for studying agentic commerce and language-based market interaction. Code and dataset are available at the link: https://github.com/SafeRL-Lab/AgenticPay.

</details>


### [46] [Learning Event-Based Shooter Models from Virtual Reality Experiments](https://arxiv.org/abs/2602.06023)
*Christopher A. McClurg,Alan R. Wagner*

Main category: cs.AI

TL;DR: 开发数据驱动的离散事件模拟器，用于评估学校安全干预策略，特别是机器人干预枪手策略，解决VR研究中招募参与者的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实虽然能有效评估高风险学校安全场景，但每次条件变化都需要招募新参与者，限制了大规模或迭代评估，尤其在学习有效干预策略时需要大量训练时更为困难。

Method: 开发数据驱动的离散事件模拟器，将枪手移动和区域内行动建模为从VR研究中参与者行为学习到的随机过程，用于评估机器人干预策略。

Result: 模拟器能够复现关键经验模式，实现可扩展的干预策略评估和学习，这些策略难以直接通过人类受试者进行训练。

Conclusion: 这项工作展示了一个高到中保真度的模拟工作流程，为开发和评估自主学校安全干预提供了可扩展的替代方案。

Abstract: Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.

</details>
