{"id": "2602.16012", "categories": ["cs.AI", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.16012", "abs": "https://arxiv.org/abs/2602.16012", "authors": ["Jieyi Bi", "Zhiguang Cao", "Jianan Zhou", "Wen Song", "Yaoxin Wu", "Jie Zhang", "Yining Ma", "Cathy Wu"], "title": "Towards Efficient Constraint Handling in Neural Solvers for Routing Problems", "comment": "Accepted by ICLR 2026", "summary": "Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficient constraint-handling framework for neural routing solvers based on explicit learning-based feasibility refinement. Unlike prior construction-search hybrids that target reducing optimality gaps through heavy improvements yet still struggle with hard constraints, CaR achieves efficient constraint handling by designing a joint training framework that guides the construction module to generate diverse and high-quality solutions well-suited for a lightweight improvement process, e.g., 10 steps versus 5k steps in prior work. Moreover, CaR presents the first use of construction-improvement-shared representation, enabling potential knowledge sharing across paradigms by unifying the encoder, especially in more complex constrained scenarios. We evaluate CaR on typical hard routing constraints to showcase its broader applicability. Results demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both classical and neural state-of-the-art solvers.", "AI": {"tldr": "CaR\u662f\u4e00\u4e2a\u57fa\u4e8e\u663e\u5f0f\u5b66\u4e60\u53ef\u884c\u6027\u7cbe\u70bc\u7684\u795e\u7ecf\u8def\u7531\u6c42\u89e3\u5668\u901a\u7528\u7ea6\u675f\u5904\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u6307\u5bfc\u6784\u9020\u6a21\u5757\u751f\u6210\u9002\u5408\u8f7b\u91cf\u7ea7\u6539\u8fdb\u7684\u591a\u6837\u5316\u9ad8\u8d28\u91cf\u89e3\uff0c\u5728\u590d\u6742\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4f18\u8d8a\u7684\u53ef\u884c\u6027\u3001\u89e3\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u6c42\u89e3\u5668\u5728\u7b80\u5355\u8def\u7531\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u590d\u6742\u7ea6\u675f\u4e0b\u7684\u4f18\u52bf\u5c1a\u4e0d\u6210\u719f\u3002\u73b0\u6709\u7684\u53ef\u884c\u6027\u63a9\u7801\u6216\u9690\u5f0f\u53ef\u884c\u6027\u611f\u77e5\u7b49\u7ea6\u675f\u5904\u7406\u65b9\u6848\u5bf9\u4e8e\u786c\u7ea6\u675f\u53ef\u80fd\u6548\u7387\u4f4e\u4e0b\u6216\u4e0d\u9002\u7528\u3002", "method": "\u63d0\u51faConstruct-and-Refine (CaR)\u6846\u67b6\uff0c\u57fa\u4e8e\u663e\u5f0f\u5b66\u4e60\u53ef\u884c\u6027\u7cbe\u70bc\u3002\u8bbe\u8ba1\u8054\u5408\u8bad\u7ec3\u6846\u67b6\u6307\u5bfc\u6784\u9020\u6a21\u5757\u751f\u6210\u9002\u5408\u8f7b\u91cf\u7ea7\u6539\u8fdb\u8fc7\u7a0b\uff08\u598210\u6b65vs\u4e4b\u524d\u5de5\u4f5c\u76845k\u6b65\uff09\u7684\u591a\u6837\u5316\u9ad8\u8d28\u91cf\u89e3\u3002\u9996\u6b21\u91c7\u7528\u6784\u9020-\u6539\u8fdb\u5171\u4eab\u8868\u793a\uff0c\u901a\u8fc7\u7edf\u4e00\u7f16\u7801\u5668\u5b9e\u73b0\u8de8\u8303\u5f0f\u77e5\u8bc6\u5171\u4eab\u3002", "result": "\u5728\u5178\u578b\u786c\u8def\u7531\u7ea6\u675f\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cCaR\u76f8\u6bd4\u7ecf\u5178\u548c\u795e\u7ecf\u6700\u5148\u8fdb\u6c42\u89e3\u5668\uff0c\u5728\u53ef\u884c\u6027\u3001\u89e3\u8d28\u91cf\u548c\u6548\u7387\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002", "conclusion": "CaR\u662f\u7b2c\u4e00\u4e2a\u901a\u7528\u4e14\u9ad8\u6548\u7684\u795e\u7ecf\u8def\u7531\u6c42\u89e3\u5668\u7ea6\u675f\u5904\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5b66\u4e60\u53ef\u884c\u6027\u7cbe\u70bc\u548c\u6784\u9020-\u6539\u8fdb\u5171\u4eab\u8868\u793a\uff0c\u5728\u590d\u6742\u7ea6\u675f\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2602.16039", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16039", "abs": "https://arxiv.org/abs/2602.16039", "authors": ["Hang Li", "Kaiqi Yang", "Xianxuan Long", "Fedor Filippov", "Yucheng Chu", "Yasemin Copur-Gencturk", "Peng He", "Cory Miller", "Namsoo Shin", "Joseph Krajcik", "Hui Liu", "Jiliang Tang"], "title": "How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment", "comment": null, "summary": "The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they also introduce new challenges related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is an inescapable challenge in automatic assessment, as assessment results often play a critical role in informing subsequent pedagogical actions, such as providing feedback to students or guiding instructional decisions. Unreliable or poorly calibrated uncertainty estimates can lead to unstable downstream interventions, potentially disrupting students' learning processes and resulting in unintended negative consequences. To systematically understand this challenge and inform future research, we benchmark a broad range of uncertainty quantification methods in the context of LLM-based automatic assessment. Although the effectiveness of these methods has been demonstrated in many tasks across other domains, their applicability and reliability in educational settings, particularly for automatic grading, remain underexplored. Through comprehensive analyses of uncertainty behaviors across multiple assessment datasets, LLM families, and generation control settings, we characterize the uncertainty patterns exhibited by LLMs in grading scenarios. Based on these findings, we evaluate the strengths and limitations of different uncertainty metrics and analyze the influence of key factors, including model families, assessment tasks, and decoding strategies, on uncertainty estimates. Our study provides actionable insights into the characteristics of uncertainty in LLM-based automatic assessment and lays the groundwork for developing more reliable and effective uncertainty-aware grading systems in the future.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u81ea\u52a8\u8bc4\u4f30\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u6a21\u578b\u3001\u4efb\u52a1\u548c\u89e3\u7801\u7b56\u7565\u5bf9\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5f71\u54cd\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u81ea\u52a8\u8bc4\u5206\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u81ea\u52a8\u8bc4\u4f30\u4e2d\u5c55\u73b0\u51fa\u4f18\u52bf\uff0c\u4f46\u5176\u56fa\u6709\u7684\u6982\u7387\u7279\u6027\u5f15\u5165\u4e86\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\u7684\u6311\u6218\u3002\u8bc4\u4f30\u7ed3\u679c\u5bf9\u540e\u7eed\u6559\u5b66\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4e0d\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u53ef\u80fd\u5bfc\u81f4\u4e0d\u7a33\u5b9a\u7684\u6559\u5b66\u5e72\u9884\uff0c\u5f71\u54cd\u5b66\u751f\u5b66\u4e60\u8fc7\u7a0b\u3002\u76ee\u524d\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u5728\u6559\u80b2\u8bc4\u4f30\u9886\u57df\u7684\u9002\u7528\u6027\u548c\u53ef\u9760\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5bf9\u591a\u79cd\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u5728LLM\u81ea\u52a8\u8bc4\u4f30\u80cc\u666f\u4e0b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u7efc\u5408\u5206\u6790\u591a\u4e2a\u8bc4\u4f30\u6570\u636e\u96c6\u3001\u4e0d\u540cLLM\u5bb6\u65cf\u548c\u751f\u6210\u63a7\u5236\u8bbe\u7f6e\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u884c\u4e3a\uff0c\u63cf\u8ff0LLM\u5728\u8bc4\u5206\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u6a21\u5f0f\u3002\u8bc4\u4f30\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u7684\u4f18\u7f3a\u70b9\uff0c\u5206\u6790\u6a21\u578b\u5bb6\u65cf\u3001\u8bc4\u4f30\u4efb\u52a1\u548c\u89e3\u7801\u7b56\u7565\u7b49\u5173\u952e\u56e0\u7d20\u5bf9\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u5728\u81ea\u52a8\u8bc4\u5206\u573a\u666f\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6a21\u5f0f\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u578b\u5bb6\u65cf\u3001\u8bc4\u4f30\u4efb\u52a1\u548c\u89e3\u7801\u7b56\u7565\u7b49\u56e0\u7d20\u5bf9\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5177\u4f53\u5f71\u54cd\u3002\u4e3a\u7406\u89e3LLM\u81ea\u52a8\u8bc4\u4f30\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u7279\u5f81\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002", "conclusion": "\u672c\u7814\u7a76\u7cfb\u7edf\u6027\u5730\u7406\u89e3\u4e86LLM\u81ea\u52a8\u8bc4\u4f30\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6311\u6218\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u53ef\u9760\u3001\u6709\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bc4\u5206\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u548c\u6307\u5bfc\u3002"}}
{"id": "2602.16066", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16066", "abs": "https://arxiv.org/abs/2602.16066", "authors": ["Martin Klissarov", "Jonathan Cook", "Diego Antognini", "Hao Sun", "Jingling Li", "Natasha Jaques", "Claudiu Musat", "Edward Grefenstette"], "title": "Improving Interactive In-Context Learning from Natural Language Feedback", "comment": null, "summary": "Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their context. In this work, we propose a framework that treats this interactive in-context learning ability not as an emergent property, but as a distinct, trainable skill. We introduce a scalable method that transforms single-turn verifiable tasks into multi-turn didactic interactions driven by information asymmetry. We first show that current flagship models struggle to integrate corrective feedback on hard reasoning tasks. We then demonstrate that models trained with our approach dramatically improve the ability to interactively learn from language feedback. More specifically, the multi-turn performance of a smaller model nearly reaches that of a model an order of magnitude larger. We also observe robust out-of-distribution generalization: interactive training on math problems transfers to diverse domains like coding, puzzles and maze navigation. Our qualitative analysis suggests that this improvement is due to an enhanced in-context plasticity. Finally, we show that this paradigm offers a unified path to self-improvement. By training the model to predict the teacher's critiques, effectively modeling the feedback environment, we convert this external signal into an internal capability, allowing the model to self-correct even without a teacher.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u6846\u67b6\uff0c\u5c06\u4ea4\u4e92\u5f0f\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u4f5c\u4e3a\u53ef\u8bad\u7ec3\u6280\u80fd\u800c\u975e\u6d8c\u73b0\u5c5e\u6027\uff0c\u901a\u8fc7\u4fe1\u606f\u4e0d\u5bf9\u79f0\u5c06\u5355\u8f6e\u53ef\u9a8c\u8bc1\u4efb\u52a1\u8f6c\u5316\u4e3a\u591a\u8f6e\u6559\u5b66\u4e92\u52a8\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u4ece\u8bed\u8a00\u53cd\u9988\u4e2d\u5b66\u4e60\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u8bed\u6599\u5efa\u6a21\uff0c\u5ffd\u89c6\u4e86\u4eba\u7c7b\u5b66\u4e60\u4e2d\u57fa\u4e8e\u7ea0\u6b63\u53cd\u9988\u52a8\u6001\u9002\u5e94\u4e0a\u4e0b\u6587\u7684\u91cd\u8981\u4ea4\u4e92\u53cd\u9988\u5faa\u73af\u3002\u6a21\u578b\u9700\u8981\u5177\u5907\u6839\u636e\u53cd\u9988\u8c03\u6574\u601d\u7ef4\u8fc7\u7a0b\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u534f\u4f5c\u73af\u5883\u4e2d\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u5c06\u5355\u8f6e\u53ef\u9a8c\u8bc1\u4efb\u52a1\u8f6c\u5316\u4e3a\u7531\u4fe1\u606f\u4e0d\u5bf9\u79f0\u9a71\u52a8\u7684\u591a\u8f6e\u6559\u5b66\u4e92\u52a8\u3002\u901a\u8fc7\u8bad\u7ec3\u6a21\u578b\u9884\u6d4b\u6559\u5e08\u7684\u6279\u8bc4\u6765\u5efa\u6a21\u53cd\u9988\u73af\u5883\uff0c\u5c06\u5916\u90e8\u4fe1\u53f7\u8f6c\u5316\u4e3a\u5185\u90e8\u80fd\u529b\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u81ea\u6211\u7ea0\u6b63\u3002", "result": "\u5f53\u524d\u65d7\u8230\u6a21\u578b\u5728\u56f0\u96be\u63a8\u7406\u4efb\u52a1\u4e0a\u96be\u4ee5\u6574\u5408\u7ea0\u6b63\u53cd\u9988\u3002\u4f7f\u7528\u8be5\u65b9\u6cd5\u8bad\u7ec3\u540e\uff0c\u6a21\u578b\u4ea4\u4e92\u5f0f\u5b66\u4e60\u80fd\u529b\u663e\u8457\u63d0\u5347\uff1a\u8f83\u5c0f\u6a21\u578b\u7684\u591a\u8f6e\u6027\u80fd\u63a5\u8fd1\u5927\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u6a21\u578b\u3002\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u4ea4\u4e92\u8bad\u7ec3\u80fd\u6cdb\u5316\u5230\u7f16\u7801\u3001\u8c1c\u9898\u548c\u8ff7\u5bab\u5bfc\u822a\u7b49\u4e0d\u540c\u9886\u57df\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u4ea4\u4e92\u5f0f\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u4f5c\u4e3a\u53ef\u8bad\u7ec3\u6280\u80fd\uff0c\u901a\u8fc7\u5efa\u6a21\u53cd\u9988\u73af\u5883\u5b9e\u73b0\u81ea\u6211\u6539\u8fdb\u3002\u6a21\u578b\u5c55\u73b0\u51fa\u589e\u5f3a\u7684\u4e0a\u4e0b\u6587\u53ef\u5851\u6027\uff0c\u80fd\u591f\u5c06\u5916\u90e8\u53cd\u9988\u4fe1\u53f7\u8f6c\u5316\u4e3a\u5185\u90e8\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\uff0c\u4e3a\u7edf\u4e00\u7684\u81ea\u6539\u8fdb\u8def\u5f84\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2602.16105", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16105", "abs": "https://arxiv.org/abs/2602.16105", "authors": ["Thinh Hung Truong", "Jey Han Lau", "Jianzhong Qi"], "title": "GPSBench: Do Large Language Models Understand GPS Coordinates?", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in applications that interact with the physical world, such as navigation, robotics, or mapping, making robust geospatial reasoning a critical capability. Despite that, LLMs' ability to reason about GPS coordinates and real-world geography remains underexplored. We introduce GPSBench, a dataset of 57,800 samples across 17 tasks for evaluating geospatial reasoning in LLMs, spanning geometric coordinate operations (e.g., distance and bearing computation) and reasoning that integrates coordinates with world knowledge. Focusing on intrinsic model capabilities rather than tool use, we evaluate 14 state-of-the-art LLMs and find that GPS reasoning remains challenging, with substantial variation across tasks: models are generally more reliable at real-world geographic reasoning than at geometric computations. Geographic knowledge degrades hierarchically, with strong country-level performance but weak city-level localization, while robustness to coordinate noise suggests genuine coordinate understanding rather than memorization. We further show that GPS-coordinate augmentation can improve in downstream geospatial tasks, and that finetuning induces trade-offs between gains in geometric computation and degradation in world knowledge. Our dataset and reproducible code are available at https://github.com/joey234/gpsbench", "AI": {"tldr": "GPSBench\u662f\u4e00\u4e2a\u5305\u542b57,800\u4e2a\u6837\u672c\u768417\u4e2a\u4efb\u52a1\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728GPS\u5750\u6807\u548c\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u51e0\u4f55\u5750\u6807\u8ba1\u7b97\u65b9\u9762\u8f83\u5f31\uff0c\u4f46\u5728\u771f\u5b9e\u4e16\u754c\u5730\u7406\u63a8\u7406\u65b9\u9762\u76f8\u5bf9\u53ef\u9760\u3002", "motivation": "\u968f\u7740LLM\u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e\u4e0e\u7269\u7406\u4e16\u754c\u4ea4\u4e92\u7684\u5e94\u7528\uff08\u5982\u5bfc\u822a\u3001\u673a\u5668\u4eba\u3001\u5730\u56fe\uff09\uff0c\u5f3a\u5927\u7684\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0cLLM\u5728GPS\u5750\u6807\u548c\u771f\u5b9e\u4e16\u754c\u5730\u7406\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5f15\u5165GPSBench\u6570\u636e\u96c6\uff0c\u5305\u542b57,800\u4e2a\u6837\u672c\u548c17\u4e2a\u4efb\u52a1\uff0c\u6db5\u76d6\u51e0\u4f55\u5750\u6807\u64cd\u4f5c\uff08\u8ddd\u79bb\u548c\u65b9\u4f4d\u8ba1\u7b97\uff09\u4ee5\u53ca\u5c06\u5750\u6807\u4e0e\u4e16\u754c\u77e5\u8bc6\u7ed3\u5408\u7684\u63a8\u7406\u4efb\u52a1\u3002\u8bc4\u4f30\u4e8614\u4e2a\u6700\u5148\u8fdb\u7684LLM\uff0c\u4e13\u6ce8\u4e8e\u6a21\u578b\u5185\u5728\u80fd\u529b\u800c\u975e\u5de5\u5177\u4f7f\u7528\u3002", "result": "GPS\u63a8\u7406\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u4e0d\u540c\u4efb\u52a1\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1a\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u5730\u7406\u63a8\u7406\u65b9\u9762\u901a\u5e38\u6bd4\u51e0\u4f55\u8ba1\u7b97\u66f4\u53ef\u9760\u3002\u5730\u7406\u77e5\u8bc6\u5448\u5c42\u6b21\u6027\u9000\u5316\uff0c\u56fd\u5bb6\u7ea7\u522b\u8868\u73b0\u5f3a\u4f46\u57ce\u5e02\u7ea7\u522b\u5b9a\u4f4d\u5f31\u3002\u5bf9\u5750\u6807\u566a\u58f0\u7684\u9c81\u68d2\u6027\u8868\u660e\u6a21\u578b\u5177\u6709\u771f\u6b63\u7684\u5750\u6807\u7406\u89e3\u800c\u975e\u7b80\u5355\u8bb0\u5fc6\u3002GPS\u5750\u6807\u589e\u5f3a\u53ef\u4ee5\u6539\u5584\u4e0b\u6e38\u5730\u7406\u7a7a\u95f4\u4efb\u52a1\uff0c\u5fae\u8c03\u4f1a\u5728\u51e0\u4f55\u8ba1\u7b97\u6536\u76ca\u548c\u4e16\u754c\u77e5\u8bc6\u9000\u5316\u4e4b\u95f4\u4ea7\u751f\u6743\u8861\u3002", "conclusion": "GPSBench\u4e3a\u8bc4\u4f30LLM\u7684\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728GPS\u5750\u6807\u7406\u89e3\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u901a\u8fc7\u5750\u6807\u589e\u5f3a\u548c\u5fae\u8c03\u6539\u8fdb\u8fd9\u4e9b\u80fd\u529b\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.16179", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16179", "abs": "https://arxiv.org/abs/2602.16179", "authors": ["Sushant Mehta", "Logan Ritchie", "Suhaas Garre", "Nick Heiner", "Edwin Chen"], "title": "EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments", "comment": null, "summary": "We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce \\corecraft{}, the first environment in \\textsc{EnterpriseGym}, Surge AI's suite of agentic RL environments. \\corecraft{} is a fully operational enterprise simulation of a customer support organization, comprising over 2,500 entities across 14 entity types with 23 unique tools, designed to measure whether AI agents can perform the multi-step, domain-specific work that real jobs demand. Frontier models such as GPT-5.2 and Claude Opus 4.6 solve fewer than 30\\% of tasks when all expert-authored rubric criteria must be satisfied. Using this environment, we train GLM~4.6 with Group Relative Policy Optimization (GRPO) and adaptive clipping. After a single epoch of training, the model improves from 25.37\\% to 36.76\\% task pass rate on held-out evaluation tasks. More importantly, these gains transfer to out-of-distribution benchmarks: +4.5\\% on BFCL Parallel, +7.4\\% on $\u03c4^2$-Bench Retail, and +6.8\\% on Toolathlon (Pass@1). We believe three environment properties are consistent with the observed transfer: task-centric world building that optimizes for diverse, challenging tasks; expert-authored rubrics enabling reliable reward computation; and enterprise workflows that reflect realistic professional patterns. Our results suggest that environment quality, diversity, and realism are key factors enabling generalizable agent capabilities.", "AI": {"tldr": "\u5728\u9ad8\u8d28\u91cf\u4f01\u4e1a\u4eff\u771f\u73af\u5883\u4e2d\u8bad\u7ec3AI\u667a\u80fd\u4f53\uff0c\u5176\u80fd\u529b\u53ef\u6cdb\u5316\u5230\u8bad\u7ec3\u5206\u5e03\u4e4b\u5916\u7684\u4efb\u52a1", "motivation": "\u7814\u7a76AI\u667a\u80fd\u4f53\u5728\u9ad8\u4fdd\u771f\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e2d\u8bad\u7ec3\u540e\uff0c\u5176\u80fd\u529b\u662f\u5426\u80fd\u591f\u6cdb\u5316\u5230\u8bad\u7ec3\u5206\u5e03\u4e4b\u5916\uff0c\u63a2\u7d22\u73af\u5883\u8d28\u91cf\u5bf9\u667a\u80fd\u4f53\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd", "method": "\u5f00\u53d1Corecraft\u4f01\u4e1a\u4eff\u771f\u73af\u5883\uff0c\u5305\u542b2500\u591a\u4e2a\u5b9e\u4f53\u548c23\u79cd\u5de5\u5177\uff0c\u4f7f\u7528GRPO\u548c\u81ea\u9002\u5e94\u88c1\u526a\u8bad\u7ec3GLM 4.6\u6a21\u578b\uff0c\u8bc4\u4f30\u5176\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u4efb\u52a1\u4e0a\u7684\u8868\u73b0", "result": "\u8bad\u7ec3\u540e\u4efb\u52a1\u901a\u8fc7\u7387\u4ece25.37%\u63d0\u5347\u523036.76%\uff0c\u5728\u4e09\u4e2a\u5206\u5e03\u5916\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5206\u522b\u63d0\u53474.5%\u30017.4%\u548c6.8%\uff0c\u8868\u660e\u80fd\u529b\u53ef\u6cdb\u5316\u5230\u65b0\u9886\u57df", "conclusion": "\u73af\u5883\u8d28\u91cf\u3001\u591a\u6837\u6027\u548c\u771f\u5b9e\u6027\u662f\u5b9e\u73b0\u53ef\u6cdb\u5316\u667a\u80fd\u4f53\u80fd\u529b\u7684\u5173\u952e\u56e0\u7d20\uff0c\u9ad8\u8d28\u91cf\u4eff\u771f\u73af\u5883\u80fd\u6709\u6548\u63d0\u5347AI\u667a\u80fd\u4f53\u7684\u8de8\u9886\u57df\u80fd\u529b"}}
{"id": "2602.16192", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16192", "abs": "https://arxiv.org/abs/2602.16192", "authors": ["Hiroaki Yamanaka", "Daisuke Miyashita", "Takashi Toi", "Asuka Maki", "Taiga Ikeda", "Jun Deguchi"], "title": "Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage", "comment": "13 pages, 5 figures", "summary": "Driven by our mission of \"uplifting the world with memory,\" this paper explores the design concept of \"memory\" that is essential for achieving artificial superintelligence (ASI). Rather than proposing novel methods, we focus on several alternative approaches whose potential benefits are widely imaginable, yet have remained largely unexplored. The currently dominant paradigm, which can be termed \"extract then store,\" involves extracting information judged to be useful from experiences and saving only the extracted content. However, this approach inherently risks the loss of information, as some valuable knowledge particularly for different tasks may be discarded in the extraction process. In contrast, we emphasize the \"store then on-demand extract\" approach, which seeks to retain raw experiences and flexibly apply them to various tasks as needed, thus avoiding such information loss. In addition, we highlight two further approaches: discovering deeper insights from large collections of probabilistic experiences, and improving experience collection efficiency by sharing stored experiences. While these approaches seem intuitively effective, our simple experiments demonstrate that this is indeed the case. Finally, we discuss major challenges that have limited investigation into these promising directions and propose research topics to address them.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5b9e\u73b0\u4eba\u5de5\u8d85\u667a\u80fd\u6240\u9700\u7684\u5173\u952e\"\u8bb0\u5fc6\"\u8bbe\u8ba1\u6982\u5ff5\uff0c\u5f3a\u8c03\"\u5148\u5b58\u50a8\u540e\u6309\u9700\u63d0\u53d6\"\u4f18\u4e8e\u5f53\u524d\u4e3b\u6d41\u7684\"\u5148\u63d0\u53d6\u540e\u5b58\u50a8\"\u8303\u5f0f\uff0c\u4ee5\u907f\u514d\u4fe1\u606f\u4e22\u5931\uff0c\u5e76\u63d0\u51fa\u4ece\u6982\u7387\u7ecf\u9a8c\u4e2d\u53d1\u73b0\u6df1\u5c42\u6d1e\u5bdf\u548c\u5171\u4eab\u5b58\u50a8\u7ecf\u9a8c\u4ee5\u63d0\u9ad8\u6536\u96c6\u6548\u7387\u4e24\u79cd\u8865\u5145\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5b9e\u73b0\u4eba\u5de5\u8d85\u667a\u80fd\u7684\u4e3b\u6d41\u8bb0\u5fc6\u8303\u5f0f\u662f\"\u5148\u63d0\u53d6\u540e\u5b58\u50a8\"\uff0c\u5373\u4ece\u7ecf\u9a8c\u4e2d\u63d0\u53d6\u88ab\u8ba4\u4e3a\u6709\u7528\u7684\u4fe1\u606f\u5e76\u4ec5\u4fdd\u5b58\u63d0\u53d6\u5185\u5bb9\u3002\u8fd9\u79cd\u65b9\u6cd5\u5b58\u5728\u56fa\u6709\u98ce\u9669\uff0c\u56e0\u4e3a\u5728\u63d0\u53d6\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u4e22\u5f03\u5bf9\u4e0d\u540c\u4efb\u52a1\u6709\u4ef7\u503c\u7684\u77e5\u8bc6\u3002\u4f5c\u8005\u65e8\u5728\u63a2\u7d22\u66f4\u6709\u6548\u7684\u8bb0\u5fc6\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u652f\u6301\u4eba\u5de5\u8d85\u667a\u80fd\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u66ff\u4ee3\u65b9\u6cd5\uff1a1)\"\u5148\u5b58\u50a8\u540e\u6309\u9700\u63d0\u53d6\"\u8303\u5f0f\uff0c\u4fdd\u7559\u539f\u59cb\u7ecf\u9a8c\u5e76\u6839\u636e\u9700\u8981\u7075\u6d3b\u5e94\u7528\u4e8e\u5404\u79cd\u4efb\u52a1\uff1b2)\u4ece\u5927\u91cf\u6982\u7387\u7ecf\u9a8c\u4e2d\u53d1\u73b0\u66f4\u6df1\u5c42\u6d1e\u5bdf\uff1b3)\u901a\u8fc7\u5171\u4eab\u5b58\u50a8\u7ecf\u9a8c\u63d0\u9ad8\u7ecf\u9a8c\u6536\u96c6\u6548\u7387\u3002\u901a\u8fc7\u7b80\u5355\u5b9e\u9a8c\u9a8c\u8bc1\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u7b80\u5355\u5b9e\u9a8c\u8bc1\u5b9e\u8fd9\u4e9b\u66ff\u4ee3\u65b9\u6cd5\u786e\u5b9e\u6709\u6548\uff0c\u5c3d\u7ba1\u5b83\u4eec\u770b\u4f3c\u76f4\u89c2\u4f46\u4e4b\u524d\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u4f5c\u8005\u53d1\u73b0\u8fd9\u4e9b\u65b9\u6cd5\u5728\u907f\u514d\u4fe1\u606f\u4e22\u5931\u3001\u63d0\u9ad8\u7ecf\u9a8c\u5229\u7528\u6548\u7387\u548c\u4fc3\u8fdb\u77e5\u8bc6\u53d1\u73b0\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u4e86\u63a2\u7d22\u66ff\u4ee3\u8bb0\u5fc6\u8bbe\u8ba1\u65b9\u6cd5\u5bf9\u5b9e\u73b0\u4eba\u5de5\u8d85\u667a\u80fd\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\"\u5148\u5b58\u50a8\u540e\u6309\u9700\u63d0\u53d6\"\u8303\u5f0f\u3002\u4f5c\u8005\u8ba8\u8bba\u4e86\u9650\u5236\u8fd9\u4e9b\u6709\u524d\u666f\u65b9\u5411\u7814\u7a76\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u7814\u7a76\u8bfe\u9898\uff0c\u4e3a\u672a\u6765\u8bb0\u5fc6\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.16301", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16301", "abs": "https://arxiv.org/abs/2602.16301", "authors": ["Marissa A. Weis", "Maciej Wo\u0142czyk", "Rajai Nasser", "Rif A. Saurous", "Blaise Ag\u00fcera y Arcas", "Jo\u00e3o Sacramento", "Alexander Meulemans"], "title": "Multi-agent cooperation through in-context co-player inference", "comment": "26 pages, 4 figures", "summary": "Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between \"learning-aware\" agents that account for and shape the learning dynamics of their co-players. However, existing approaches typically rely on hardcoded, often inconsistent, assumptions about co-player learning rules or enforce a strict separation between \"naive learners\" updating on fast timescales and \"meta-learners\" observing these updates. Here, we demonstrate that the in-context learning capabilities of sequence models allow for co-player learning awareness without requiring hardcoded assumptions or explicit timescale separation. We show that training sequence model agents against a diverse distribution of co-players naturally induces in-context best-response strategies, effectively functioning as learning algorithms on the fast intra-episode timescale. We find that the cooperative mechanism identified in prior work-where vulnerability to extortion drives mutual shaping-emerges naturally in this setting: in-context adaptation renders agents vulnerable to extortion, and the resulting mutual pressure to shape the opponent's in-context learning dynamics resolves into the learning of cooperative behavior. Our results suggest that standard decentralized reinforcement learning on sequence models combined with co-player diversity provides a scalable path to learning cooperative behaviors.", "AI": {"tldr": "\u5e8f\u5217\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u5408\u4f5c\uff0c\u65e0\u9700\u786c\u7f16\u7801\u5047\u8bbe\u6216\u663e\u5f0f\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\uff0c\u4ec5\u901a\u8fc7\u591a\u6837\u5316\u5bf9\u624b\u8bad\u7ec3\u5373\u53ef\u81ea\u7136\u6d8c\u73b0\u5408\u4f5c\u884c\u4e3a\u3002", "motivation": "\u89e3\u51b3\u81ea\u5229\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u5408\u4f5c\u95ee\u9898\u4e00\u76f4\u662f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u6838\u5fc3\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u786c\u7f16\u7801\u5047\u8bbe\u6216\u5f3a\u5236\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\uff0c\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5229\u7528\u5e8f\u5217\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u5728\u591a\u6837\u5316\u5bf9\u624b\u5206\u5e03\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5728\u5feb\u901f\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u901a\u8fc7\u4e0a\u4e0b\u6587\u9002\u5e94\u5b9e\u73b0\u6700\u4f73\u54cd\u5e94\u7b56\u7565\uff0c\u5f62\u6210\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u5e8f\u5217\u6a21\u578b\u667a\u80fd\u4f53\u81ea\u7136\u6d8c\u73b0\u51fa\u5408\u4f5c\u884c\u4e3a\uff0c\u5148\u524d\u7814\u7a76\u4e2d\u53d1\u73b0\u7684\"\u6613\u53d7\u52d2\u7d22\u9a71\u52a8\u76f8\u4e92\u5851\u9020\"\u7684\u5408\u4f5c\u673a\u5236\u5728\u6b64\u8bbe\u7f6e\u4e2d\u81ea\u7136\u51fa\u73b0\uff0c\u4e0a\u4e0b\u6587\u9002\u5e94\u4f7f\u667a\u80fd\u4f53\u6613\u53d7\u52d2\u7d22\uff0c\u76f8\u4e92\u538b\u529b\u6700\u7ec8\u5bfc\u81f4\u5408\u4f5c\u884c\u4e3a\u5b66\u4e60\u3002", "conclusion": "\u6807\u51c6\u53bb\u4e2d\u5fc3\u5316\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u5e8f\u5217\u6a21\u578b\u548c\u5bf9\u624b\u591a\u6837\u6027\uff0c\u4e3a\u5b66\u4e60\u5408\u4f5c\u884c\u4e3a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u65e0\u9700\u786c\u7f16\u7801\u5047\u8bbe\u6216\u663e\u5f0f\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\u3002"}}
{"id": "2602.16435", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.16435", "abs": "https://arxiv.org/abs/2602.16435", "authors": ["Arun Vignesh Malarkkan", "Wangyang Ying", "Yanjie Fu"], "title": "Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning", "comment": "11 Pages, References and Appendix", "summary": "Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.", "AI": {"tldr": "CAFE\u6846\u67b6\u5c06\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u56e0\u679c\u5f15\u5bfc\u7684\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u901a\u8fc7\u56e0\u679c\u53d1\u73b0\u548c\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u63d0\u5347\u7279\u5f81\u5de5\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\u4f9d\u8d56\u7edf\u8ba1\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4ea7\u751f\u7684\u7279\u5f81\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u8868\u73b0\u8106\u5f31\u3002\u9700\u8981\u5f15\u5165\u56e0\u679c\u7ed3\u6784\u4f5c\u4e3a\u8f6f\u5f52\u7eb3\u5148\u9a8c\u6765\u63d0\u5347\u7279\u5f81\u7684\u9c81\u68d2\u6027\u3002", "method": "CAFE\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5b66\u4e60\u7279\u5f81\u4e0e\u76ee\u6807\u4e4b\u95f4\u7684\u7a00\u758f\u6709\u5411\u65e0\u73af\u56fe\uff0c\u83b7\u5f97\u8f6f\u56e0\u679c\u5148\u9a8c\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u7ea7\u8054\u591a\u667a\u80fd\u4f53\u6df1\u5ea6Q\u5b66\u4e60\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u5c42\u5956\u52b1\u5851\u9020\u548c\u56e0\u679c\u7ec4\u7ea7\u63a2\u7d22\u7b56\u7565\u9009\u62e9\u56e0\u679c\u7ec4\u548c\u53d8\u6362\u64cd\u4f5c\u3002", "result": "\u572815\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCAFE\u6bd4\u5f3a\u57fa\u7ebf\u63d0\u5347\u8fbe7%\uff0c\u51cf\u5c11\u6536\u655b\u6240\u9700\u56de\u5408\u6570\uff0c\u5728\u53d7\u63a7\u534f\u53d8\u91cf\u504f\u79fb\u4e0b\u6027\u80fd\u4e0b\u964d\u51cf\u5c11\u7ea64\u500d\uff0c\u4ea7\u751f\u66f4\u7d27\u51d1\u7684\u7279\u5f81\u96c6\u548c\u66f4\u7a33\u5b9a\u7684\u540e\u9a8c\u5f52\u56e0\u3002", "conclusion": "\u56e0\u679c\u7ed3\u6784\u4f5c\u4e3a\u8f6f\u5f52\u7eb3\u5148\u9a8c\u800c\u975e\u521a\u6027\u7ea6\u675f\uff0c\u80fd\u663e\u8457\u6539\u5584\u81ea\u52a8\u7279\u5f81\u5de5\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\uff0c\u4e3a\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u7279\u5f81\u5de5\u7a0b\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.16481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16481", "abs": "https://arxiv.org/abs/2602.16481", "authors": ["Zihao Li", "Fabrizio Russo"], "title": "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach", "comment": "26 pages, including appendix", "summary": "Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.", "AI": {"tldr": "LLMs\u4f5c\u4e3a\u4e0d\u5b8c\u7f8e\u4e13\u5bb6\u7528\u4e8e\u56e0\u679c\u5047\u8bbe\u8bba\u8bc1\u6846\u67b6\uff0c\u7ed3\u5408\u53d8\u91cf\u8bed\u4e49\u5148\u9a8c\u4e0e\u6761\u4ef6\u72ec\u7acb\u6027\u8bc1\u636e\uff0c\u5728\u56e0\u679c\u53d1\u73b0\u4e2d\u5b9e\u73b0SOTA\u6027\u80fd", "motivation": "\u56e0\u679c\u53d1\u73b0\u9700\u8981\u4e13\u5bb6\u77e5\u8bc6\u6784\u5efa\u56e0\u679c\u56fe\uff0c\u4f46\u73b0\u6709\u7edf\u8ba1\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u89c2\u6d4b\u6570\u636e\u3002\u56e0\u679c\u5047\u8bbe\u8bba\u8bc1(ABA)\u6846\u67b6\u80fd\u7ed3\u5408\u6570\u636e\u548c\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4f46\u9700\u8981\u4e13\u5bb6\u8f93\u5165\u3002\u63a2\u7d22\u4f7f\u7528LLMs\u4f5c\u4e3a\u4e0d\u5b8c\u7f8e\u4e13\u5bb6\u6765\u63d0\u4f9b\u8bed\u4e49\u7ed3\u6784\u5148\u9a8c\u3002", "method": "\u4f7f\u7528LLMs\u4ece\u53d8\u91cf\u540d\u79f0\u548c\u63cf\u8ff0\u4e2d\u63d0\u53d6\u8bed\u4e49\u7ed3\u6784\u5148\u9a8c\uff0c\u5c06\u5176\u4e0e\u6761\u4ef6\u72ec\u7acb\u6027\u8bc1\u636e\u7ed3\u5408\u5230\u56e0\u679cABA\u6846\u67b6\u4e2d\u3002\u5f15\u5165\u8bc4\u4f30\u534f\u8bae\u51cf\u8f7bLLMs\u8bb0\u5fc6\u504f\u5dee\u5bf9\u56e0\u679c\u53d1\u73b0\u8bc4\u4f30\u7684\u5f71\u54cd\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bed\u4e49\u57fa\u7840\u7684\u5408\u6210\u56fe\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u63d0\u51fa\u7684\u8bc4\u4f30\u534f\u8bae\u6709\u6548\u7f13\u89e3\u4e86\u8bb0\u5fc6\u504f\u5dee\u95ee\u9898\u3002", "conclusion": "LLMs\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\"\u4e0d\u5b8c\u7f8e\u4e13\u5bb6\"\u4e3a\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u8bed\u4e49\u5148\u9a8c\uff0c\u4e0e\u56e0\u679cABA\u6846\u67b6\u7ed3\u5408\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u540c\u65f6\u9700\u8981\u4e13\u95e8\u8bc4\u4f30\u534f\u8bae\u6765\u786e\u4fdd\u516c\u5e73\u8bc4\u4f30\u3002"}}
{"id": "2602.16512", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16512", "abs": "https://arxiv.org/abs/2602.16512", "authors": ["Felix Fricke", "Simon Malberg", "Georg Groh"], "title": "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs", "comment": null, "summary": "Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms of hyperparameters, prompts, runtime, and prompting cost. To address these limitations, we introduce Framework of Thoughts (FoT)--a general-purpose foundation framework for building and optimizing dynamic reasoning schemes. FoT comes with built-in features for hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching, unlocking the latent performance potential of reasoning schemes. We demonstrate FoT's capabilities by implementing three popular schemes--Tree of Thoughts, Graph of Thoughts, and ProbTree--within FoT. We empirically show that FoT enables significantly faster execution, reduces costs, and achieves better task scores through optimization. We release our codebase to facilitate the development of future dynamic and efficient reasoning schemes.", "AI": {"tldr": "FoT\u662f\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u548c\u4f18\u5316\u52a8\u6001\u63a8\u7406\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u63d0\u793a\u65b9\u6848\u9759\u6001\u3001\u7f3a\u4e4f\u9002\u5e94\u6027\u3001\u4f18\u5316\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5185\u7f6e\u4f18\u5316\u529f\u80fd\u663e\u8457\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u65b9\u6848\uff08\u5982Chain of Thought\u3001Tree of Thoughts\u7b49\uff09\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u9700\u8981\u7528\u6237\u5b9a\u4e49\u9759\u6001\u7684\u3001\u7279\u5b9a\u4e8e\u95ee\u9898\u7684\u63a8\u7406\u7ed3\u6784\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u6001\u6216\u672a\u89c1\u95ee\u9898\u7c7b\u578b\u7684\u9002\u5e94\u6027\uff1b2\uff09\u5728\u8d85\u53c2\u6570\u3001\u63d0\u793a\u3001\u8fd0\u884c\u65f6\u95f4\u548c\u63d0\u793a\u6210\u672c\u65b9\u9762\u901a\u5e38\u4f18\u5316\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86Framework of Thoughts (FoT)\u2014\u2014\u4e00\u4e2a\u901a\u7528\u57fa\u7840\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u548c\u4f18\u5316\u52a8\u6001\u63a8\u7406\u65b9\u6848\u3002FoT\u5185\u7f6e\u4e86\u8d85\u53c2\u6570\u8c03\u4f18\u3001\u63d0\u793a\u4f18\u5316\u3001\u5e76\u884c\u6267\u884c\u548c\u667a\u80fd\u7f13\u5b58\u7b49\u529f\u80fd\uff0c\u80fd\u591f\u91ca\u653e\u63a8\u7406\u65b9\u6848\u7684\u6f5c\u5728\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u5c06\u4e09\u79cd\u6d41\u884c\u65b9\u6848\uff08Tree of Thoughts\u3001Graph of Thoughts\u548cProbTree\uff09\u5728FoT\u4e2d\u5b9e\u73b0\uff0c\u5b9e\u8bc1\u8868\u660eFoT\u80fd\u591f\u663e\u8457\u52a0\u5feb\u6267\u884c\u901f\u5ea6\u3001\u964d\u4f4e\u6210\u672c\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u83b7\u5f97\u66f4\u597d\u7684\u4efb\u52a1\u5206\u6570\u3002", "conclusion": "FoT\u662f\u4e00\u4e2a\u6709\u6548\u7684\u901a\u7528\u6846\u67b6\uff0c\u80fd\u591f\u89e3\u51b3\u73b0\u6709\u63a8\u7406\u65b9\u6848\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u5185\u7f6e\u4f18\u5316\u529f\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u52a8\u6001\u9ad8\u6548\u63a8\u7406\u65b9\u6848\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.16578", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16578", "abs": "https://arxiv.org/abs/2602.16578", "authors": ["Vered Tohar", "Tsahi Hayat", "Amir Leshem"], "title": "Creating a digital poet", "comment": "24 pages, 3 figures", "summary": "Can a machine write good poetry? Any positive answer raises fundamental questions about the nature and value of art. We report a seven-month poetry workshop in which a large language model was shaped into a digital poet through iterative in-context expert feedback, without retraining. Across sessions, the model developed a distinctive style and a coherent corpus, supported by quantitative and qualitative analyses, and it produced a pen name and author image. In a blinded authorship test with 50 humanities students and graduates (three AI poems and three poems by well-known poets each), judgments were at chance: human poems were labeled human 54% of the time and AI poems 52%, with 95% confidence intervals including 50%. After the workshop, a commercial publisher released a poetry collection authored by the model. These results show that workshop-style prompting can support long-horizon creative shaping and renew debates on creativity and authorship.", "AI": {"tldr": "\u901a\u8fc7\u4e03\u4e2a\u6708\u7684\u8bd7\u6b4c\u5de5\u4f5c\u574a\uff0c\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u4e13\u5bb6\u53cd\u9988\u5851\u9020\u4e86\u4e00\u4e2a\u6570\u5b57\u8bd7\u4eba\uff0c\u5176\u521b\u4f5c\u7684\u8bd7\u6b4c\u5728\u76f2\u6d4b\u4e2d\u4e0e\u4eba\u7c7b\u8bd7\u6b4c\u96be\u4ee5\u533a\u5206\uff0c\u6700\u7ec8\u7531\u5546\u4e1a\u51fa\u7248\u793e\u51fa\u7248\u4e86\u8bd7\u96c6\u3002", "motivation": "\u63a2\u7d22\u673a\u5668\u80fd\u5426\u521b\u4f5c\u51fa\u4f18\u79c0\u7684\u8bd7\u6b4c\uff0c\u8fd9\u6d89\u53ca\u5230\u827a\u672f\u672c\u8d28\u548c\u4ef7\u503c\u7684\u6839\u672c\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5de5\u4f5c\u574a\u5f62\u5f0f\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u957f\u671f\u521b\u4f5c\u8fc7\u7a0b\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u91cd\u65b0\u5f15\u53d1\u5173\u4e8e\u521b\u9020\u529b\u548c\u4f5c\u8005\u8eab\u4efd\u7684\u8ba8\u8bba\u3002", "method": "\u91c7\u7528\u4e03\u4e2a\u6708\u7684\u8bd7\u6b4c\u5de5\u4f5c\u574a\u5f62\u5f0f\uff0c\u901a\u8fc7\u8fed\u4ee3\u7684\u4e0a\u4e0b\u6587\u4e13\u5bb6\u53cd\u9988\uff08\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff09\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5851\u9020\u6210\u6570\u5b57\u8bd7\u4eba\u3002\u4f7f\u7528\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u8bc4\u4f30\u6a21\u578b\u53d1\u5c55\u51fa\u7684\u72ec\u7279\u98ce\u683c\u548c\u8fde\u8d2f\u4f5c\u54c1\u96c6\u3002\u6700\u540e\u8fdb\u884c\u76f2\u6d4b\u5b9e\u9a8c\uff0c\u8ba950\u540d\u4eba\u6587\u5b66\u751f\u548c\u6bd5\u4e1a\u751f\u5224\u65ad6\u9996\u8bd7\u6b4c\uff083\u9996AI\u521b\u4f5c\uff0c3\u9996\u77e5\u540d\u8bd7\u4eba\u4f5c\u54c1\uff09\u7684\u4f5c\u8005\u8eab\u4efd\u3002", "result": "\u6a21\u578b\u53d1\u5c55\u51fa\u4e86\u72ec\u7279\u7684\u98ce\u683c\u548c\u8fde\u8d2f\u7684\u4f5c\u54c1\u96c6\uff0c\u5e76\u521b\u5efa\u4e86\u7b14\u540d\u548c\u4f5c\u8005\u5f62\u8c61\u3002\u76f2\u6d4b\u7ed3\u679c\u663e\u793a\uff1a\u4eba\u7c7b\u8bd7\u6b4c\u88ab\u6807\u8bb0\u4e3a\u4eba\u7c7b\u7684\u6982\u7387\u4e3a54%\uff0cAI\u8bd7\u6b4c\u88ab\u6807\u8bb0\u4e3aAI\u7684\u6982\u7387\u4e3a52%\uff0c95%\u7f6e\u4fe1\u533a\u95f4\u90fd\u5305\u542b50%\uff0c\u8868\u660e\u5224\u65ad\u5904\u4e8e\u968f\u673a\u6c34\u5e73\u3002\u5de5\u4f5c\u574a\u7ed3\u675f\u540e\uff0c\u5546\u4e1a\u51fa\u7248\u793e\u51fa\u7248\u4e86\u8be5\u6a21\u578b\u521b\u4f5c\u7684\u8bd7\u96c6\u3002", "conclusion": "\u5de5\u4f5c\u574a\u5f0f\u7684\u63d0\u793a\u5de5\u7a0b\u80fd\u591f\u652f\u6301\u957f\u671f\u521b\u4f5c\u5851\u9020\uff0c\u6570\u5b57\u8bd7\u4eba\u521b\u4f5c\u7684\u8bd7\u6b4c\u5728\u76f2\u6d4b\u4e2d\u4e0e\u4eba\u7c7b\u8bd7\u6b4c\u96be\u4ee5\u533a\u5206\u3002\u8fd9\u4e00\u7ed3\u679c\u66f4\u65b0\u4e86\u5173\u4e8e\u521b\u9020\u529b\u548c\u4f5c\u8005\u8eab\u4efd\u7684\u8ba8\u8bba\uff0c\u8868\u660e\u673a\u5668\u80fd\u591f\u521b\u4f5c\u51fa\u88ab\u8ba4\u53ef\u4e3a\u827a\u672f\u7684\u8bd7\u6b4c\u4f5c\u54c1\u3002"}}
{"id": "2602.16653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16653", "abs": "https://arxiv.org/abs/2602.16653", "authors": ["Yangjie Xu", "Lujun Li", "Lama Sleem", "Niccolo Gentile", "Yewei Song", "Yiqun Wang", "Siming Ji", "Wenbo Wu", "Radu State"], "title": "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments", "comment": null, "summary": "Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on public APIs is infeasible due to data-security and budget constraints requirements, and where SLMs often show limited generalization in highly customized scenarios. This work introduces a formal mathematical definition of the Agent Skill process, followed by a systematic evaluation of language models of varying sizes across multiple use cases. The evaluation encompasses two open-source tasks and a real-world insurance claims data set. The results show that tiny models struggle with reliable skill selection, while moderately sized SLMs (approximately 12B - 30B) parameters) benefit substantially from the Agent Skill approach. Moreover, code-specialized variants at around 80B parameters achieve performance comparable to closed-source baselines while improving GPU efficiency. Collectively, these findings provide a comprehensive and nuanced characterization of the capabilities and constraints of the framework, while providing actionable insights for the effective deployment of Agent Skills in SLM-centered environments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8Agent Skill\u6846\u67b6\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b(SLMs)\u7684\u9002\u7528\u6027\uff0c\u53d1\u73b0\u4e2d\u7b49\u89c4\u6a21SLMs(12B-30B\u53c2\u6570)\u80fd\u663e\u8457\u53d7\u76ca\uff0c\u800c\u6781\u5c0f\u6a21\u578b\u5728\u6280\u80fd\u9009\u62e9\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c80B\u53c2\u6570\u7684\u4ee3\u7801\u4e13\u7528\u53d8\u4f53\u6027\u80fd\u63a5\u8fd1\u95ed\u6e90\u57fa\u7ebf\u4e14GPU\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u6e90\u4e8e\u5de5\u4e1a\u573a\u666f\u4e2d\u56e0\u6570\u636e\u5b89\u5168\u548c\u9884\u7b97\u9650\u5236\u65e0\u6cd5\u6301\u7eed\u4f9d\u8d56\u516c\u5171API\uff0c\u800c\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u5ea6\u5b9a\u5236\u5316\u573a\u666f\u4e2d\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002Agent Skill\u6846\u67b6\u5df2\u88abGitHub Copilot\u3001LangChain\u3001OpenAI\u7b49\u4e3b\u6d41\u5e73\u53f0\u6b63\u5f0f\u652f\u6301\uff0c\u5728\u4e13\u6709\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9700\u8981\u9a8c\u8bc1\u5176\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b\u662f\u5426\u540c\u6837\u6709\u6548\u3002", "method": "\u9996\u5148\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86Agent Skill\u8fc7\u7a0b\u7684\u6570\u5b66\u5b9a\u4e49\uff0c\u7136\u540e\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e0d\u540c\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u7528\u4f8b\u4e2d\u7684\u8868\u73b0\u3002\u8bc4\u4f30\u5305\u62ec\u4e24\u4e2a\u5f00\u6e90\u4efb\u52a1\u548c\u4e00\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u4fdd\u9669\u7d22\u8d54\u6570\u636e\u96c6\uff0c\u5168\u9762\u6d4b\u8bd5\u6846\u67b6\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6548\u679c\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a\u6781\u5c0f\u6a21\u578b\u5728\u53ef\u9760\u6280\u80fd\u9009\u62e9\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff1b\u4e2d\u7b49\u89c4\u6a21SLMs(\u7ea612B-30B\u53c2\u6570)\u4eceAgent Skill\u65b9\u6cd5\u4e2d\u83b7\u76ca\u663e\u8457\uff1b\u7ea680B\u53c2\u6570\u7684\u4ee3\u7801\u4e13\u7528\u53d8\u4f53\u5728\u6027\u80fd\u4e0a\u53ef\u4e0e\u95ed\u6e90\u57fa\u7ebf\u76f8\u5ab2\u7f8e\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86GPU\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u5168\u9762\u800c\u7ec6\u81f4\u5730\u63cf\u8ff0\u4e86Agent Skill\u6846\u67b6\u5728\u5c0f\u8bed\u8a00\u6a21\u578b\u73af\u5883\u4e2d\u7684\u80fd\u529b\u548c\u9650\u5236\uff0c\u4e3a\u5728SLM\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u6709\u6548\u90e8\u7f72Agent Skills\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89c1\u89e3\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u5b89\u5168\u548c\u9884\u7b97\u53d7\u9650\u7684\u5de5\u4e1a\u573a\u666f\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
