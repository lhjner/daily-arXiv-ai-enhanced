<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems](https://arxiv.org/abs/2601.10738)
*Percy Jardine*

Main category: cs.AI

TL;DR: CTHA是一个约束性时间分层架构，通过结构化流形和仲裁机制解决多时间尺度智能体系统中的协调稳定性问题，显著减少故障级联并提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 多时间尺度智能体架构虽然提升了性能，但破坏了统一智能体系统的协调稳定性，导致严重的层间冲突、无界错误传播和可扩展性受限。

Method: 提出约束性时间分层架构（CTHA），将层间通信空间投影到结构化流形上，包含三个关键约束：消息契约约束、权威流形约束和仲裁解决约束。

Result: 实验证明CTHA在复杂任务执行中有效，相比无约束分层基线，故障级联减少47%，样本效率提高2.3倍，并具有优越的可扩展性。

Conclusion: CTHA作为时间分层架构的原则性扩展，有助于深入理解多智能体协调，并为稳健自主系统的演进提供了有前景的方向。

Abstract: Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.

</details>


### [2] [Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration](https://arxiv.org/abs/2601.10744)
*Sen Wang,Bangwei Liu,Zhenkun Gao,Lizhuang Ma,Xuhong Wang,Yuan Xie,Xin Tan*

Main category: cs.AI

TL;DR: 该论文提出了LMEE框架和LMEE-Bench基准，通过MemoryExplorer方法增强智能体的长期记忆和主动探索能力，在长时程具身任务中取得显著优势。


<details>
  <summary>Details</summary>
Motivation: 现有主流的一次性具身任务主要关注任务完成结果，忽视了探索过程和记忆利用这一关键环节。理想的具身智能体应具备终身学习能力，能够利用长期情景记忆优化决策，在通用环境中持续运行。

Method: 提出LMEE框架统一智能体的探索认知和决策行为；构建LMEE-Bench数据集和基准，包含多目标导航和基于记忆的问答任务；提出MemoryExplorer方法，通过强化学习微调多模态大语言模型，鼓励主动记忆查询，采用包含动作预测、前沿选择和问答的多任务奖励函数。

Result: 与最先进的具身探索模型进行大量实验对比，证明该方法在长时程具身任务中取得显著优势，提升了智能体的记忆回忆和主动探索能力。

Conclusion: LMEE框架和MemoryExplorer方法有效促进了具身智能体的终身学习能力，通过统一探索认知和决策行为，结合主动记忆查询机制，在长时程复杂任务中表现出色。

Abstract: An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.

</details>


### [3] [Optimisation of complex product innovation processes based on trend models with three-valued logic](https://arxiv.org/abs/2601.10768)
*Nina Bočková,Barbora Volná,Mirko Dohnal*

Main category: cs.AI

TL;DR: 该研究使用基于启发式规则的趋势模型分析复杂产品创新过程，通过简单趋势（增加、减少、恒定）作为最小信息强度量化器，避免依赖数值或粗糙集，用转换图表示系统可能的未来或过去行为。


<details>
  <summary>Details</summary>
Motivation: 研究复杂产品创新过程需要有效的分析方法，传统数值方法可能过于复杂或不适用，需要一种简单但信息丰富的方法来量化创新动态。

Method: 基于启发式规则构建趋势模型，每个启发式通过简单趋势（增加、减少、恒定）表达，作为最小信息强度量化器。解决方案定义为包含可能转换的场景集合，用转换图表示。

Result: 开发了一种用转换图表示系统行为的方法，任何可能的未来或过去行为都可以通过图中的路径来描绘，为复杂产品创新过程提供了可视化分析框架。

Conclusion: 基于启发式的趋势模型为分析复杂产品创新过程提供了一种有效方法，通过简单趋势量化和转换图表示，能够捕捉系统动态而不依赖复杂数值分析。

Abstract: This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.

</details>


### [4] [ARC Prize 2025: Technical Report](https://arxiv.org/abs/2601.10904)
*François Chollet,Mike Knoop,Gregory Kamradt,Bryan Landers*

Main category: cs.AI

TL;DR: ARC-AGI-2竞赛显示AI在抽象推理方面仍有局限，当前最佳方法依赖迭代优化循环，前沿AI模型性能受知识覆盖限制，存在基准污染问题。


<details>
  <summary>Details</summary>
Motivation: 分析2025年ARC-AGI竞赛结果，研究当前AI在抽象推理和少样本泛化方面的进展与局限，探讨精炼循环在AGI发展中的作用。

Method: 通过调查ARC-AGI-2竞赛的顶级方法，分析精炼循环（包括进化程序合成和商业AI系统应用层优化）的作用，评估前沿AI实验室的公开性能报告。

Result: 竞赛最佳成绩仅达24%，精炼循环成为2025年主要方法，前沿AI模型性能受知识覆盖限制，存在基准污染问题，需要新的评估方法。

Conclusion: 当前AI抽象推理能力仍有限，精炼循环是重要进展方向，但需解决知识依赖过拟合问题，ARC-AGI-3将引入交互式推理挑战以评估更全面的智能能力。

Abstract: The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.

</details>


### [5] [What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge](https://arxiv.org/abs/2601.10922)
*Yosub Shin,Michael Buriek,Boris Sobolev,Pavel Bushuyeu,Vikas Kumar,Haoyang Xu,Samuel Watson,Igor Molybog*

Main category: cs.AI

TL;DR: 该研究通过NeurIPS 2025 DCVLR挑战赛探讨多模态推理的数据策展，发现基于难度的样本选择是性能提升的关键因素，而数据集大小增加主要减少方差而非提升平均准确率。


<details>
  <summary>Details</summary>
Motivation: 研究多模态推理中的数据策展问题，通过固定模型和训练协议来隔离数据集选择的影响，探索在数据效率有限的情况下如何优化多模态推理性能。

Method: 使用NeurIPS 2025 DCVLR挑战赛框架，固定模型和训练协议，主要基于Walton Multimodal Cold Start构建紧凑的策展数据集，通过赛后消融实验分析不同数据策展策略的效果。

Result: 基于难度的样本选择在已对齐的基础数据集上是性能提升的主要驱动力；增加数据集大小不能可靠提高平均准确率，但能减少运行方差；常用的多样性和合成增强启发式方法没有额外益处，反而可能降低性能。

Conclusion: DCVLR是一个饱和状态评估，强调了对齐和难度在数据高效多模态推理中的核心作用，为多模态数据策展提供了重要指导。

Abstract: We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.

</details>


### [6] [ReCreate: Reasoning and Creating Domain Agents Driven by Experience](https://arxiv.org/abs/2601.11100)
*Zhezheng Hao,Hong Wang,Jian Luo,Jianqing Zhang,Yuyan Zhou,Qiang Lin,Can Wang,Hande Dong,Jiawei Chen*

Main category: cs.AI

TL;DR: ReCreate是一个基于经验的自动领域智能体创建框架，通过智能体交互历史学习成功与失败原因，实现高效智能体生成与优化


<details>
  <summary>Details</summary>
Motivation: 当前大多数实用智能体仍需要人工设计，因为任务差异大且构建成本高。现有自动化方法将智能体生成视为黑盒过程，仅依赖最终性能指标，忽略了成功/失败的关键证据，且计算成本高

Method: 提出智能体即优化器范式，包含三个核心组件：1) 经验存储与检索机制用于按需检查；2) 推理-创建协同管道将执行经验映射到脚手架编辑；3) 分层更新将实例级细节抽象为可重用的领域模式

Result: 在多个不同领域的实验中，ReCreate始终优于人工设计的智能体和现有自动化智能体生成方法，即使从最小种子脚手架开始也能取得良好效果

Conclusion: ReCreate通过系统利用智能体交互历史中的具体信号，实现了更高效、更智能的领域智能体自动创建与适应，解决了现有方法忽略关键证据和计算成本高的问题

Abstract: Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.

</details>


### [7] [Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems](https://arxiv.org/abs/2601.11147)
*Zixu Wang,Bingbing Xu,Yige Yuan,Huawei Shen,Xueqi Cheng*

Main category: cs.AI

TL;DR: SCALE框架通过任务级工作流生成和自预测评估，在保持性能的同时大幅降低多智能体系统的token消耗


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的多智能体系统在工作流生成上存在任务级和查询级两种方法，但它们的相对成本和效益不明确。研究发现查询级工作流生成并非总是必要，而任务级的穷举执行评估既token成本极高又不可靠。

Method: 提出SCALE框架：通过少量样本校准的自预测优化器进行任务级工作流生成，替代昂贵的全验证执行评估。该方法结合自演化和生成式奖励建模思想，实现低成本的任务级工作流优化。

Result: 实验表明SCALE在多个数据集上保持竞争力，平均性能仅下降0.61%，同时将总体token使用量减少高达83%。

Conclusion: 任务级工作流生成配合自预测评估是高效的多智能体系统设计方向，能够在保持性能的同时显著降低计算成本。

Abstract: Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \textbf{SCALE}, which means \underline{\textbf{S}}elf prediction of the optimizer with few shot \underline{\textbf{CAL}}ibration for \underline{\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\%.

</details>


### [8] [TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech](https://arxiv.org/abs/2601.11178)
*Girish A. Koushik,Helen Treharne,Diptesh Kanojia*

Main category: cs.AI

TL;DR: TANDEM框架将音视频仇恨检测从二元分类转变为结构化推理问题，通过跨模态强化学习实现可解释的仇恨内容检测，在目标识别和时间定位方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体上的长格式多模态内容中，有害叙事通过音频、视觉和文本的复杂交互构建。现有的自动化仇恨检测系统虽然准确率高，但缺乏可解释性，无法提供精确的时间戳和目标身份等细粒度证据，难以支持有效的人机协同审核。

Method: 提出TANDEM统一框架，采用新颖的串联强化学习策略，让视觉-语言和音频-语言模型通过自约束的跨模态上下文相互优化，在不需要密集帧级监督的情况下稳定处理长时间序列的推理。

Result: 在三个基准数据集上的实验表明，TANDEM显著优于零样本和上下文增强基线，在HateMM数据集上目标识别F1达到0.73（比现有最佳方法提升30%），同时保持精确的时间定位。二元检测稳健，但在多类别设置中区分冒犯性和仇恨内容仍具挑战性。

Conclusion: 即使在复杂的多模态环境中，结构化、可解释的对齐也是可以实现的，为下一代透明且可操作的在线安全审核工具提供了蓝图。该方法将仇恨检测从黑盒分类转变为可解释的推理过程。

Abstract: Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as "black boxes" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.

</details>


### [9] [Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning](https://arxiv.org/abs/2601.11252)
*Qianyue Wang,Jinwu Hu,Yufeng Wang,Huanxiang Lin,Bolin Chen,Zhiquan Wen,Yaofo Chen,Mingkui Tan*

Main category: cs.AI

TL;DR: Think-with-Me是一种新型的测试时交互式推理范式，通过在推理过程中引入外部反馈干预，解决大型推理模型存在的过度思考和推理偏移问题，在有限上下文窗口中实现准确性和推理长度的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在多步推理方面表现出色，但经常存在推理效率低下的问题，如过度思考和推理偏移，这些低效推理过程会增加计算成本并降低性能。现有的高效推理方法以闭环方式运行，缺乏外部干预机制来指导推理过程。

Method: 提出Think-with-Me范式，核心洞察是过渡连词作为自然干预点，标志着自我验证或探索阶段。系统在这些点暂停推理以获取外部反馈，通过多标准评估（合理性和完整性）生成反馈，使用Group Relative Policy Optimization训练目标模型适应这种交互模式。

Result: 在AIME24上，Think-with-Me在8K窗口下比QwQ-32B准确率提高7.19%，同时平均推理长度减少81%。该范式在有限上下文窗口中实现了准确性和推理长度的优越平衡，同时有益于安全和创造性任务。

Conclusion: Think-with-Me通过引入外部反馈干预的交互式推理范式，有效解决了大型推理模型的低效推理问题，在保持准确性的同时显著减少推理长度，为高效推理提供了新的解决方案。

Abstract: Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.

</details>


### [10] [XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making](https://arxiv.org/abs/2601.11286)
*Weihong Qi,Fan Huang,Rasika Muralidharan,Jisun An,Haewoon Kwak*

Main category: cs.AI

TL;DR: XChoice是一个可解释的框架，用于评估约束决策中AI与人类的对齐程度，超越传统准确率指标，通过机制建模分析决策因素、约束敏感性和权衡关系。


<details>
  <summary>Details</summary>
Motivation: 现有AI评估主要关注结果一致性（如准确率、F1分数），缺乏对决策机制的深入理解，无法诊断AI与人类在约束决策中的根本差异和潜在偏见。

Method: XChoice框架通过拟合基于机制的决策模型到人类数据和LLM生成决策，恢复可解释参数（决策因素重要性、约束敏感性、隐含权衡），通过比较参数向量评估对齐程度。

Result: 在美国时间分配研究中发现模型间对齐存在异质性，黑人和已婚群体中存在显著不对齐；通过不变性分析验证了框架鲁棒性，RAG干预可针对性缓解不对齐问题。

Conclusion: XChoice提供了基于机制的评估指标，能够诊断不对齐问题并支持超越表面结果匹配的改进，为AI与人类对齐提供了更深入的分析工具。

Abstract: We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.

</details>


### [11] [AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems](https://arxiv.org/abs/2601.11354)
*Weiyi Wang,Xinchi Chen,Jingjing Gong,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: AstroReason-Bench是一个用于评估智能体在空间规划问题中规划能力的基准测试，该基准整合了多种调度机制，发现当前智能体在现实约束下的表现远不如专业求解器。


<details>
  <summary>Details</summary>
Motivation: 现有智能体基准主要关注符号化或弱接地环境，而在物理约束的真实世界领域中的性能尚未得到充分探索，特别是在空间规划这类高风险、多目标、严格物理约束和长时程决策的问题上。

Method: 引入AstroReason-Bench基准，整合地面站通信和敏捷地球观测等多种调度机制，提供统一的智能体导向交互协议，并在多种最先进的开放和闭源智能体LLM系统上进行评估。

Result: 评估发现，当前智能体在空间规划问题上的表现显著低于专业求解器，突显了在现实约束下通用规划器的关键局限性。

Conclusion: AstroReason-Bench为未来智能体研究提供了一个具有挑战性和诊断性的测试平台，有助于推动在物理约束真实世界领域中的智能体规划能力发展。

Abstract: Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.

</details>


### [12] [Hyperparameter Optimization of Constraint Programming Solvers](https://arxiv.org/abs/2601.11389)
*Hedieh Haddad,Thibault Falque,Pierre Talbot,Pascal Bouvry*

Main category: cs.AI

TL;DR: 提出"探测与求解"两阶段框架，通过贝叶斯优化自动调优约束规划求解器超参数，在CPMpy库中实现，显著提升求解性能


<details>
  <summary>Details</summary>
Motivation: 约束规划求解器的性能高度依赖超参数设置，手动调优需要专业知识且耗时。需要自动化方法来优化求解器配置，提高求解效率。

Method: 提出两阶段框架：探测阶段使用贝叶斯优化或汉明距离搜索探索超参数配置，求解阶段使用最佳配置解决剩余问题。在CPMpy库中实现并比较两种优化方法。

Result: 贝叶斯优化方法显著优于默认配置：ACE求解器在25.4%实例中提升质量，57.9%持平；Choco求解器在38.6%实例中表现更优。贝叶斯优化也优于汉明距离搜索。

Conclusion: "探测与求解"算法提供了一种实用、资源感知的约束求解器调优方法，通过模型化探索显著提升求解性能，适用于多样化问题类型。

Abstract: The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.
  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.
  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.

</details>


### [13] [Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs](https://arxiv.org/abs/2601.11468)
*Alessandro Padella,Massimiliano de Leoni,Marlon Dumas*

Main category: cs.AI

TL;DR: 本文扩展了基于LLM的预测性流程监控框架，从仅预测总时间扩展到多KPI预测，在数据稀缺场景下（仅100条轨迹）超越基准方法，并验证了LLM利用先验知识和训练轨迹内部相关性的能力。


<details>
  <summary>Details</summary>
Motivation: 预测性流程监控旨在预测正在进行的流程结果，传统方法使用机器学习和深度学习架构。作者先前开发了基于LLM的框架，但仅专注于总时间预测。本文旨在扩展该框架，全面评估其通用性、语义利用和推理机制，并扩展到多个关键绩效指标。

Method: 扩展了先前的LLM-based Predictive Process Monitoring框架，从仅通过提示进行总时间预测扩展到多KPI预测。在三个不同的事件日志上进行实证评估，涵盖总时间和活动发生预测两个KPI。特别关注数据稀缺场景（仅100条训练轨迹），并与基准方法进行比较。

Result: 在数据稀缺设置（仅100条轨迹）下，LLM超越了基准方法。实验表明LLM既利用了其先验知识，也利用了训练轨迹之间的内部相关性。对推理策略的分析显示，LLM不仅仅是复制现有预测方法，而是执行高阶推理来生成预测。

Conclusion: LLM-based Predictive Process Monitoring框架在数据稀缺场景下表现优异，能够有效利用先验知识和数据内部相关性，并通过高阶推理机制生成预测，展示了在预测性流程监控任务中的潜力和优势。

Abstract: Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.

</details>


### [14] [Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning](https://arxiv.org/abs/2601.11479)
*Yohai Trabelsi,Guojun Xiong,Fentabil Getnet,Stéphane Verguet,Milind Tambe*

Main category: cs.AI

TL;DR: 提出LEG框架，结合大语言模型和扩展贪心算法，在资源有限条件下优化埃塞俄比亚卫生站升级决策，平衡人口覆盖与专家偏好


<details>
  <summary>Details</summary>
Motivation: 埃塞俄比亚卫生部升级卫生站以改善基本服务可及性，但资源有限需要优先选择升级设施。传统优化方法需要明确的量化目标，而利益相关者的标准通常用自然语言表达且难以形式化，需要结合专家知识与优化技术

Method: 提出LEG框架：结合具有理论保证的人口覆盖优化近似算法与LLM驱动的迭代精炼，通过人机对齐确保解决方案反映专家定性指导同时保持覆盖保证

Result: 在埃塞俄比亚三个地区的真实数据实验中验证了框架的有效性，展示了其在促进公平、数据驱动的卫生系统规划方面的潜力

Conclusion: LEG框架成功整合专家知识与优化技术，为资源有限的卫生设施升级决策提供了系统方法，能够平衡人口覆盖与多样化的专家和利益相关者偏好

Abstract: Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.

</details>


### [15] [BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics](https://arxiv.org/abs/2601.11492)
*Kaiwen Wang,Kaili Zheng,Rongrong Deng,Qingmin Fan,Milin Zhang,Zongrui Li,Xuesi Zhou,Bo Han,Liren Chen,Chenyi Guo,Ji Wu*

Main category: cs.AI

TL;DR: BoxMind是一个用于拳击战术分析的闭环AI专家系统，通过定义原子击打事件、构建层次化技术战术指标，结合图预测模型和可学习的时间变体嵌入来预测比赛结果并生成战术建议，在2024年巴黎奥运会上成功验证。


<details>
  <summary>Details</summary>
Motivation: 格斗类运动如拳击在AI驱动的战术分析方面发展不足，主要由于动作动态复杂且缺乏结构化战术表示。需要将非结构化视频数据转化为战略智能，弥合计算机视觉与竞技体育决策支持之间的差距。

Method: 1. 定义具有精确时间边界、空间和技术属性的原子击打事件；2. 将比赛视频解析为18个层次化技术战术指标；3. 提出基于图的预测模型，融合显式技术战术特征与可学习的时间变体潜在嵌入；4. 将比赛结果建模为技术战术指标的可微函数，将获胜概率梯度转化为可执行的战术调整。

Result: 1. 结果预测模型在BoxerGraph测试集上达到69.8%准确率，在奥运比赛上达到87.5%准确率；2. 系统生成的战略建议达到与人类专家相当的水平；3. 在2024年巴黎奥运会闭环部署中，直接助力中国国家队获得3金2银的历史性成绩。

Conclusion: BoxMind建立了将非结构化视频数据转化为战略智能的可复制范式，弥合了计算机视觉与竞技体育决策支持之间的差距，为格斗类运动的AI驱动战术分析提供了有效解决方案。

Abstract: Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.

</details>
