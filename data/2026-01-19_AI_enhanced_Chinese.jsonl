{"id": "2601.10738", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10738", "abs": "https://arxiv.org/abs/2601.10738", "authors": ["Percy Jardine"], "title": "CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems", "comment": null, "summary": "Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems.", "AI": {"tldr": "CTHA\u662f\u4e00\u4e2a\u7ea6\u675f\u6027\u65f6\u95f4\u5206\u5c42\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6d41\u5f62\u548c\u4ef2\u88c1\u673a\u5236\u89e3\u51b3\u591a\u65f6\u95f4\u5c3a\u5ea6\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u534f\u8c03\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u6545\u969c\u7ea7\u8054\u5e76\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002", "motivation": "\u591a\u65f6\u95f4\u5c3a\u5ea6\u667a\u80fd\u4f53\u67b6\u6784\u867d\u7136\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4f46\u7834\u574f\u4e86\u7edf\u4e00\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u534f\u8c03\u7a33\u5b9a\u6027\uff0c\u5bfc\u81f4\u4e25\u91cd\u7684\u5c42\u95f4\u51b2\u7a81\u3001\u65e0\u754c\u9519\u8bef\u4f20\u64ad\u548c\u53ef\u6269\u5c55\u6027\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u7ea6\u675f\u6027\u65f6\u95f4\u5206\u5c42\u67b6\u6784\uff08CTHA\uff09\uff0c\u5c06\u5c42\u95f4\u901a\u4fe1\u7a7a\u95f4\u6295\u5f71\u5230\u7ed3\u6784\u5316\u6d41\u5f62\u4e0a\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ea6\u675f\uff1a\u6d88\u606f\u5951\u7ea6\u7ea6\u675f\u3001\u6743\u5a01\u6d41\u5f62\u7ea6\u675f\u548c\u4ef2\u88c1\u89e3\u51b3\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eCTHA\u5728\u590d\u6742\u4efb\u52a1\u6267\u884c\u4e2d\u6709\u6548\uff0c\u76f8\u6bd4\u65e0\u7ea6\u675f\u5206\u5c42\u57fa\u7ebf\uff0c\u6545\u969c\u7ea7\u8054\u51cf\u5c1147%\uff0c\u6837\u672c\u6548\u7387\u63d0\u9ad82.3\u500d\uff0c\u5e76\u5177\u6709\u4f18\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "CTHA\u4f5c\u4e3a\u65f6\u95f4\u5206\u5c42\u67b6\u6784\u7684\u539f\u5219\u6027\u6269\u5c55\uff0c\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u591a\u667a\u80fd\u4f53\u534f\u8c03\uff0c\u5e76\u4e3a\u7a33\u5065\u81ea\u4e3b\u7cfb\u7edf\u7684\u6f14\u8fdb\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2601.10744", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.10744", "abs": "https://arxiv.org/abs/2601.10744", "authors": ["Sen Wang", "Bangwei Liu", "Zhenkun Gao", "Lizhuang Ma", "Xuhong Wang", "Yuan Xie", "Xin Tan"], "title": "Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration", "comment": "Our dataset and code will be released at our \\href{https://wangsen99.github.io/papers/lmee/}{website}", "summary": "An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86LMEE\u6846\u67b6\u548cLMEE-Bench\u57fa\u51c6\uff0c\u901a\u8fc7MemoryExplorer\u65b9\u6cd5\u589e\u5f3a\u667a\u80fd\u4f53\u7684\u957f\u671f\u8bb0\u5fc6\u548c\u4e3b\u52a8\u63a2\u7d22\u80fd\u529b\uff0c\u5728\u957f\u65f6\u7a0b\u5177\u8eab\u4efb\u52a1\u4e2d\u53d6\u5f97\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u4e3b\u6d41\u7684\u4e00\u6b21\u6027\u5177\u8eab\u4efb\u52a1\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u5b8c\u6210\u7ed3\u679c\uff0c\u5ffd\u89c6\u4e86\u63a2\u7d22\u8fc7\u7a0b\u548c\u8bb0\u5fc6\u5229\u7528\u8fd9\u4e00\u5173\u952e\u73af\u8282\u3002\u7406\u60f3\u7684\u5177\u8eab\u667a\u80fd\u4f53\u5e94\u5177\u5907\u7ec8\u8eab\u5b66\u4e60\u80fd\u529b\uff0c\u80fd\u591f\u5229\u7528\u957f\u671f\u60c5\u666f\u8bb0\u5fc6\u4f18\u5316\u51b3\u7b56\uff0c\u5728\u901a\u7528\u73af\u5883\u4e2d\u6301\u7eed\u8fd0\u884c\u3002", "method": "\u63d0\u51faLMEE\u6846\u67b6\u7edf\u4e00\u667a\u80fd\u4f53\u7684\u63a2\u7d22\u8ba4\u77e5\u548c\u51b3\u7b56\u884c\u4e3a\uff1b\u6784\u5efaLMEE-Bench\u6570\u636e\u96c6\u548c\u57fa\u51c6\uff0c\u5305\u542b\u591a\u76ee\u6807\u5bfc\u822a\u548c\u57fa\u4e8e\u8bb0\u5fc6\u7684\u95ee\u7b54\u4efb\u52a1\uff1b\u63d0\u51faMemoryExplorer\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u9f13\u52b1\u4e3b\u52a8\u8bb0\u5fc6\u67e5\u8be2\uff0c\u91c7\u7528\u5305\u542b\u52a8\u4f5c\u9884\u6d4b\u3001\u524d\u6cbf\u9009\u62e9\u548c\u95ee\u7b54\u7684\u591a\u4efb\u52a1\u5956\u52b1\u51fd\u6570\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u7684\u5177\u8eab\u63a2\u7d22\u6a21\u578b\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\u5bf9\u6bd4\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u957f\u65f6\u7a0b\u5177\u8eab\u4efb\u52a1\u4e2d\u53d6\u5f97\u663e\u8457\u4f18\u52bf\uff0c\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u7684\u8bb0\u5fc6\u56de\u5fc6\u548c\u4e3b\u52a8\u63a2\u7d22\u80fd\u529b\u3002", "conclusion": "LMEE\u6846\u67b6\u548cMemoryExplorer\u65b9\u6cd5\u6709\u6548\u4fc3\u8fdb\u4e86\u5177\u8eab\u667a\u80fd\u4f53\u7684\u7ec8\u8eab\u5b66\u4e60\u80fd\u529b\uff0c\u901a\u8fc7\u7edf\u4e00\u63a2\u7d22\u8ba4\u77e5\u548c\u51b3\u7b56\u884c\u4e3a\uff0c\u7ed3\u5408\u4e3b\u52a8\u8bb0\u5fc6\u67e5\u8be2\u673a\u5236\uff0c\u5728\u957f\u65f6\u7a0b\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.10768", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10768", "abs": "https://arxiv.org/abs/2601.10768", "authors": ["Nina Bo\u010dkov\u00e1", "Barbora Voln\u00e1", "Mirko Dohnal"], "title": "Optimisation of complex product innovation processes based on trend models with three-valued logic", "comment": null, "summary": "This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u57fa\u4e8e\u542f\u53d1\u5f0f\u89c4\u5219\u7684\u8d8b\u52bf\u6a21\u578b\u5206\u6790\u590d\u6742\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7b80\u5355\u8d8b\u52bf\uff08\u589e\u52a0\u3001\u51cf\u5c11\u3001\u6052\u5b9a\uff09\u4f5c\u4e3a\u6700\u5c0f\u4fe1\u606f\u5f3a\u5ea6\u91cf\u5316\u5668\uff0c\u907f\u514d\u4f9d\u8d56\u6570\u503c\u6216\u7c97\u7cd9\u96c6\uff0c\u7528\u8f6c\u6362\u56fe\u8868\u793a\u7cfb\u7edf\u53ef\u80fd\u7684\u672a\u6765\u6216\u8fc7\u53bb\u884c\u4e3a\u3002", "motivation": "\u7814\u7a76\u590d\u6742\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\u9700\u8981\u6709\u6548\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u53ef\u80fd\u8fc7\u4e8e\u590d\u6742\u6216\u4e0d\u9002\u7528\uff0c\u9700\u8981\u4e00\u79cd\u7b80\u5355\u4f46\u4fe1\u606f\u4e30\u5bcc\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u521b\u65b0\u52a8\u6001\u3002", "method": "\u57fa\u4e8e\u542f\u53d1\u5f0f\u89c4\u5219\u6784\u5efa\u8d8b\u52bf\u6a21\u578b\uff0c\u6bcf\u4e2a\u542f\u53d1\u5f0f\u901a\u8fc7\u7b80\u5355\u8d8b\u52bf\uff08\u589e\u52a0\u3001\u51cf\u5c11\u3001\u6052\u5b9a\uff09\u8868\u8fbe\uff0c\u4f5c\u4e3a\u6700\u5c0f\u4fe1\u606f\u5f3a\u5ea6\u91cf\u5316\u5668\u3002\u89e3\u51b3\u65b9\u6848\u5b9a\u4e49\u4e3a\u5305\u542b\u53ef\u80fd\u8f6c\u6362\u7684\u573a\u666f\u96c6\u5408\uff0c\u7528\u8f6c\u6362\u56fe\u8868\u793a\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7528\u8f6c\u6362\u56fe\u8868\u793a\u7cfb\u7edf\u884c\u4e3a\u7684\u65b9\u6cd5\uff0c\u4efb\u4f55\u53ef\u80fd\u7684\u672a\u6765\u6216\u8fc7\u53bb\u884c\u4e3a\u90fd\u53ef\u4ee5\u901a\u8fc7\u56fe\u4e2d\u7684\u8def\u5f84\u6765\u63cf\u7ed8\uff0c\u4e3a\u590d\u6742\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u53ef\u89c6\u5316\u5206\u6790\u6846\u67b6\u3002", "conclusion": "\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u8d8b\u52bf\u6a21\u578b\u4e3a\u5206\u6790\u590d\u6742\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b80\u5355\u8d8b\u52bf\u91cf\u5316\u548c\u8f6c\u6362\u56fe\u8868\u793a\uff0c\u80fd\u591f\u6355\u6349\u7cfb\u7edf\u52a8\u6001\u800c\u4e0d\u4f9d\u8d56\u590d\u6742\u6570\u503c\u5206\u6790\u3002"}}
{"id": "2601.10904", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10904", "abs": "https://arxiv.org/abs/2601.10904", "authors": ["Fran\u00e7ois Chollet", "Mike Knoop", "Gregory Kamradt", "Bryan Landers"], "title": "ARC Prize 2025: Technical Report", "comment": null, "summary": "The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.", "AI": {"tldr": "ARC-AGI-2\u7ade\u8d5b\u663e\u793aAI\u5728\u62bd\u8c61\u63a8\u7406\u65b9\u9762\u4ecd\u6709\u5c40\u9650\uff0c\u5f53\u524d\u6700\u4f73\u65b9\u6cd5\u4f9d\u8d56\u8fed\u4ee3\u4f18\u5316\u5faa\u73af\uff0c\u524d\u6cbfAI\u6a21\u578b\u6027\u80fd\u53d7\u77e5\u8bc6\u8986\u76d6\u9650\u5236\uff0c\u5b58\u5728\u57fa\u51c6\u6c61\u67d3\u95ee\u9898\u3002", "motivation": "\u5206\u67902025\u5e74ARC-AGI\u7ade\u8d5b\u7ed3\u679c\uff0c\u7814\u7a76\u5f53\u524dAI\u5728\u62bd\u8c61\u63a8\u7406\u548c\u5c11\u6837\u672c\u6cdb\u5316\u65b9\u9762\u7684\u8fdb\u5c55\u4e0e\u5c40\u9650\uff0c\u63a2\u8ba8\u7cbe\u70bc\u5faa\u73af\u5728AGI\u53d1\u5c55\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u901a\u8fc7\u8c03\u67e5ARC-AGI-2\u7ade\u8d5b\u7684\u9876\u7ea7\u65b9\u6cd5\uff0c\u5206\u6790\u7cbe\u70bc\u5faa\u73af\uff08\u5305\u62ec\u8fdb\u5316\u7a0b\u5e8f\u5408\u6210\u548c\u5546\u4e1aAI\u7cfb\u7edf\u5e94\u7528\u5c42\u4f18\u5316\uff09\u7684\u4f5c\u7528\uff0c\u8bc4\u4f30\u524d\u6cbfAI\u5b9e\u9a8c\u5ba4\u7684\u516c\u5f00\u6027\u80fd\u62a5\u544a\u3002", "result": "\u7ade\u8d5b\u6700\u4f73\u6210\u7ee9\u4ec5\u8fbe24%\uff0c\u7cbe\u70bc\u5faa\u73af\u6210\u4e3a2025\u5e74\u4e3b\u8981\u65b9\u6cd5\uff0c\u524d\u6cbfAI\u6a21\u578b\u6027\u80fd\u53d7\u77e5\u8bc6\u8986\u76d6\u9650\u5236\uff0c\u5b58\u5728\u57fa\u51c6\u6c61\u67d3\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "\u5f53\u524dAI\u62bd\u8c61\u63a8\u7406\u80fd\u529b\u4ecd\u6709\u9650\uff0c\u7cbe\u70bc\u5faa\u73af\u662f\u91cd\u8981\u8fdb\u5c55\u65b9\u5411\uff0c\u4f46\u9700\u89e3\u51b3\u77e5\u8bc6\u4f9d\u8d56\u8fc7\u62df\u5408\u95ee\u9898\uff0cARC-AGI-3\u5c06\u5f15\u5165\u4ea4\u4e92\u5f0f\u63a8\u7406\u6311\u6218\u4ee5\u8bc4\u4f30\u66f4\u5168\u9762\u7684\u667a\u80fd\u80fd\u529b\u3002"}}
{"id": "2601.10922", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10922", "abs": "https://arxiv.org/abs/2601.10922", "authors": ["Yosub Shin", "Michael Buriek", "Boris Sobolev", "Pavel Bushuyeu", "Vikas Kumar", "Haoyang Xu", "Samuel Watson", "Igor Molybog"], "title": "What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge", "comment": null, "summary": "We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7NeurIPS 2025 DCVLR\u6311\u6218\u8d5b\u63a2\u8ba8\u591a\u6a21\u6001\u63a8\u7406\u7684\u6570\u636e\u7b56\u5c55\uff0c\u53d1\u73b0\u57fa\u4e8e\u96be\u5ea6\u7684\u6837\u672c\u9009\u62e9\u662f\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\u56e0\u7d20\uff0c\u800c\u6570\u636e\u96c6\u5927\u5c0f\u589e\u52a0\u4e3b\u8981\u51cf\u5c11\u65b9\u5dee\u800c\u975e\u63d0\u5347\u5e73\u5747\u51c6\u786e\u7387\u3002", "motivation": "\u7814\u7a76\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u6570\u636e\u7b56\u5c55\u95ee\u9898\uff0c\u901a\u8fc7\u56fa\u5b9a\u6a21\u578b\u548c\u8bad\u7ec3\u534f\u8bae\u6765\u9694\u79bb\u6570\u636e\u96c6\u9009\u62e9\u7684\u5f71\u54cd\uff0c\u63a2\u7d22\u5728\u6570\u636e\u6548\u7387\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u4f18\u5316\u591a\u6a21\u6001\u63a8\u7406\u6027\u80fd\u3002", "method": "\u4f7f\u7528NeurIPS 2025 DCVLR\u6311\u6218\u8d5b\u6846\u67b6\uff0c\u56fa\u5b9a\u6a21\u578b\u548c\u8bad\u7ec3\u534f\u8bae\uff0c\u4e3b\u8981\u57fa\u4e8eWalton Multimodal Cold Start\u6784\u5efa\u7d27\u51d1\u7684\u7b56\u5c55\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u8d5b\u540e\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u4e0d\u540c\u6570\u636e\u7b56\u5c55\u7b56\u7565\u7684\u6548\u679c\u3002", "result": "\u57fa\u4e8e\u96be\u5ea6\u7684\u6837\u672c\u9009\u62e9\u5728\u5df2\u5bf9\u9f50\u7684\u57fa\u7840\u6570\u636e\u96c6\u4e0a\u662f\u6027\u80fd\u63d0\u5347\u7684\u4e3b\u8981\u9a71\u52a8\u529b\uff1b\u589e\u52a0\u6570\u636e\u96c6\u5927\u5c0f\u4e0d\u80fd\u53ef\u9760\u63d0\u9ad8\u5e73\u5747\u51c6\u786e\u7387\uff0c\u4f46\u80fd\u51cf\u5c11\u8fd0\u884c\u65b9\u5dee\uff1b\u5e38\u7528\u7684\u591a\u6837\u6027\u548c\u5408\u6210\u589e\u5f3a\u542f\u53d1\u5f0f\u65b9\u6cd5\u6ca1\u6709\u989d\u5916\u76ca\u5904\uff0c\u53cd\u800c\u53ef\u80fd\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "DCVLR\u662f\u4e00\u4e2a\u9971\u548c\u72b6\u6001\u8bc4\u4f30\uff0c\u5f3a\u8c03\u4e86\u5bf9\u9f50\u548c\u96be\u5ea6\u5728\u6570\u636e\u9ad8\u6548\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u4e3a\u591a\u6a21\u6001\u6570\u636e\u7b56\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2601.11100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11100", "abs": "https://arxiv.org/abs/2601.11100", "authors": ["Zhezheng Hao", "Hong Wang", "Jian Luo", "Jianqing Zhang", "Yuyan Zhou", "Qiang Lin", "Can Wang", "Hande Dong", "Jiawei Chen"], "title": "ReCreate: Reasoning and Creating Domain Agents Driven by Experience", "comment": null, "summary": "Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds.", "AI": {"tldr": "ReCreate\u662f\u4e00\u4e2a\u57fa\u4e8e\u7ecf\u9a8c\u7684\u81ea\u52a8\u9886\u57df\u667a\u80fd\u4f53\u521b\u5efa\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u4ea4\u4e92\u5386\u53f2\u5b66\u4e60\u6210\u529f\u4e0e\u5931\u8d25\u539f\u56e0\uff0c\u5b9e\u73b0\u9ad8\u6548\u667a\u80fd\u4f53\u751f\u6210\u4e0e\u4f18\u5316", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u5b9e\u7528\u667a\u80fd\u4f53\u4ecd\u9700\u8981\u4eba\u5de5\u8bbe\u8ba1\uff0c\u56e0\u4e3a\u4efb\u52a1\u5dee\u5f02\u5927\u4e14\u6784\u5efa\u6210\u672c\u9ad8\u3002\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u5c06\u667a\u80fd\u4f53\u751f\u6210\u89c6\u4e3a\u9ed1\u76d2\u8fc7\u7a0b\uff0c\u4ec5\u4f9d\u8d56\u6700\u7ec8\u6027\u80fd\u6307\u6807\uff0c\u5ffd\u7565\u4e86\u6210\u529f/\u5931\u8d25\u7684\u5173\u952e\u8bc1\u636e\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8", "method": "\u63d0\u51fa\u667a\u80fd\u4f53\u5373\u4f18\u5316\u5668\u8303\u5f0f\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u7ecf\u9a8c\u5b58\u50a8\u4e0e\u68c0\u7d22\u673a\u5236\u7528\u4e8e\u6309\u9700\u68c0\u67e5\uff1b2) \u63a8\u7406-\u521b\u5efa\u534f\u540c\u7ba1\u9053\u5c06\u6267\u884c\u7ecf\u9a8c\u6620\u5c04\u5230\u811a\u624b\u67b6\u7f16\u8f91\uff1b3) \u5206\u5c42\u66f4\u65b0\u5c06\u5b9e\u4f8b\u7ea7\u7ec6\u8282\u62bd\u8c61\u4e3a\u53ef\u91cd\u7528\u7684\u9886\u57df\u6a21\u5f0f", "result": "\u5728\u591a\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u5b9e\u9a8c\u4e2d\uff0cReCreate\u59cb\u7ec8\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u7684\u667a\u80fd\u4f53\u548c\u73b0\u6709\u81ea\u52a8\u5316\u667a\u80fd\u4f53\u751f\u6210\u65b9\u6cd5\uff0c\u5373\u4f7f\u4ece\u6700\u5c0f\u79cd\u5b50\u811a\u624b\u67b6\u5f00\u59cb\u4e5f\u80fd\u53d6\u5f97\u826f\u597d\u6548\u679c", "conclusion": "ReCreate\u901a\u8fc7\u7cfb\u7edf\u5229\u7528\u667a\u80fd\u4f53\u4ea4\u4e92\u5386\u53f2\u4e2d\u7684\u5177\u4f53\u4fe1\u53f7\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u667a\u80fd\u7684\u9886\u57df\u667a\u80fd\u4f53\u81ea\u52a8\u521b\u5efa\u4e0e\u9002\u5e94\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u5173\u952e\u8bc1\u636e\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898"}}
{"id": "2601.11147", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11147", "abs": "https://arxiv.org/abs/2601.11147", "authors": ["Zixu Wang", "Bingbing Xu", "Yige Yuan", "Huawei Shen", "Xueqi Cheng"], "title": "Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems", "comment": "17 pages, 4 figures, 3 tables", "summary": "Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \\textbf{SCALE}, which means \\underline{\\textbf{S}}elf prediction of the optimizer with few shot \\underline{\\textbf{CAL}}ibration for \\underline{\\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \\textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\\%.", "AI": {"tldr": "SCALE\u6846\u67b6\u901a\u8fc7\u4efb\u52a1\u7ea7\u5de5\u4f5c\u6d41\u751f\u6210\u548c\u81ea\u9884\u6d4b\u8bc4\u4f30\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684token\u6d88\u8017", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u5de5\u4f5c\u6d41\u751f\u6210\u4e0a\u5b58\u5728\u4efb\u52a1\u7ea7\u548c\u67e5\u8be2\u7ea7\u4e24\u79cd\u65b9\u6cd5\uff0c\u4f46\u5b83\u4eec\u7684\u76f8\u5bf9\u6210\u672c\u548c\u6548\u76ca\u4e0d\u660e\u786e\u3002\u7814\u7a76\u53d1\u73b0\u67e5\u8be2\u7ea7\u5de5\u4f5c\u6d41\u751f\u6210\u5e76\u975e\u603b\u662f\u5fc5\u8981\uff0c\u800c\u4efb\u52a1\u7ea7\u7684\u7a77\u4e3e\u6267\u884c\u8bc4\u4f30\u65e2token\u6210\u672c\u6781\u9ad8\u53c8\u4e0d\u53ef\u9760\u3002", "method": "\u63d0\u51faSCALE\u6846\u67b6\uff1a\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u6821\u51c6\u7684\u81ea\u9884\u6d4b\u4f18\u5316\u5668\u8fdb\u884c\u4efb\u52a1\u7ea7\u5de5\u4f5c\u6d41\u751f\u6210\uff0c\u66ff\u4ee3\u6602\u8d35\u7684\u5168\u9a8c\u8bc1\u6267\u884c\u8bc4\u4f30\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u81ea\u6f14\u5316\u548c\u751f\u6210\u5f0f\u5956\u52b1\u5efa\u6a21\u601d\u60f3\uff0c\u5b9e\u73b0\u4f4e\u6210\u672c\u7684\u4efb\u52a1\u7ea7\u5de5\u4f5c\u6d41\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSCALE\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u5e73\u5747\u6027\u80fd\u4ec5\u4e0b\u964d0.61%\uff0c\u540c\u65f6\u5c06\u603b\u4f53token\u4f7f\u7528\u91cf\u51cf\u5c11\u9ad8\u8fbe83%\u3002", "conclusion": "\u4efb\u52a1\u7ea7\u5de5\u4f5c\u6d41\u751f\u6210\u914d\u5408\u81ea\u9884\u6d4b\u8bc4\u4f30\u662f\u9ad8\u6548\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u5411\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2601.11178", "categories": ["cs.AI", "cs.CL", "cs.MM", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11178", "abs": "https://arxiv.org/abs/2601.11178", "authors": ["Girish A. Koushik", "Helen Treharne", "Diptesh Kanojia"], "title": "TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech", "comment": "Under review at ICWSM 2026", "summary": "Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as \"black boxes\" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.", "AI": {"tldr": "TANDEM\u6846\u67b6\u5c06\u97f3\u89c6\u9891\u4ec7\u6068\u68c0\u6d4b\u4ece\u4e8c\u5143\u5206\u7c7b\u8f6c\u53d8\u4e3a\u7ed3\u6784\u5316\u63a8\u7406\u95ee\u9898\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u4ec7\u6068\u5185\u5bb9\u68c0\u6d4b\uff0c\u5728\u76ee\u6807\u8bc6\u522b\u548c\u65f6\u95f4\u5b9a\u4f4d\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u957f\u683c\u5f0f\u591a\u6a21\u6001\u5185\u5bb9\u4e2d\uff0c\u6709\u5bb3\u53d9\u4e8b\u901a\u8fc7\u97f3\u9891\u3001\u89c6\u89c9\u548c\u6587\u672c\u7684\u590d\u6742\u4ea4\u4e92\u6784\u5efa\u3002\u73b0\u6709\u7684\u81ea\u52a8\u5316\u4ec7\u6068\u68c0\u6d4b\u7cfb\u7edf\u867d\u7136\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u65e0\u6cd5\u63d0\u4f9b\u7cbe\u786e\u7684\u65f6\u95f4\u6233\u548c\u76ee\u6807\u8eab\u4efd\u7b49\u7ec6\u7c92\u5ea6\u8bc1\u636e\uff0c\u96be\u4ee5\u652f\u6301\u6709\u6548\u7684\u4eba\u673a\u534f\u540c\u5ba1\u6838\u3002", "method": "\u63d0\u51faTANDEM\u7edf\u4e00\u6846\u67b6\uff0c\u91c7\u7528\u65b0\u9896\u7684\u4e32\u8054\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u8ba9\u89c6\u89c9-\u8bed\u8a00\u548c\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u81ea\u7ea6\u675f\u7684\u8de8\u6a21\u6001\u4e0a\u4e0b\u6587\u76f8\u4e92\u4f18\u5316\uff0c\u5728\u4e0d\u9700\u8981\u5bc6\u96c6\u5e27\u7ea7\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u7a33\u5b9a\u5904\u7406\u957f\u65f6\u95f4\u5e8f\u5217\u7684\u63a8\u7406\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTANDEM\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c\u548c\u4e0a\u4e0b\u6587\u589e\u5f3a\u57fa\u7ebf\uff0c\u5728HateMM\u6570\u636e\u96c6\u4e0a\u76ee\u6807\u8bc6\u522bF1\u8fbe\u52300.73\uff08\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u63d0\u534730%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u7cbe\u786e\u7684\u65f6\u95f4\u5b9a\u4f4d\u3002\u4e8c\u5143\u68c0\u6d4b\u7a33\u5065\uff0c\u4f46\u5728\u591a\u7c7b\u522b\u8bbe\u7f6e\u4e2d\u533a\u5206\u5192\u72af\u6027\u548c\u4ec7\u6068\u5185\u5bb9\u4ecd\u5177\u6311\u6218\u6027\u3002", "conclusion": "\u5373\u4f7f\u5728\u590d\u6742\u7684\u591a\u6a21\u6001\u73af\u5883\u4e2d\uff0c\u7ed3\u6784\u5316\u3001\u53ef\u89e3\u91ca\u7684\u5bf9\u9f50\u4e5f\u662f\u53ef\u4ee5\u5b9e\u73b0\u7684\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u900f\u660e\u4e14\u53ef\u64cd\u4f5c\u7684\u5728\u7ebf\u5b89\u5168\u5ba1\u6838\u5de5\u5177\u63d0\u4f9b\u4e86\u84dd\u56fe\u3002\u8be5\u65b9\u6cd5\u5c06\u4ec7\u6068\u68c0\u6d4b\u4ece\u9ed1\u76d2\u5206\u7c7b\u8f6c\u53d8\u4e3a\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8fc7\u7a0b\u3002"}}
{"id": "2601.11252", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11252", "abs": "https://arxiv.org/abs/2601.11252", "authors": ["Qianyue Wang", "Jinwu Hu", "Yufeng Wang", "Huanxiang Lin", "Bolin Chen", "Zhiquan Wen", "Yaofo Chen", "Mingkui Tan"], "title": "Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning", "comment": null, "summary": "Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.", "AI": {"tldr": "Think-with-Me\u662f\u4e00\u79cd\u65b0\u578b\u7684\u6d4b\u8bd5\u65f6\u4ea4\u4e92\u5f0f\u63a8\u7406\u8303\u5f0f\uff0c\u901a\u8fc7\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5f15\u5165\u5916\u90e8\u53cd\u9988\u5e72\u9884\uff0c\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b58\u5728\u7684\u8fc7\u5ea6\u601d\u8003\u548c\u63a8\u7406\u504f\u79fb\u95ee\u9898\uff0c\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e2d\u5b9e\u73b0\u51c6\u786e\u6027\u548c\u63a8\u7406\u957f\u5ea6\u7684\u6700\u4f73\u5e73\u8861\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u591a\u6b65\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7ecf\u5e38\u5b58\u5728\u63a8\u7406\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u5982\u8fc7\u5ea6\u601d\u8003\u548c\u63a8\u7406\u504f\u79fb\uff0c\u8fd9\u4e9b\u4f4e\u6548\u63a8\u7406\u8fc7\u7a0b\u4f1a\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u5e76\u964d\u4f4e\u6027\u80fd\u3002\u73b0\u6709\u7684\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5\u4ee5\u95ed\u73af\u65b9\u5f0f\u8fd0\u884c\uff0c\u7f3a\u4e4f\u5916\u90e8\u5e72\u9884\u673a\u5236\u6765\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faThink-with-Me\u8303\u5f0f\uff0c\u6838\u5fc3\u6d1e\u5bdf\u662f\u8fc7\u6e21\u8fde\u8bcd\u4f5c\u4e3a\u81ea\u7136\u5e72\u9884\u70b9\uff0c\u6807\u5fd7\u7740\u81ea\u6211\u9a8c\u8bc1\u6216\u63a2\u7d22\u9636\u6bb5\u3002\u7cfb\u7edf\u5728\u8fd9\u4e9b\u70b9\u6682\u505c\u63a8\u7406\u4ee5\u83b7\u53d6\u5916\u90e8\u53cd\u9988\uff0c\u901a\u8fc7\u591a\u6807\u51c6\u8bc4\u4f30\uff08\u5408\u7406\u6027\u548c\u5b8c\u6574\u6027\uff09\u751f\u6210\u53cd\u9988\uff0c\u4f7f\u7528Group Relative Policy Optimization\u8bad\u7ec3\u76ee\u6807\u6a21\u578b\u9002\u5e94\u8fd9\u79cd\u4ea4\u4e92\u6a21\u5f0f\u3002", "result": "\u5728AIME24\u4e0a\uff0cThink-with-Me\u57288K\u7a97\u53e3\u4e0b\u6bd4QwQ-32B\u51c6\u786e\u7387\u63d0\u9ad87.19%\uff0c\u540c\u65f6\u5e73\u5747\u63a8\u7406\u957f\u5ea6\u51cf\u5c1181%\u3002\u8be5\u8303\u5f0f\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e2d\u5b9e\u73b0\u4e86\u51c6\u786e\u6027\u548c\u63a8\u7406\u957f\u5ea6\u7684\u4f18\u8d8a\u5e73\u8861\uff0c\u540c\u65f6\u6709\u76ca\u4e8e\u5b89\u5168\u548c\u521b\u9020\u6027\u4efb\u52a1\u3002", "conclusion": "Think-with-Me\u901a\u8fc7\u5f15\u5165\u5916\u90e8\u53cd\u9988\u5e72\u9884\u7684\u4ea4\u4e92\u5f0f\u63a8\u7406\u8303\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u4f4e\u6548\u63a8\u7406\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u63a8\u7406\u957f\u5ea6\uff0c\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11286", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11286", "abs": "https://arxiv.org/abs/2601.11286", "authors": ["Weihong Qi", "Fan Huang", "Rasika Muralidharan", "Jisun An", "Haewoon Kwak"], "title": "XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making", "comment": null, "summary": "We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.", "AI": {"tldr": "XChoice\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u7ea6\u675f\u51b3\u7b56\u4e2dAI\u4e0e\u4eba\u7c7b\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u8d85\u8d8a\u4f20\u7edf\u51c6\u786e\u7387\u6307\u6807\uff0c\u901a\u8fc7\u673a\u5236\u5efa\u6a21\u5206\u6790\u51b3\u7b56\u56e0\u7d20\u3001\u7ea6\u675f\u654f\u611f\u6027\u548c\u6743\u8861\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709AI\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u7ed3\u679c\u4e00\u81f4\u6027\uff08\u5982\u51c6\u786e\u7387\u3001F1\u5206\u6570\uff09\uff0c\u7f3a\u4e4f\u5bf9\u51b3\u7b56\u673a\u5236\u7684\u6df1\u5165\u7406\u89e3\uff0c\u65e0\u6cd5\u8bca\u65adAI\u4e0e\u4eba\u7c7b\u5728\u7ea6\u675f\u51b3\u7b56\u4e2d\u7684\u6839\u672c\u5dee\u5f02\u548c\u6f5c\u5728\u504f\u89c1\u3002", "method": "XChoice\u6846\u67b6\u901a\u8fc7\u62df\u5408\u57fa\u4e8e\u673a\u5236\u7684\u51b3\u7b56\u6a21\u578b\u5230\u4eba\u7c7b\u6570\u636e\u548cLLM\u751f\u6210\u51b3\u7b56\uff0c\u6062\u590d\u53ef\u89e3\u91ca\u53c2\u6570\uff08\u51b3\u7b56\u56e0\u7d20\u91cd\u8981\u6027\u3001\u7ea6\u675f\u654f\u611f\u6027\u3001\u9690\u542b\u6743\u8861\uff09\uff0c\u901a\u8fc7\u6bd4\u8f83\u53c2\u6570\u5411\u91cf\u8bc4\u4f30\u5bf9\u9f50\u7a0b\u5ea6\u3002", "result": "\u5728\u7f8e\u56fd\u65f6\u95f4\u5206\u914d\u7814\u7a76\u4e2d\u53d1\u73b0\u6a21\u578b\u95f4\u5bf9\u9f50\u5b58\u5728\u5f02\u8d28\u6027\uff0c\u9ed1\u4eba\u548c\u5df2\u5a5a\u7fa4\u4f53\u4e2d\u5b58\u5728\u663e\u8457\u4e0d\u5bf9\u9f50\uff1b\u901a\u8fc7\u4e0d\u53d8\u6027\u5206\u6790\u9a8c\u8bc1\u4e86\u6846\u67b6\u9c81\u68d2\u6027\uff0cRAG\u5e72\u9884\u53ef\u9488\u5bf9\u6027\u7f13\u89e3\u4e0d\u5bf9\u9f50\u95ee\u9898\u3002", "conclusion": "XChoice\u63d0\u4f9b\u4e86\u57fa\u4e8e\u673a\u5236\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u80fd\u591f\u8bca\u65ad\u4e0d\u5bf9\u9f50\u95ee\u9898\u5e76\u652f\u6301\u8d85\u8d8a\u8868\u9762\u7ed3\u679c\u5339\u914d\u7684\u6539\u8fdb\uff0c\u4e3aAI\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2601.11354", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11354", "abs": "https://arxiv.org/abs/2601.11354", "authors": ["Weiyi Wang", "Xinchi Chen", "Jingjing Gong", "Xuanjing Huang", "Xipeng Qiu"], "title": "AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems", "comment": null, "summary": "Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research.", "AI": {"tldr": "AstroReason-Bench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u7a7a\u95f4\u89c4\u5212\u95ee\u9898\u4e2d\u89c4\u5212\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8be5\u57fa\u51c6\u6574\u5408\u4e86\u591a\u79cd\u8c03\u5ea6\u673a\u5236\uff0c\u53d1\u73b0\u5f53\u524d\u667a\u80fd\u4f53\u5728\u73b0\u5b9e\u7ea6\u675f\u4e0b\u7684\u8868\u73b0\u8fdc\u4e0d\u5982\u4e13\u4e1a\u6c42\u89e3\u5668\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u7b26\u53f7\u5316\u6216\u5f31\u63a5\u5730\u73af\u5883\uff0c\u800c\u5728\u7269\u7406\u7ea6\u675f\u7684\u771f\u5b9e\u4e16\u754c\u9886\u57df\u4e2d\u7684\u6027\u80fd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u7279\u522b\u662f\u5728\u7a7a\u95f4\u89c4\u5212\u8fd9\u7c7b\u9ad8\u98ce\u9669\u3001\u591a\u76ee\u6807\u3001\u4e25\u683c\u7269\u7406\u7ea6\u675f\u548c\u957f\u65f6\u7a0b\u51b3\u7b56\u7684\u95ee\u9898\u4e0a\u3002", "method": "\u5f15\u5165AstroReason-Bench\u57fa\u51c6\uff0c\u6574\u5408\u5730\u9762\u7ad9\u901a\u4fe1\u548c\u654f\u6377\u5730\u7403\u89c2\u6d4b\u7b49\u591a\u79cd\u8c03\u5ea6\u673a\u5236\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u667a\u80fd\u4f53\u5bfc\u5411\u4ea4\u4e92\u534f\u8bae\uff0c\u5e76\u5728\u591a\u79cd\u6700\u5148\u8fdb\u7684\u5f00\u653e\u548c\u95ed\u6e90\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0\uff0c\u5f53\u524d\u667a\u80fd\u4f53\u5728\u7a7a\u95f4\u89c4\u5212\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u663e\u8457\u4f4e\u4e8e\u4e13\u4e1a\u6c42\u89e3\u5668\uff0c\u7a81\u663e\u4e86\u5728\u73b0\u5b9e\u7ea6\u675f\u4e0b\u901a\u7528\u89c4\u5212\u5668\u7684\u5173\u952e\u5c40\u9650\u6027\u3002", "conclusion": "AstroReason-Bench\u4e3a\u672a\u6765\u667a\u80fd\u4f53\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u548c\u8bca\u65ad\u6027\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u5728\u7269\u7406\u7ea6\u675f\u771f\u5b9e\u4e16\u754c\u9886\u57df\u4e2d\u7684\u667a\u80fd\u4f53\u89c4\u5212\u80fd\u529b\u53d1\u5c55\u3002"}}
{"id": "2601.11389", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11389", "abs": "https://arxiv.org/abs/2601.11389", "authors": ["Hedieh Haddad", "Thibault Falque", "Pierre Talbot", "Pascal Bouvry"], "title": "Hyperparameter Optimization of Constraint Programming Solvers", "comment": "28 pages, 3 figures. Submitted to Journal of Combinatorial Optimization. Special Issue: Recent applications, models and algorithms in Combinatorial Optimization", "summary": "The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.\n  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.\n  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.", "AI": {"tldr": "\u63d0\u51fa\"\u63a2\u6d4b\u4e0e\u6c42\u89e3\"\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u81ea\u52a8\u8c03\u4f18\u7ea6\u675f\u89c4\u5212\u6c42\u89e3\u5668\u8d85\u53c2\u6570\uff0c\u5728CPMpy\u5e93\u4e2d\u5b9e\u73b0\uff0c\u663e\u8457\u63d0\u5347\u6c42\u89e3\u6027\u80fd", "motivation": "\u7ea6\u675f\u89c4\u5212\u6c42\u89e3\u5668\u7684\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u8d85\u53c2\u6570\u8bbe\u7f6e\uff0c\u624b\u52a8\u8c03\u4f18\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u4e14\u8017\u65f6\u3002\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u4f18\u5316\u6c42\u89e3\u5668\u914d\u7f6e\uff0c\u63d0\u9ad8\u6c42\u89e3\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u63a2\u6d4b\u9636\u6bb5\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u6216\u6c49\u660e\u8ddd\u79bb\u641c\u7d22\u63a2\u7d22\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u6c42\u89e3\u9636\u6bb5\u4f7f\u7528\u6700\u4f73\u914d\u7f6e\u89e3\u51b3\u5269\u4f59\u95ee\u9898\u3002\u5728CPMpy\u5e93\u4e2d\u5b9e\u73b0\u5e76\u6bd4\u8f83\u4e24\u79cd\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u9ed8\u8ba4\u914d\u7f6e\uff1aACE\u6c42\u89e3\u5668\u572825.4%\u5b9e\u4f8b\u4e2d\u63d0\u5347\u8d28\u91cf\uff0c57.9%\u6301\u5e73\uff1bChoco\u6c42\u89e3\u5668\u572838.6%\u5b9e\u4f8b\u4e2d\u8868\u73b0\u66f4\u4f18\u3002\u8d1d\u53f6\u65af\u4f18\u5316\u4e5f\u4f18\u4e8e\u6c49\u660e\u8ddd\u79bb\u641c\u7d22\u3002", "conclusion": "\"\u63a2\u6d4b\u4e0e\u6c42\u89e3\"\u7b97\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u3001\u8d44\u6e90\u611f\u77e5\u7684\u7ea6\u675f\u6c42\u89e3\u5668\u8c03\u4f18\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u5316\u63a2\u7d22\u663e\u8457\u63d0\u5347\u6c42\u89e3\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u95ee\u9898\u7c7b\u578b\u3002"}}
{"id": "2601.11468", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11468", "abs": "https://arxiv.org/abs/2601.11468", "authors": ["Alessandro Padella", "Massimiliano de Leoni", "Marlon Dumas"], "title": "Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs", "comment": "19 pages, 4 figure, TMIS journal submission", "summary": "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u57fa\u4e8eLLM\u7684\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\u6846\u67b6\uff0c\u4ece\u4ec5\u9884\u6d4b\u603b\u65f6\u95f4\u6269\u5c55\u5230\u591aKPI\u9884\u6d4b\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\uff08\u4ec5100\u6761\u8f68\u8ff9\uff09\u8d85\u8d8a\u57fa\u51c6\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u4e86LLM\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u548c\u8bad\u7ec3\u8f68\u8ff9\u5185\u90e8\u76f8\u5173\u6027\u7684\u80fd\u529b\u3002", "motivation": "\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\u65e8\u5728\u9884\u6d4b\u6b63\u5728\u8fdb\u884c\u7684\u6d41\u7a0b\u7ed3\u679c\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u3002\u4f5c\u8005\u5148\u524d\u5f00\u53d1\u4e86\u57fa\u4e8eLLM\u7684\u6846\u67b6\uff0c\u4f46\u4ec5\u4e13\u6ce8\u4e8e\u603b\u65f6\u95f4\u9884\u6d4b\u3002\u672c\u6587\u65e8\u5728\u6269\u5c55\u8be5\u6846\u67b6\uff0c\u5168\u9762\u8bc4\u4f30\u5176\u901a\u7528\u6027\u3001\u8bed\u4e49\u5229\u7528\u548c\u63a8\u7406\u673a\u5236\uff0c\u5e76\u6269\u5c55\u5230\u591a\u4e2a\u5173\u952e\u7ee9\u6548\u6307\u6807\u3002", "method": "\u6269\u5c55\u4e86\u5148\u524d\u7684LLM-based Predictive Process Monitoring\u6846\u67b6\uff0c\u4ece\u4ec5\u901a\u8fc7\u63d0\u793a\u8fdb\u884c\u603b\u65f6\u95f4\u9884\u6d4b\u6269\u5c55\u5230\u591aKPI\u9884\u6d4b\u3002\u5728\u4e09\u4e2a\u4e0d\u540c\u7684\u4e8b\u4ef6\u65e5\u5fd7\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u6db5\u76d6\u603b\u65f6\u95f4\u548c\u6d3b\u52a8\u53d1\u751f\u9884\u6d4b\u4e24\u4e2aKPI\u3002\u7279\u522b\u5173\u6ce8\u6570\u636e\u7a00\u7f3a\u573a\u666f\uff08\u4ec5100\u6761\u8bad\u7ec3\u8f68\u8ff9\uff09\uff0c\u5e76\u4e0e\u57fa\u51c6\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u6570\u636e\u7a00\u7f3a\u8bbe\u7f6e\uff08\u4ec5100\u6761\u8f68\u8ff9\uff09\u4e0b\uff0cLLM\u8d85\u8d8a\u4e86\u57fa\u51c6\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8868\u660eLLM\u65e2\u5229\u7528\u4e86\u5176\u5148\u9a8c\u77e5\u8bc6\uff0c\u4e5f\u5229\u7528\u4e86\u8bad\u7ec3\u8f68\u8ff9\u4e4b\u95f4\u7684\u5185\u90e8\u76f8\u5173\u6027\u3002\u5bf9\u63a8\u7406\u7b56\u7565\u7684\u5206\u6790\u663e\u793a\uff0cLLM\u4e0d\u4ec5\u4ec5\u662f\u590d\u5236\u73b0\u6709\u9884\u6d4b\u65b9\u6cd5\uff0c\u800c\u662f\u6267\u884c\u9ad8\u9636\u63a8\u7406\u6765\u751f\u6210\u9884\u6d4b\u3002", "conclusion": "LLM-based Predictive Process Monitoring\u6846\u67b6\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u548c\u6570\u636e\u5185\u90e8\u76f8\u5173\u6027\uff0c\u5e76\u901a\u8fc7\u9ad8\u9636\u63a8\u7406\u673a\u5236\u751f\u6210\u9884\u6d4b\uff0c\u5c55\u793a\u4e86\u5728\u9884\u6d4b\u6027\u6d41\u7a0b\u76d1\u63a7\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u548c\u4f18\u52bf\u3002"}}
{"id": "2601.11479", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11479", "abs": "https://arxiv.org/abs/2601.11479", "authors": ["Yohai Trabelsi", "Guojun Xiong", "Fentabil Getnet", "St\u00e9phane Verguet", "Milind Tambe"], "title": "Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning", "comment": null, "summary": "Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.", "AI": {"tldr": "\u63d0\u51faLEG\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6269\u5c55\u8d2a\u5fc3\u7b97\u6cd5\uff0c\u5728\u8d44\u6e90\u6709\u9650\u6761\u4ef6\u4e0b\u4f18\u5316\u57c3\u585e\u4fc4\u6bd4\u4e9a\u536b\u751f\u7ad9\u5347\u7ea7\u51b3\u7b56\uff0c\u5e73\u8861\u4eba\u53e3\u8986\u76d6\u4e0e\u4e13\u5bb6\u504f\u597d", "motivation": "\u57c3\u585e\u4fc4\u6bd4\u4e9a\u536b\u751f\u90e8\u5347\u7ea7\u536b\u751f\u7ad9\u4ee5\u6539\u5584\u57fa\u672c\u670d\u52a1\u53ef\u53ca\u6027\uff0c\u4f46\u8d44\u6e90\u6709\u9650\u9700\u8981\u4f18\u5148\u9009\u62e9\u5347\u7ea7\u8bbe\u65bd\u3002\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u9700\u8981\u660e\u786e\u7684\u91cf\u5316\u76ee\u6807\uff0c\u800c\u5229\u76ca\u76f8\u5173\u8005\u7684\u6807\u51c6\u901a\u5e38\u7528\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u4e14\u96be\u4ee5\u5f62\u5f0f\u5316\uff0c\u9700\u8981\u7ed3\u5408\u4e13\u5bb6\u77e5\u8bc6\u4e0e\u4f18\u5316\u6280\u672f", "method": "\u63d0\u51faLEG\u6846\u67b6\uff1a\u7ed3\u5408\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u4eba\u53e3\u8986\u76d6\u4f18\u5316\u8fd1\u4f3c\u7b97\u6cd5\u4e0eLLM\u9a71\u52a8\u7684\u8fed\u4ee3\u7cbe\u70bc\uff0c\u901a\u8fc7\u4eba\u673a\u5bf9\u9f50\u786e\u4fdd\u89e3\u51b3\u65b9\u6848\u53cd\u6620\u4e13\u5bb6\u5b9a\u6027\u6307\u5bfc\u540c\u65f6\u4fdd\u6301\u8986\u76d6\u4fdd\u8bc1", "result": "\u5728\u57c3\u585e\u4fc4\u6bd4\u4e9a\u4e09\u4e2a\u5730\u533a\u7684\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4fc3\u8fdb\u516c\u5e73\u3001\u6570\u636e\u9a71\u52a8\u7684\u536b\u751f\u7cfb\u7edf\u89c4\u5212\u65b9\u9762\u7684\u6f5c\u529b", "conclusion": "LEG\u6846\u67b6\u6210\u529f\u6574\u5408\u4e13\u5bb6\u77e5\u8bc6\u4e0e\u4f18\u5316\u6280\u672f\uff0c\u4e3a\u8d44\u6e90\u6709\u9650\u7684\u536b\u751f\u8bbe\u65bd\u5347\u7ea7\u51b3\u7b56\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0c\u80fd\u591f\u5e73\u8861\u4eba\u53e3\u8986\u76d6\u4e0e\u591a\u6837\u5316\u7684\u4e13\u5bb6\u548c\u5229\u76ca\u76f8\u5173\u8005\u504f\u597d"}}
{"id": "2601.11492", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11492", "abs": "https://arxiv.org/abs/2601.11492", "authors": ["Kaiwen Wang", "Kaili Zheng", "Rongrong Deng", "Qingmin Fan", "Milin Zhang", "Zongrui Li", "Xuesi Zhou", "Bo Han", "Liren Chen", "Chenyi Guo", "Ji Wu"], "title": "BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics", "comment": null, "summary": "Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.", "AI": {"tldr": "BoxMind\u662f\u4e00\u4e2a\u7528\u4e8e\u62f3\u51fb\u6218\u672f\u5206\u6790\u7684\u95ed\u73afAI\u4e13\u5bb6\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b9a\u4e49\u539f\u5b50\u51fb\u6253\u4e8b\u4ef6\u3001\u6784\u5efa\u5c42\u6b21\u5316\u6280\u672f\u6218\u672f\u6307\u6807\uff0c\u7ed3\u5408\u56fe\u9884\u6d4b\u6a21\u578b\u548c\u53ef\u5b66\u4e60\u7684\u65f6\u95f4\u53d8\u4f53\u5d4c\u5165\u6765\u9884\u6d4b\u6bd4\u8d5b\u7ed3\u679c\u5e76\u751f\u6210\u6218\u672f\u5efa\u8bae\uff0c\u57282024\u5e74\u5df4\u9ece\u5965\u8fd0\u4f1a\u4e0a\u6210\u529f\u9a8c\u8bc1\u3002", "motivation": "\u683c\u6597\u7c7b\u8fd0\u52a8\u5982\u62f3\u51fb\u5728AI\u9a71\u52a8\u7684\u6218\u672f\u5206\u6790\u65b9\u9762\u53d1\u5c55\u4e0d\u8db3\uff0c\u4e3b\u8981\u7531\u4e8e\u52a8\u4f5c\u52a8\u6001\u590d\u6742\u4e14\u7f3a\u4e4f\u7ed3\u6784\u5316\u6218\u672f\u8868\u793a\u3002\u9700\u8981\u5c06\u975e\u7ed3\u6784\u5316\u89c6\u9891\u6570\u636e\u8f6c\u5316\u4e3a\u6218\u7565\u667a\u80fd\uff0c\u5f25\u5408\u8ba1\u7b97\u673a\u89c6\u89c9\u4e0e\u7ade\u6280\u4f53\u80b2\u51b3\u7b56\u652f\u6301\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "1. \u5b9a\u4e49\u5177\u6709\u7cbe\u786e\u65f6\u95f4\u8fb9\u754c\u3001\u7a7a\u95f4\u548c\u6280\u672f\u5c5e\u6027\u7684\u539f\u5b50\u51fb\u6253\u4e8b\u4ef6\uff1b2. \u5c06\u6bd4\u8d5b\u89c6\u9891\u89e3\u6790\u4e3a18\u4e2a\u5c42\u6b21\u5316\u6280\u672f\u6218\u672f\u6307\u6807\uff1b3. \u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u878d\u5408\u663e\u5f0f\u6280\u672f\u6218\u672f\u7279\u5f81\u4e0e\u53ef\u5b66\u4e60\u7684\u65f6\u95f4\u53d8\u4f53\u6f5c\u5728\u5d4c\u5165\uff1b4. \u5c06\u6bd4\u8d5b\u7ed3\u679c\u5efa\u6a21\u4e3a\u6280\u672f\u6218\u672f\u6307\u6807\u7684\u53ef\u5fae\u51fd\u6570\uff0c\u5c06\u83b7\u80dc\u6982\u7387\u68af\u5ea6\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u6218\u672f\u8c03\u6574\u3002", "result": "1. \u7ed3\u679c\u9884\u6d4b\u6a21\u578b\u5728BoxerGraph\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u523069.8%\u51c6\u786e\u7387\uff0c\u5728\u5965\u8fd0\u6bd4\u8d5b\u4e0a\u8fbe\u523087.5%\u51c6\u786e\u7387\uff1b2. \u7cfb\u7edf\u751f\u6210\u7684\u6218\u7565\u5efa\u8bae\u8fbe\u5230\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5f53\u7684\u6c34\u5e73\uff1b3. \u57282024\u5e74\u5df4\u9ece\u5965\u8fd0\u4f1a\u95ed\u73af\u90e8\u7f72\u4e2d\uff0c\u76f4\u63a5\u52a9\u529b\u4e2d\u56fd\u56fd\u5bb6\u961f\u83b7\u5f973\u91d12\u94f6\u7684\u5386\u53f2\u6027\u6210\u7ee9\u3002", "conclusion": "BoxMind\u5efa\u7acb\u4e86\u5c06\u975e\u7ed3\u6784\u5316\u89c6\u9891\u6570\u636e\u8f6c\u5316\u4e3a\u6218\u7565\u667a\u80fd\u7684\u53ef\u590d\u5236\u8303\u5f0f\uff0c\u5f25\u5408\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u4e0e\u7ade\u6280\u4f53\u80b2\u51b3\u7b56\u652f\u6301\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u683c\u6597\u7c7b\u8fd0\u52a8\u7684AI\u9a71\u52a8\u6218\u672f\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
