<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 9]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration](https://arxiv.org/abs/2512.21360)
*Shuide Wen,Yu Sun,Beier Ku,Zhi Gao,Lijun Ma,Yang Yang,Can Jiao*

Main category: cs.AI

TL;DR: 本研究提出了一种基于多模态大语言模型的多智能体协作框架，用于标准化HTP绘画测试的评估，解决了传统方法主观性强、评分标准不统一的问题。


<details>
  <summary>Details</summary>
Motivation: HTP绘画测试作为临床心理学中广泛使用的投射技术，长期面临评分标准不统一、依赖评估者主观经验、缺乏统一量化编码系统等问题，需要开发标准化评估工具。

Method: 采用多模态大语言模型构建多智能体协作框架，通过角色分工将特征识别与心理推断解耦，整合社会心理学视角和去污名化叙事，提高评估的客观性和准确性。

Result: 定量实验显示MLLM解释与人类专家解释的平均语义相似度约为0.75（标准差约0.05），在结构化专家数据集中相似度提升至0.85，达到专家级理解水平。定性分析表明系统能有效纠正视觉幻觉，生成具有高生态效度和内在一致性的心理报告。

Conclusion: 多模态大模型具有作为投射评估标准化工具的潜力，提出的多智能体框架为数字心理健康服务提供了新范式，通过角色分工实现了特征识别与心理推断的解耦。

Abstract: Background: The House-Tree-Person (HTP) drawing test, introduced by John Buck in 1948, remains a widely used projective technique in clinical psychology. However, it has long faced challenges such as heterogeneous scoring standards, reliance on examiners subjective experience, and a lack of a unified quantitative coding system.
  Results: Quantitative experiments showed that the mean semantic similarity between Multimodal Large Language Model (MLLM) interpretations and human expert interpretations was approximately 0.75 (standard deviation about 0.05). In structurally oriented expert data sets, this similarity rose to 0.85, indicating expert-level baseline comprehension. Qualitative analyses demonstrated that the multi-agent system, by integrating social-psychological perspectives and destigmatizing narratives, effectively corrected visual hallucinations and produced psychological reports with high ecological validity and internal coherence.
  Conclusions: The findings confirm the potential of multimodal large models as standardized tools for projective assessment. The proposed multi-agent framework, by dividing roles, decouples feature recognition from psychological inference and offers a new paradigm for digital mental-health services.
  Keywords: House-Tree-Person test; multimodal large language model; multi-agent collaboration; cosine similarity; computational psychology; artificial intelligence

</details>


### [2] [A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers](https://arxiv.org/abs/2512.21365)
*Chung-Chin Shih,Ti-Rong Wu,Ting Han Wei,Yu-Shan Hsu,Hung Guei,I-Chen Wu*

Main category: cs.AI

TL;DR: 该研究分析了使用相关区域搜索(RZS)和相关区域模式表技术的最先进计算机围棋求解器在死活题求解中的表现，发现求解器能识别关键区域、发现罕见模式，但在某些问题上与人类解法存在差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估当前最先进的计算机围棋求解器在死活题求解中的表现，特别是使用相关区域搜索(RZS)和相关区域模式表技术时，探究这些求解器与人类专家解法之间的差异。

Method: 研究方法包括：1) 使用相关区域搜索(RZS)和相关区域模式表技术的计算机围棋求解器；2) 测试7个来自围棋大师赵治勋《死活辞典》的经典死活题；3) 分析求解器识别的相关区域、发现的模式类型；4) 对比求解器答案与书中给定解法的差异。

Result: 研究结果发现：1) 求解器能为每个问题识别出关键的相关区域；2) 求解器发现了一系列模式，包括一些罕见模式；3) 在两个问题上，求解器找到了与给定解法不同的答案；4) 同时发现求解器存在两个问题：a) 对罕见模式的估值判断错误，b) 倾向于直接做活而非最大化实地，这与人类棋手的策略不同。

Conclusion: 结论表明当前基于相关区域搜索的围棋求解器在死活题求解中表现出色，能够识别关键区域和发现罕见模式，但与人类解法存在策略差异。研究提出了解决这些问题的可能方法，并公开了代码和数据供进一步研究。

Abstract: This paper analyzes the behavior of solving Life-and-Death (L&D) problems in the game of Go using current state-of-the-art computer Go solvers with two techniques: the Relevance-Zone Based Search (RZS) and the relevance-zone pattern table. We examined the solutions derived by relevance-zone based solvers on seven L&D problems from the renowned book "Life and Death Dictionary" written by Cho Chikun, a Go grandmaster, and found several interesting results. First, for each problem, the solvers identify a relevance-zone that highlights the critical areas for solving. Second, the solvers discover a series of patterns, including some that are rare. Finally, the solvers even find different answers compared to the given solutions for two problems. We also identified two issues with the solver: (a) it misjudges values of rare patterns, and (b) it tends to prioritize living directly rather than maximizing territory, which differs from the behavior of human Go players. We suggest possible approaches to address these issues in future work. Our code and data are available at https://rlg.iis.sinica.edu.tw/papers/study-LD-RZ.

</details>


### [3] [Three-way decision with incomplete information based on similarity and satisfiability](https://arxiv.org/abs/2512.21421)
*Junfang Luo,Mengjun Hu,Keyun Qin*

Main category: cs.AI

TL;DR: 本文在回顾完整信息下三支决策的计算和概念两种表述基础上，将两者推广到更实用的不完备信息场景，提出了相似度度量、α-相似类、可逼近性等新方法。


<details>
  <summary>Details</summary>
Motivation: 现有三支决策方法主要处理完备信息，但在实际应用中不完备信息更为常见。需要将完备信息下的计算和概念两种表述推广到不完备信息场景，以增强三支决策的实用性。

Method: 1. 计算表述：提出对象相似度度量作为等价关系的推广，基于此讨论使用α-相似类和对象可逼近性的两种三支决策方法。
2. 概念表述：提出公式满足度度量作为完备信息下满足性的量化推广，基于此研究使用公式α-意义集和公式置信度的两种三支决策方法。

Result: 成功将三支决策的计算和概念两种表述从完备信息推广到不完备信息，提出了相似度度量、α-相似类、可逼近性、公式满足度度量、α-意义集和公式置信度等新概念和方法，为不完备信息下的三支决策提供了系统框架。

Conclusion: 本文提出的可逼近性概念和概念表述中的两种新方法为不完备信息分析开辟了有前景的新方向，而相似类方法则是文献中分析不完备信息的常用方法。这些推广增强了三支决策在实际应用中的实用性。

Abstract: Three-way decision is widely applied with rough set theory to learn classification or decision rules. The approaches dealing with complete information are well established in the literature, including the two complementary computational and conceptual formulations. The computational formulation uses equivalence relations, and the conceptual formulation uses satisfiability of logic formulas. In this paper, based on a briefly review of these two formulations, we generalize both formulations into three-way decision with incomplete information that is more practical in real-world applications. For the computational formulation, we propose a new measure of similarity degree of objects as a generalization of equivalence relations. Based on it, we discuss two approaches to three-way decision using alpha-similarity classes and approximability of objects, respectively. For the conceptual formulation, we propose a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability with complete information. Based on it, we study two approaches to three-way decision using alpha-meaning sets of formulas and confidence of formulas, respectively. While using similarity classes is a common method of analyzing incomplete information in the literature, the proposed concept of approximability and the two approaches in conceptual formulation point out new promising directions.

</details>


### [4] [LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis](https://arxiv.org/abs/2512.21482)
*Fanwei Zeng,Changtao Miao,Jing Huang,Zhiya Tan,Shutao Gong,Xiaoming Yu,Yang Wang,Huazhe Tan,Weibin Yao,Jianshu Li*

Main category: cs.AI

TL;DR: LogicLens是一个统一的视觉-文本协同推理框架，用于分析文本中心伪造图像，通过跨线索感知思维链机制和GRPO优化实现检测、定位和解释的联合任务，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着AIGC技术的快速发展，复杂的文本中心伪造图像对社会安全和信息真实性构成重大威胁。现有方法通常局限于粗粒度的视觉分析，缺乏深度推理能力，并且将检测、定位和解释视为独立子任务，忽略了它们之间的内在联系。

Method: 提出LogicLens统一框架，采用跨线索感知思维链机制迭代交叉验证视觉线索与文本逻辑；使用加权多任务奖励函数进行GRPO优化；设计了PR²（感知器、推理器、审查器）流水线生成高质量标注；构建了包含5,397张图像的RealText数据集。

Result: 在T-IC13的零样本评估中，LogicLens比专门框架高出41.4%，比GPT-4o高出23.4%的宏平均F1分数；在密集文本T-SROIE数据集上，在mF1、CSS和宏平均F1指标上显著领先其他MLLM方法。

Conclusion: LogicLens通过统一的视觉-文本协同推理框架，有效解决了文本中心伪造分析中的挑战，在多个基准测试中展现了优越性能，为伪造图像分析提供了新的解决方案。

Abstract: Sophisticated text-centric forgeries, fueled by rapid AIGC advancements, pose a significant threat to societal security and information authenticity. Current methods for text-centric forgery analysis are often limited to coarse-grained visual analysis and lack the capacity for sophisticated reasoning. Moreover, they typically treat detection, grounding, and explanation as discrete sub-tasks, overlooking their intrinsic relationships for holistic performance enhancement. To address these challenges, we introduce LogicLens, a unified framework for Visual-Textual Co-reasoning that reformulates these objectives into a joint task. The deep reasoning of LogicLens is powered by our novel Cross-Cues-aware Chain of Thought (CCT) mechanism, which iteratively cross-validates visual cues against textual logic. To ensure robust alignment across all tasks, we further propose a weighted multi-task reward function for GRPO-based optimization. Complementing this framework, we first designed the PR$^2$ (Perceiver, Reasoner, Reviewer) pipeline, a hierarchical and iterative multi-agent system that generates high-quality, cognitively-aligned annotations. Then, we constructed RealText, a diverse dataset comprising 5,397 images with fine-grained annotations, including textual explanations, pixel-level segmentation, and authenticity labels for model training. Extensive experiments demonstrate the superiority of LogicLens across multiple benchmarks. In a zero-shot evaluation on T-IC13, it surpasses the specialized framework by 41.4% and GPT-4o by 23.4% in macro-average F1 score. Moreover, on the challenging dense-text T-SROIE dataset, it establishes a significant lead over other MLLM-based methods in mF1, CSS, and the macro-average F1. Our dataset, model, and code will be made publicly available.

</details>


### [5] [Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model](https://arxiv.org/abs/2512.21540)
*Yanhao Li,Lu Ma,Jiaran Zhang,Lexiang Tang,Wentao Zhang,Guibo Luo*

Main category: cs.AI

TL;DR: Leash：一个通过自适应长度惩罚和奖励塑造的强化学习框架，用于在LLMs中实现高效推理，在保持任务性能的同时减少60%的平均推理长度。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖固定长度惩罚，但这种惩罚难以调整且无法适应LLMs不断发展的推理能力，导致准确性和简洁性之间的次优权衡。

Method: 将长度控制建模为约束优化问题，采用拉格朗日对偶方法动态调整惩罚系数：当生成超过目标长度时增强惩罚，当生成较短时放松惩罚。

Result: 在Deepseek-R1-Distill-Qwen-1.5B和Qwen3-4B-Thinking-2507上的实验表明，Leash在数学推理、编码和指令遵循等任务中减少平均推理长度60%，同时保持竞争性性能。

Conclusion: Leash为开发可控且高效的LLMs提供了一个实用有效的范式，能够在推理能力和计算预算之间取得平衡。

Abstract: Existing approaches typically rely on fixed length penalties, but such penalties are hard to tune and fail to adapt to the evolving reasoning abilities of LLMs, leading to suboptimal trade-offs between accuracy and conciseness. To address this challenge, we propose Leash (adaptive LEngth penAlty and reward SHaping), a reinforcement learning framework for efficient reasoning in LLMs. We formulate length control as a constrained optimization problem and employ a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. When generations exceed the target length, the penalty is intensified; when they are shorter, it is relaxed. This adaptive mechanism guides models toward producing concise reasoning without sacrificing task performance. Experiments on Deepseek-R1-Distill-Qwen-1.5B and Qwen3-4B-Thinking-2507 show that Leash reduces the average reasoning length by 60% across diverse tasks - including in-distribution mathematical reasoning and out-of-distribution domains such as coding and instruction following - while maintaining competitive performance. Our work thus presents a practical and effective paradigm for developing controllable and efficient LLMs that balance reasoning capabilities with computational budgets.

</details>


### [6] [A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning](https://arxiv.org/abs/2512.21583)
*Zelin Zang,Wenyi Gu,Siqi Ma,Dan Yang,Yue Shen,Zhu Zhang,Guohui Fan,Wing-Kuen Ling,Fuji Yang*

Main category: cs.AI

TL;DR: 基于LLaVA构建的诊断框架，结合视觉语言对齐与逻辑正则化推理，提升医疗多模态任务的诊断准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和视觉语言模型在医学领域的快速发展，简单地整合临床文本和医学影像并不能保证可靠的推理。现有的多模态模型经常产生幻觉或不一致的思维链，限制了临床信任度。

Method: 提出基于LLaVA的诊断框架，包含：文本和图像的输入编码器、跨模态对齐的投影模块、将诊断任务分解为步骤的推理控制器，以及将逐步前提组装成可验证结论的逻辑树生成器。

Result: 在MedXpertQA和其他基准测试上的评估表明，该方法提高了多模态任务的诊断准确性，产生了更具可解释性的推理轨迹，同时在纯文本设置下保持竞争力。

Conclusion: 这些结果表明，该方法朝着可信赖的多模态医疗AI迈出了有希望的一步。

Abstract: With the rapid growth of large language models (LLMs) and vision-language models (VLMs) in medicine, simply integrating clinical text and medical imaging does not guarantee reliable reasoning. Existing multimodal models often produce hallucinations or inconsistent chains of thought, limiting clinical trust. We propose a diagnostic framework built upon LLaVA that combines vision-language alignment with logic-regularized reasoning. The system includes an input encoder for text and images, a projection module for cross-modal alignment, a reasoning controller that decomposes diagnostic tasks into steps, and a logic tree generator that assembles stepwise premises into verifiable conclusions. Evaluations on MedXpertQA and other benchmarks show that our method improves diagnostic accuracy and yields more interpretable reasoning traces on multimodal tasks, while remaining competitive on text-only settings. These results suggest a promising step toward trustworthy multimodal medical AI.

</details>


### [7] [Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design](https://arxiv.org/abs/2512.21623)
*Takahide Suzuki,Kazuki Nakanishi,Takashi Fujiwara,Hideyuki Shimizu*

Main category: cs.AI

TL;DR: OrchestRA是一个人类在环的多智能体平台，将生物学、化学和药理学统一为自主发现引擎，通过自主执行模拟和推理结果来驱动迭代优化，改变药物发现为可编程的循证工程学科。


<details>
  <summary>Details</summary>
Motivation: 治疗发现面临专业领域碎片化和计算设计与生理验证之间执行差距的挑战。当前生成式AI模型通常作为被动助手而非自主执行者，需要更主动的解决方案。

Method: OrchestRA采用多智能体架构：由Orchestrator协调，生物学家智能体利用超过1000万关联的知识图谱进行深度推理识别高置信度靶点；化学家智能体自主检测结构口袋进行从头设计或药物重定位；药理学家智能体通过基于生理的药代动力学(PBPK)模拟评估候选药物，建立动态反馈循环。

Result: 该平台建立了动态反馈循环，药代动力学和毒性特征直接触发结构重新优化，将自主执行与人类指导无缝集成，使治疗设计民主化。

Conclusion: OrchestRA将药物发现从随机搜索转变为可编程的循证工程学科，通过统一生物学、化学和药理学并建立自主执行与人类指导的集成，解决了治疗发现中的关键挑战。

Abstract: Therapeutic discovery remains a formidable challenge, impeded by the fragmentation of specialized domains and the execution gap between computational design and physiological validation. Although generative AI offers promise, current models often function as passive assistants rather than as autonomous executors. Here, we introduce OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine. Unlike static code generators, our agents actively execute simulations and reason the results to drive iterative optimization. Governed by an Orchestrator, a Biologist Agent leverages deep reasoning over a massive knowledge graph (>10 million associations) to pinpoint high-confidence targets; a Chemist Agent autonomously detects structural pockets for de novo design or drug repositioning; and a Pharmacologist Agent evaluates candidates via rigorous physiologically based pharmacokinetic (PBPK) simulations. This architecture establishes a dynamic feedback loop where pharmacokinetic and toxicity profiles directly trigger structural reoptimization. By seamlessly integrating autonomous execution with human guidance, OrchestRA democratizes therapeutic design, transforming drug discovery from a stochastic search to a programmable evidence-based engineering discipline.

</details>


### [8] [Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing](https://arxiv.org/abs/2512.21626)
*Hong Xie,Haoran Gu,Yanying Huang,Tao Tan,Defu Lian*

Main category: cs.AI

TL;DR: 该论文提出了一种针对LLM应用、边缘智能等资源分配问题的多臂赌博机变体，建立了优先资源共享机制下的遗憾下界，并设计了匹配下界的算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM应用、边缘智能等场景中的资源分配问题，需要一种能够处理优先资源共享机制的多臂赌博机模型。传统模型无法有效处理这种非线性组合效用函数。

Method: 提出MSB-PRS模型：M个臂，K次游戏，每个臂有随机容量，每个容量单元有奖励函数，游戏有优先级权重。当多个游戏竞争臂容量时，按优先级权重从大到小分配。设计了MSB-PRS-OffOpt算法（复杂度O(MK³)）和基于近似UCB的算法。

Result: 证明了实例无关遗憾下界Ω(α₁σ√(KMT))和实例相关遗憾下界Ω(α₁σ²(M/Δ)lnT)。设计的算法实现了与下界匹配的遗憾上界（分别相差√(KlnKT)和α₁K²因子）。

Conclusion: 该研究成功解决了优先资源共享机制下的非线性组合优化和学习问题，为资源分配应用提供了理论保证和实用算法。

Abstract: This paper proposes a variant of multiple-play stochastic bandits tailored to resource allocation problems arising from LLM applications, edge intelligence, etc. The model is composed of $M$ arms and $K$ plays. Each arm has a stochastic number of capacities, and each unit of capacity is associated with a reward function. Each play is associated with a priority weight. When multiple plays compete for the arm capacity, the arm capacity is allocated in a larger priority weight first manner. Instance independent and instance dependent regret lower bounds of $Ω( α_1 σ\sqrt{KM T} )$ and $Ω(α_1 σ^2 \frac{M}Δ \ln T)$ are proved, where $α_1$ is the largest priority weight and $σ$ characterizes the reward tail. When model parameters are given, we design an algorithm named \texttt{MSB-PRS-OffOpt} to locate the optimal play allocation policy with a computational complexity of $O(MK^3)$. Utilizing \texttt{MSB-PRS-OffOpt} as a subroutine, an approximate upper confidence bound (UCB) based algorithm is designed, which has instance independent and instance dependent regret upper bounds matching the corresponding lower bound up to factors of $ \sqrt{K \ln KT }$ and $α_1 K^2$ respectively. To this end, we address nontrivial technical challenges arising from optimizing and learning under a special nonlinear combinatorial utility function induced by the prioritized resource sharing mechanism.

</details>


### [9] [Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets](https://arxiv.org/abs/2512.21775)
*Matyas Bohacek,Ignacio Vilanova Echavarri*

Main category: cs.AI

TL;DR: 论文提出了一个名为合规评级方案（CRS）的框架，用于评估数据集在透明度、问责制和安全性方面的合规性，并发布了相应的开源Python库。


<details>
  <summary>Details</summary>
Motivation: 当前生成式人工智能（GAI）快速发展，但其训练数据集往往采用不透明、不受限制的数据收集方式，缺乏伦理和法律考量。数据集在共享、编辑和复制过程中，其来源、合法性和安全性信息常常丢失。

Method: 提出了合规评级方案（CRS）框架，基于数据溯源技术开发了开源Python库，该库既能评估现有数据集的CRS评分，也能指导负责任的数据抓取和新数据集构建。

Result: 开发了一个开源Python库，能够无缝集成到现有数据集处理和AI训练流程中，实现反应式和主动式的数据集合规评估。

Conclusion: CRS框架和相关工具填补了生成式人工智能领域数据集合规评估的空白，有助于提高数据集的透明度、问责制和安全性，促进负责任的AI发展。

Abstract: Generative Artificial Intelligence (GAI) has experienced exponential growth in recent years, partly facilitated by the abundance of large-scale open-source datasets. These datasets are often built using unrestricted and opaque data collection practices. While most literature focuses on the development and applications of GAI models, the ethical and legal considerations surrounding the creation of these datasets are often neglected. In addition, as datasets are shared, edited, and further reproduced online, information about their origin, legitimacy, and safety often gets lost. To address this gap, we introduce the Compliance Rating Scheme (CRS), a framework designed to evaluate dataset compliance with critical transparency, accountability, and security principles. We also release an open-source Python library built around data provenance technology to implement this framework, allowing for seamless integration into existing dataset-processing and AI training pipelines. The library is simultaneously reactive and proactive, as in addition to evaluating the CRS of existing datasets, it equally informs responsible scraping and construction of new datasets.

</details>
