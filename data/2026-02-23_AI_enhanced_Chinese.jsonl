{"id": "2602.17826", "categories": ["cs.AI", "cs.LG", "cs.SC"], "pdf": "https://arxiv.org/pdf/2602.17826", "abs": "https://arxiv.org/abs/2602.17826", "authors": ["Marcelo Labre"], "title": "Ontology-Guided Neuro-Symbolic Inference: Grounding Language Models with Mathematical Domain Knowledge", "comment": "Submitted to NeuS 2026. Supplementary materials and code: https://doi.org/10.5281/zenodo.18665030", "summary": "Language models exhibit fundamental limitations -- hallucination, brittleness, and lack of formal grounding -- that are particularly problematic in high-stakes specialist fields requiring verifiable reasoning. I investigate whether formal domain ontologies can enhance language model reliability through retrieval-augmented generation. Using mathematics as proof of concept, I implement a neuro-symbolic pipeline leveraging the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts. Evaluation on the MATH benchmark with three open-source models reveals that ontology-guided context improves performance when retrieval quality is high, but irrelevant context actively degrades it -- highlighting both the promise and challenges of neuro-symbolic approaches.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u5f62\u5f0f\u5316\u9886\u57df\u672c\u4f53\uff08OpenMath\uff09\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6765\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u672c\u4f53\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u5728\u68c0\u7d22\u8d28\u91cf\u9ad8\u65f6\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u964d\u4f4e\u6027\u80fd\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u3001\u8106\u5f31\u6027\u548c\u7f3a\u4e4f\u5f62\u5f0f\u5316\u57fa\u7840\u7b49\u6839\u672c\u9650\u5236\uff0c\u8fd9\u5728\u9700\u8981\u53ef\u9a8c\u8bc1\u63a8\u7406\u7684\u9ad8\u98ce\u9669\u4e13\u4e1a\u9886\u57df\uff08\u5982\u6570\u5b66\uff09\u4e2d\u5c24\u4e3a\u6210\u95ee\u9898\u3002\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u5f62\u5f0f\u5316\u9886\u57df\u672c\u4f53\u662f\u5426\u80fd\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6765\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u6570\u5b66\u4f5c\u4e3a\u6982\u5ff5\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u7ba1\u9053\uff0c\u5229\u7528OpenMath\u672c\u4f53\uff0c\u7ed3\u5408\u6df7\u5408\u68c0\u7d22\u548c\u4ea4\u53c9\u7f16\u7801\u5668\u91cd\u6392\u5e8f\u6280\u672f\uff0c\u5c06\u76f8\u5173\u5b9a\u4e49\u6ce8\u5165\u6a21\u578b\u63d0\u793a\u4e2d\u3002\u5728MATH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\u4e86\u4e09\u4e2a\u5f00\u6e90\u6a21\u578b\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u672c\u4f53\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u5728\u68c0\u7d22\u8d28\u91cf\u9ad8\u65f6\u80fd\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u4e3b\u52a8\u964d\u4f4e\u6027\u80fd\u3002\u8fd9\u7a81\u663e\u4e86\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u7684\u6f5c\u529b\u548c\u6311\u6218\u3002", "conclusion": "\u5f62\u5f0f\u5316\u9886\u57df\u672c\u4f53\u53ef\u4ee5\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\uff0c\u4f46\u68c0\u7d22\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u635f\u5bb3\u6027\u80fd\uff0c\u8868\u660e\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u9700\u8981\u7cbe\u786e\u7684\u68c0\u7d22\u673a\u5236\u6765\u53d1\u6325\u5176\u6f5c\u529b\u3002"}}
{"id": "2602.17831", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17831", "abs": "https://arxiv.org/abs/2602.17831", "authors": ["Simon Henniger", "Gabriel Poesia"], "title": "The Token Games: Evaluating Language Model Reasoning with Puzzle Duels", "comment": "Project website: https://token-games.ai/", "summary": "Evaluating the reasoning capabilities of Large Language Models is increasingly challenging as models improve. Human curation of hard questions is highly expensive, especially in recent benchmarks using PhD-level domain knowledge to challenge the most capable models. Even then, there is always a concern about whether these questions test genuine reasoning or if similar problems have been seen during training. Here, we take inspiration from 16th-century mathematical duels to design The Token Games (TTG): an evaluation framework where models challenge each other by creating their own puzzles. We leverage the format of Programming Puzzles - given a Python function that returns a boolean, find inputs that make it return True - to flexibly represent problems and enable verifying solutions. Using results from pairwise duels, we then compute Elo ratings, allowing us to compare models relative to each other. We evaluate 10 frontier models on TTG, and closely match the ranking from existing benchmarks such as Humanity's Last Exam, without involving any human effort in creating puzzles. We also find that creating good puzzles is still a highly challenging task for current models, not measured by previous benchmarks. Overall, our work suggests new paradigms for evaluating reasoning that cannot be saturated by design, and that allow testing models for other skills like creativity and task creation alongside problem solving.", "AI": {"tldr": "TTG\u662f\u4e00\u4e2a\u57fa\u4e8e16\u4e16\u7eaa\u6570\u5b66\u51b3\u6597\u542f\u53d1\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u521b\u5efa\u7f16\u7a0b\u8c1c\u9898\u76f8\u4e92\u6311\u6218\uff0c\u81ea\u52a8\u8bc4\u4f30\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u9700\u4eba\u5de5\u51fa\u9898\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u6311\u6218\uff1a\u4eba\u5de5\u51fa\u9898\u6210\u672c\u9ad8\uff08\u7279\u522b\u662f\u9700\u8981\u535a\u58eb\u7ea7\u9886\u57df\u77e5\u8bc6\u7684\u96be\u9898\uff09\uff0c\u4e14\u96be\u4ee5\u786e\u5b9a\u6a21\u578b\u662f\u5426\u771f\u6b63\u63a8\u7406\u8fd8\u662f\u89c1\u8fc7\u7c7b\u4f3c\u8bad\u7ec3\u6570\u636e\u3002\u9700\u8981\u4e00\u79cd\u65e0\u6cd5\u901a\u8fc7\u8bbe\u8ba1\u9971\u548c\u7684\u8bc4\u4f30\u8303\u5f0f\u3002", "method": "\u91c7\u7528\u7f16\u7a0b\u8c1c\u9898\u683c\u5f0f\uff1a\u7ed9\u5b9a\u8fd4\u56de\u5e03\u5c14\u503c\u7684Python\u51fd\u6570\uff0c\u5bfb\u627e\u4f7f\u5176\u8fd4\u56deTrue\u7684\u8f93\u5165\u3002\u6a21\u578b\u76f8\u4e92\u521b\u5efa\u8c1c\u9898\u6311\u6218\u5bf9\u65b9\uff0c\u901a\u8fc7\u4e24\u4e24\u5bf9\u51b3\u8ba1\u7b97Elo\u8bc4\u5206\u6765\u6bd4\u8f83\u6a21\u578b\u76f8\u5bf9\u80fd\u529b\u3002", "result": "\u8bc4\u4f30\u4e8610\u4e2a\u524d\u6cbf\u6a21\u578b\uff0cTTG\u7684\u6392\u540d\u4e0e\u73b0\u6709\u57fa\u51c6\uff08\u5982Humanity's Last Exam\uff09\u9ad8\u5ea6\u5339\u914d\uff0c\u4e14\u65e0\u9700\u4eba\u5de5\u521b\u5efa\u8c1c\u9898\u3002\u53d1\u73b0\u521b\u5efa\u4f18\u8d28\u8c1c\u9898\u5bf9\u5f53\u524d\u6a21\u578b\u4ecd\u662f\u6781\u5177\u6311\u6218\u7684\u4efb\u52a1\uff0c\u8fd9\u662f\u5148\u524d\u57fa\u51c6\u672a\u6d4b\u91cf\u7684\u80fd\u529b\u3002", "conclusion": "TTG\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u8303\u5f0f\uff0c\u65e2\u65e0\u6cd5\u901a\u8fc7\u8bbe\u8ba1\u9971\u548c\uff0c\u53c8\u80fd\u540c\u65f6\u6d4b\u8bd5\u6a21\u578b\u7684\u521b\u9020\u529b\u3001\u4efb\u52a1\u521b\u5efa\u80fd\u529b\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4e3a\u8bc4\u4f30\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.17990", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17990", "abs": "https://arxiv.org/abs/2602.17990", "authors": ["Madhav Kanda", "Pedro Las-Casas", "Alok Gautam Kumbhare", "Rodrigo Fonseca", "Sharad Agarwal"], "title": "WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics", "comment": null, "summary": "LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows and 44,757 perturbed variants across three perturbation types (Missing Steps, Compressed Steps, and Description Changes), each applied at severity levels of 10%, 30%, and 50%. We benchmark multiple metric families and analyze their sensitivity and calibration using expected score trajectories and residuals. Our results characterize systematic differences across metric families and support severity-aware interpretation of workflow evaluation scores. Our dataset will be released upon acceptance.", "AI": {"tldr": "WorkflowPerturb\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5de5\u4f5c\u6d41\u8bc4\u4f30\u6307\u6807\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5bf9\u9ec4\u91d1\u5de5\u4f5c\u6d41\u65bd\u52a0\u53d7\u63a7\u6270\u52a8\u6765\u7814\u7a76\u6307\u6807\u7684\u6027\u80fd", "motivation": "LLM\u751f\u6210\u7684\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u8bc4\u4f30\u56f0\u96be\uff0c\u56e0\u4e3a\u6307\u6807\u5206\u6570\u901a\u5e38\u672a\u6821\u51c6\uff0c\u4e14\u5206\u6570\u53d8\u5316\u4e0d\u80fd\u76f4\u63a5\u53cd\u6620\u5de5\u4f5c\u6d41\u9000\u5316\u7684\u4e25\u91cd\u7a0b\u5ea6", "method": "\u901a\u8fc7\u5411\u9ec4\u91d1\u5de5\u4f5c\u6d41\u65bd\u52a0\u4e09\u79cd\u7c7b\u578b\u7684\u53d7\u63a7\u6270\u52a8\uff08\u7f3a\u5931\u6b65\u9aa4\u3001\u538b\u7f29\u6b65\u9aa4\u3001\u63cf\u8ff0\u53d8\u5316\uff09\uff0c\u6bcf\u79cd\u7c7b\u578b\u572810%\u300130%\u300150%\u7684\u4e25\u91cd\u7ea7\u522b\u4e0a\u5e94\u7528\uff0c\u521b\u5efa\u5305\u542b4,973\u4e2a\u9ec4\u91d1\u5de5\u4f5c\u6d41\u548c44,757\u4e2a\u6270\u52a8\u53d8\u4f53\u7684\u57fa\u51c6\u6570\u636e\u96c6", "result": "\u57fa\u51c6\u6d4b\u8bd5\u4e86\u591a\u4e2a\u6307\u6807\u5bb6\u65cf\uff0c\u4f7f\u7528\u9884\u671f\u5206\u6570\u8f68\u8ff9\u548c\u6b8b\u5dee\u5206\u6790\u5176\u654f\u611f\u6027\u548c\u6821\u51c6\u6027\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6307\u6807\u5bb6\u65cf\u4e4b\u95f4\u7684\u7cfb\u7edf\u6027\u5dee\u5f02", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301\u57fa\u4e8e\u4e25\u91cd\u7a0b\u5ea6\u7684\u5de5\u4f5c\u6d41\u8bc4\u4f30\u5206\u6570\u89e3\u91ca\uff0c\u6570\u636e\u96c6\u5c06\u5728\u63a5\u53d7\u540e\u53d1\u5e03\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u5de5\u4f5c\u6d41\u8bc4\u4f30\u6307\u6807\u7684\u8bbe\u8ba1\u548c\u4f7f\u7528"}}
{"id": "2602.18025", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.18025", "abs": "https://arxiv.org/abs/2602.18025", "authors": ["Haruki Abe", "Takayuki Osa", "Yusuke Mukuta", "Tatsuya Harada"], "title": "Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets", "comment": "ICLR 2026", "summary": "Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7ed3\u5408\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u548c\u8de8\u5177\u8eab\u5b66\u4e60\u6765\u89e3\u51b3\u673a\u5668\u4eba\u7b56\u7565\u9884\u8bad\u7ec3\u4e2d\u9ad8\u8d28\u91cf\u6f14\u793a\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u5efa\u5305\u542b16\u4e2a\u673a\u5668\u4eba\u5e73\u53f0\u7684\u8fd0\u52a8\u6570\u636e\u96c6\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u5f62\u6001\u76f8\u4f3c\u6027\u7684\u5206\u7ec4\u7b56\u7565\u6765\u7f13\u89e3\u8de8\u673a\u5668\u4eba\u68af\u5ea6\u51b2\u7a81\u3002", "motivation": "\u673a\u5668\u4eba\u7b56\u7565\u9884\u8bad\u7ec3\u9762\u4e34\u9ad8\u8d28\u91cf\u6f14\u793a\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u627e\u5230\u65e2\u80fd\u5229\u7528\u4e13\u5bb6\u6570\u636e\u53c8\u80fd\u5229\u7528\u5927\u91cf\u6b21\u4f18\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u8fd8\u8981\u5904\u7406\u4e0d\u540c\u673a\u5668\u4eba\u5f62\u6001\u7684\u5f02\u8d28\u6027\u3002", "method": "\u7ed3\u5408\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u548c\u8de8\u5177\u8eab\u5b66\u4e60\uff0c\u6784\u5efa\u5305\u542b16\u4e2a\u4e0d\u540c\u673a\u5668\u4eba\u5e73\u53f0\u7684\u8fd0\u52a8\u6570\u636e\u96c6\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u3002\u4e3a\u7f13\u89e3\u8de8\u673a\u5668\u4eba\u5f62\u6001\u7684\u68af\u5ea6\u51b2\u7a81\uff0c\u63d0\u51fa\u57fa\u4e8e\u5f62\u6001\u76f8\u4f3c\u6027\u7684\u5206\u7ec4\u7b56\u7565\uff0c\u5c06\u673a\u5668\u4eba\u6309\u5f62\u6001\u76f8\u4f3c\u6027\u805a\u7c7b\uff0c\u4f7f\u7528\u7ec4\u68af\u5ea6\u66f4\u65b0\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\uff0c\u7ed3\u5408\u79bb\u7ebfRL\u548c\u8de8\u5177\u8eab\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u6b21\u4f18\u8f68\u8ff9\u4e30\u5bcc\u7684\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u7eaf\u884c\u4e3a\u514b\u9686\u3002\u4f46\u968f\u7740\u6b21\u4f18\u6570\u636e\u6bd4\u4f8b\u548c\u673a\u5668\u4eba\u7c7b\u578b\u589e\u52a0\uff0c\u8de8\u5f62\u6001\u7684\u68af\u5ea6\u51b2\u7a81\u4f1a\u963b\u788d\u5b66\u4e60\u3002\u63d0\u51fa\u7684\u5206\u7ec4\u7b56\u7565\u80fd\u663e\u8457\u51cf\u5c11\u673a\u5668\u4eba\u95f4\u51b2\u7a81\uff0c\u4f18\u4e8e\u73b0\u6709\u51b2\u7a81\u89e3\u51b3\u65b9\u6cd5\u3002", "conclusion": "\u79bb\u7ebfRL\u4e0e\u8de8\u5177\u8eab\u5b66\u4e60\u7684\u7ed3\u5408\u4e3a\u673a\u5668\u4eba\u7b56\u7565\u9884\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u7279\u522b\u662f\u5728\u6b21\u4f18\u6570\u636e\u4e30\u5bcc\u7684\u573a\u666f\u4e0b\u3002\u57fa\u4e8e\u5f62\u6001\u76f8\u4f3c\u6027\u7684\u5206\u7ec4\u7b56\u7565\u662f\u7f13\u89e3\u8de8\u673a\u5668\u4eba\u68af\u5ea6\u51b2\u7a81\u7684\u7b80\u5355\u6709\u6548\u65b9\u6cd5\uff0c\u4e3a\u5927\u89c4\u6a21\u673a\u5668\u4eba\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.18201", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18201", "abs": "https://arxiv.org/abs/2602.18201", "authors": ["Joseph Bingham", "Netanel Arussy", "Dvir Aran"], "title": "SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps", "comment": "10 pages, 2 figures, preprint", "summary": "Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \\textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u8bad\u7ec3\u65f6\u6392\u9664\u654f\u611f\u5c5e\u6027\uff0c\u65e0\u76d1\u7763\u8868\u793a\u4ecd\u4f1a\u7f16\u7801\u8fd9\u4e9b\u5c5e\u6027\uff0c\u516c\u5e73\u6027\u901a\u8fc7\u65e0\u77e5\u5728\u8868\u793a\u5c42\u9762\u5931\u6548", "motivation": "\u6311\u6218\u65e0\u76d1\u7763\u8868\u793a\u5bf9\u654f\u611f\u5c5e\u6027\u4fdd\u6301\u4e2d\u6027\u7684\u666e\u904d\u5047\u8bbe\uff0c\u63ed\u793a\u516c\u5e73\u6027\u901a\u8fc7\u65e0\u77e5\u5728\u8868\u793a\u5c42\u9762\u7684\u5c40\u9650\u6027", "method": "\u4f7f\u7528SOMtime\uff08\u57fa\u4e8e\u9ad8\u5bb9\u91cf\u81ea\u7ec4\u7ec7\u6620\u5c04\u7684\u62d3\u6251\u4fdd\u6301\u8868\u793a\u65b9\u6cd5\uff09\uff0c\u5728\u4e24\u4e2a\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\uff08\u4e16\u754c\u4ef7\u503c\u89c2\u8c03\u67e5\u548c\u4eba\u53e3\u666e\u67e5\u6536\u5165\u6570\u636e\u96c6\uff09\u4e0a\u6d4b\u8bd5\uff0c\u4e0ePCA\u3001UMAP\u3001t-SNE\u548c\u81ea\u7f16\u7801\u5668\u5bf9\u6bd4", "result": "SOMtime\u6062\u590d\u4e86\u4e0e\u88ab\u6392\u9664\u654f\u611f\u5c5e\u6027\u5bf9\u9f50\u7684\u5355\u8c03\u6392\u5e8f\uff0cSpearman\u76f8\u5173\u6027\u9ad8\u8fbe0.85\uff0c\u800c\u5176\u4ed6\u65b9\u6cd5\u901a\u5e38\u4f4e\u4e8e0.23\uff1b\u65e0\u76d1\u7763\u5206\u5272\u4ea7\u751f\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u659c\u7684\u805a\u7c7b", "conclusion": "\u516c\u5e73\u6027\u901a\u8fc7\u65e0\u77e5\u5728\u8868\u793a\u5c42\u9762\u5bf9\u5e8f\u6570\u654f\u611f\u5c5e\u6027\u5931\u6548\uff0c\u516c\u5e73\u6027\u5ba1\u8ba1\u5fc5\u987b\u6269\u5c55\u5230\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u7684\u65e0\u76d1\u7763\u7ec4\u4ef6"}}
{"id": "2602.18291", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18291", "abs": "https://arxiv.org/abs/2602.18291", "authors": ["Zhuoran Li", "Hai Zhong", "Xun Wang", "Qingxin Xia", "Lihua Zhang", "Longbo Huang"], "title": "Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies", "comment": null, "summary": "Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \\underline{O}nline off-policy \\underline{MA}RL framework using \\underline{D}iffusion policies (\\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\\times$ to $5\\times$ improvement in sample efficiency.", "AI": {"tldr": "OMAD\uff1a\u9996\u4e2a\u5728\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u6269\u6563\u7b56\u7565\u534f\u8c03\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u653e\u677e\u7b56\u7565\u76ee\u6807\u6700\u5927\u5316\u8054\u5408\u71b5\u5b9e\u73b0\u6709\u6548\u63a2\u7d22\uff0c\u5728MPE\u548cMAMuJoCo\u4efb\u52a1\u4e0a\u5b9e\u73b02.5-5\u500d\u6837\u672c\u6548\u7387\u63d0\u5347", "motivation": "\u5728\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u9700\u8981\u589e\u5f3a\u7b56\u7565\u8868\u8fbe\u80fd\u529b\u4ee5\u83b7\u5f97\u66f4\u597d\u6027\u80fd\u3002\u6269\u6563\u6a21\u578b\u5728\u56fe\u50cf\u751f\u6210\u548c\u79bb\u7ebf\u8bbe\u7f6e\u4e2d\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u8868\u8fbe\u80fd\u529b\u548c\u591a\u6a21\u6001\u8868\u793a\u80fd\u529b\uff0c\u4f46\u5728\u5728\u7ebfMARL\u4e2d\u5e94\u7528\u4e0d\u8db3\uff0c\u4e3b\u8981\u969c\u788d\u662f\u6269\u6563\u6a21\u578b\u7684\u4e0d\u53ef\u5904\u7406\u4f3c\u7136\u6027\u963b\u788d\u4e86\u57fa\u4e8e\u71b5\u7684\u63a2\u7d22\u548c\u534f\u8c03\u3002", "method": "\u63d0\u51faOMAD\u6846\u67b6\uff1a1\uff09\u653e\u677e\u7b56\u7565\u76ee\u6807\u6700\u5927\u5316\u7f29\u653e\u8054\u5408\u71b5\uff0c\u5b9e\u73b0\u6709\u6548\u63a2\u7d22\u800c\u4e0d\u4f9d\u8d56\u53ef\u5904\u7406\u4f3c\u7136\uff1b2\uff09\u5728CTDE\u8303\u5f0f\u4e0b\u4f7f\u7528\u8054\u5408\u5206\u5e03\u503c\u51fd\u6570\u4f18\u5316\u5206\u6563\u6269\u6563\u7b56\u7565\uff1b3\uff09\u5229\u7528\u53ef\u5904\u7406\u7684\u71b5\u589e\u5f3a\u76ee\u6807\u6307\u5bfc\u6269\u6563\u7b56\u7565\u540c\u6b65\u66f4\u65b0\uff0c\u786e\u4fdd\u7a33\u5b9a\u534f\u8c03\u3002", "result": "\u5728MPE\u548cMAMuJoCo\u768410\u4e2a\u591a\u6837\u5316\u4efb\u52a1\u4e0a\u5efa\u7acb\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5c55\u793a\u4e862.5\u500d\u52305\u500d\u7684\u6837\u672c\u6548\u7387\u663e\u8457\u63d0\u5347\u3002", "conclusion": "OMAD\u662f\u9996\u4e2a\u4f7f\u7528\u6269\u6563\u7b56\u7565\u7684\u5728\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u653e\u677e\u7b56\u7565\u76ee\u6807\u548c\u8054\u5408\u5206\u5e03\u503c\u51fd\u6570\u6709\u6548\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u5728\u5728\u7ebfMARL\u4e2d\u7684\u5e94\u7528\u969c\u788d\uff0c\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u534f\u8c03\u6027\u80fd\u548c\u6837\u672c\u6548\u7387\u3002"}}
