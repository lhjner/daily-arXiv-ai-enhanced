{"id": "2602.12316", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.12316", "abs": "https://arxiv.org/abs/2602.12316", "authors": ["Pepijn Cobben", "Xuanqiang Angelo Huang", "Thao Amelia Pham", "Isabel Dahlgren", "Terry Jingchen Zhang", "Zhijing Jin"], "title": "GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory", "comment": null, "summary": "Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and conflict poorly understood. We introduce GT-HarmBench, a benchmark of 2,009 high-stakes scenarios spanning game-theoretic structures such as the Prisoner's Dilemma, Stag Hunt and Chicken. Scenarios are drawn from realistic AI risk contexts in the MIT AI Risk Repository. Across 15 frontier models, agents choose socially beneficial actions in only 62% of cases, frequently leading to harmful outcomes. We measure sensitivity to game-theoretic prompt framing and ordering, and analyze reasoning patterns driving failures. We further show that game-theoretic interventions improve socially beneficial outcomes by up to 18%. Our results highlight substantial reliability gaps and provide a broad standardized testbed for studying alignment in multi-agent environments. The benchmark and code are available at https://github.com/causalNLP/gt-harmbench.", "AI": {"tldr": "GT-HarmBench\u662f\u4e00\u4e2a\u5305\u542b2009\u4e2a\u9ad8\u98ce\u9669\u573a\u666f\u7684\u591a\u667a\u80fd\u4f53\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u56da\u5f92\u56f0\u5883\u3001\u730e\u9e7f\u535a\u5f08\u7b49\u535a\u5f08\u8bba\u7ed3\u6784\uff0c\u7528\u4e8e\u8bc4\u4f30\u524d\u6cbfAI\u7cfb\u7edf\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\u548c\u534f\u8c03\u80fd\u529b\u3002", "motivation": "\u73b0\u6709AI\u5b89\u5168\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u5355\u667a\u80fd\u4f53\uff0c\u800c\u5ffd\u7565\u4e86\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u98ce\u9669\uff0c\u5982\u534f\u8c03\u5931\u8d25\u548c\u51b2\u7a81\u3002\u968f\u7740\u524d\u6cbfAI\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u7406\u89e3\u548c\u8bc4\u4f30\u8fd9\u4e9b\u98ce\u9669\u3002", "method": "\u4eceMIT AI\u98ce\u9669\u5e93\u4e2d\u63d0\u53d6\u771f\u5b9eAI\u98ce\u9669\u573a\u666f\uff0c\u6784\u5efa\u5305\u542b2009\u4e2a\u9ad8\u98ce\u9669\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u56da\u5f92\u56f0\u5883\u3001\u730e\u9e7f\u535a\u5f08\u3001\u6597\u9e21\u535a\u5f08\u7b49\u535a\u5f08\u8bba\u7ed3\u6784\u3002\u8bc4\u4f3015\u4e2a\u524d\u6cbf\u6a21\u578b\uff0c\u6d4b\u91cf\u5bf9\u535a\u5f08\u8bba\u63d0\u793a\u6846\u67b6\u548c\u987a\u5e8f\u7684\u654f\u611f\u6027\uff0c\u5e76\u5206\u6790\u5bfc\u81f4\u5931\u8d25\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "result": "\u572815\u4e2a\u524d\u6cbf\u6a21\u578b\u4e2d\uff0c\u667a\u80fd\u4f53\u4ec5\u572862%\u7684\u60c5\u51b5\u4e0b\u9009\u62e9\u5bf9\u793e\u4f1a\u6709\u76ca\u7684\u884c\u52a8\uff0c\u7ecf\u5e38\u5bfc\u81f4\u6709\u5bb3\u7ed3\u679c\u3002\u535a\u5f08\u8bba\u5e72\u9884\u53ef\u4ee5\u5c06\u793e\u4f1a\u6709\u76ca\u7ed3\u679c\u63d0\u9ad818%\u3002\u7814\u7a76\u63ed\u793a\u4e86\u663e\u8457\u7684\u53ef\u9760\u6027\u5dee\u8ddd\u3002", "conclusion": "GT-HarmBench\u4e3a\u7814\u7a76\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u7684\u6807\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u63ed\u793a\u4e86\u524d\u6cbfAI\u7cfb\u7edf\u5728\u591a\u667a\u80fd\u4f53\u534f\u8c03\u65b9\u9762\u7684\u91cd\u5927\u5b89\u5168\u7f3a\u9677\uff0c\u5e76\u5c55\u793a\u4e86\u535a\u5f08\u8bba\u5e72\u9884\u7684\u6539\u8fdb\u6f5c\u529b\u3002"}}
{"id": "2602.12389", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.12389", "abs": "https://arxiv.org/abs/2602.12389", "authors": ["Siyuan Li", "Yunjia Wu", "Yiyong Xiao", "Pingyang Huang", "Peize Li", "Ruitong Liu", "Yan Wen", "Te Sun", "Fangyi Pei"], "title": "Evolving Beyond Snapshots: Harmonizing Structure and Sequence via Entity State Tuning for Temporal Knowledge Graph Forecasting", "comment": null, "summary": "Temporal knowledge graph (TKG) forecasting requires predicting future facts by jointly modeling structural dependencies within each snapshot and temporal evolution across snapshots. However, most existing methods are stateless: they recompute entity representations at each timestamp from a limited query window, leading to episodic amnesia and rapid decay of long-term dependencies. To address this limitation, we propose Entity State Tuning (EST), an encoder-agnostic framework that endows TKG forecasters with persistent and continuously evolving entity states. EST maintains a global state buffer and progressively aligns structural evidence with sequential signals via a closed-loop design. Specifically, a topology-aware state perceiver first injects entity-state priors into structural encoding. Then, a unified temporal context module aggregates the state-enhanced events with a pluggable sequence backbone. Subsequently, a dual-track evolution mechanism writes the updated context back to the global entity state memory, balancing plasticity against stability. Experiments on multiple benchmarks show that EST consistently improves diverse backbones and achieves state-of-the-art performance, highlighting the importance of state persistence for long-horizon TKG forecasting. The code is published at https://github.com/yuanwuyuan9/Evolving-Beyond-Snapshots", "AI": {"tldr": "EST\u6846\u67b6\u901a\u8fc7\u7ef4\u62a4\u6301\u7eed\u6f14\u5316\u7684\u5b9e\u4f53\u72b6\u6001\u6765\u89e3\u51b3TKG\u9884\u6d4b\u4e2d\u7684\u957f\u671f\u4f9d\u8d56\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u79cd\u9aa8\u5e72\u6a21\u578b\u7684\u6027\u80fd", "motivation": "\u73b0\u6709TKG\u9884\u6d4b\u65b9\u6cd5\u5927\u591a\u662f\u65e0\u72b6\u6001\u7684\uff0c\u6bcf\u6b21\u65f6\u95f4\u6233\u90fd\u4ece\u6709\u9650\u67e5\u8be2\u7a97\u53e3\u91cd\u65b0\u8ba1\u7b97\u5b9e\u4f53\u8868\u793a\uff0c\u5bfc\u81f4\"\u60c5\u666f\u6027\u9057\u5fd8\"\u548c\u957f\u671f\u4f9d\u8d56\u5feb\u901f\u8870\u51cf", "method": "\u63d0\u51faEntity State Tuning\uff08EST\uff09\u6846\u67b6\uff1a1\uff09\u62d3\u6251\u611f\u77e5\u72b6\u6001\u611f\u77e5\u5668\u6ce8\u5165\u5b9e\u4f53\u72b6\u6001\u5148\u9a8c\uff1b2\uff09\u7edf\u4e00\u65f6\u5e8f\u4e0a\u4e0b\u6587\u6a21\u5757\u805a\u5408\u72b6\u6001\u589e\u5f3a\u4e8b\u4ef6\uff1b3\uff09\u53cc\u8f68\u6f14\u5316\u673a\u5236\u66f4\u65b0\u5168\u5c40\u5b9e\u4f53\u72b6\u6001\u5185\u5b58\uff0c\u5e73\u8861\u53ef\u5851\u6027\u4e0e\u7a33\u5b9a\u6027", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEST\u6301\u7eed\u6539\u8fdb\u4e0d\u540c\u9aa8\u5e72\u6a21\u578b\u5e76\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u72b6\u6001\u6301\u4e45\u6027\u5bf9\u957f\u671fTKG\u9884\u6d4b\u7684\u91cd\u8981\u6027", "conclusion": "EST\u6846\u67b6\u901a\u8fc7\u8d4b\u4e88TKG\u9884\u6d4b\u5668\u6301\u4e45\u4e14\u6301\u7eed\u6f14\u5316\u7684\u5b9e\u4f53\u72b6\u6001\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u671f\u4f9d\u8d56\u95ee\u9898\uff0c\u4e3aTKG\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.12566", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12566", "abs": "https://arxiv.org/abs/2602.12566", "authors": ["Haoqing Wang", "Xiang Long", "Ziheng Li", "Yilong Xu", "Tingguang Li", "Yehui Tang"], "title": "To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) plays a key role in stimulating the explicit reasoning capability of Large Language Models (LLMs). We can achieve expert-level performance in some specific domains via RLVR, such as coding or math. When a general multi-domain expert-level model is required, we need to carefully consider the collaboration of RLVR across different domains. The current state-of-the-art models mainly employ two different training paradigms for multi-domain RLVR: mixed multi-task RLVR and separate RLVR followed by model merging. However, most of the works did not provide a detailed comparison and analysis about these paradigms. To this end, we choose multiple commonly used high-level tasks (e.g., math, coding, science, and instruction following) as our target domains and design extensive qualitative and quantitative experiments using open-source datasets. We find the RLVR across domains exhibits few mutual interferences, and reasoning-intensive domains demonstrate mutually synergistic effects. Furthermore, we analyze the internal mechanisms of mutual gains from the perspectives of weight space geometry, model prediction behavior, and information constraints. This project is named as M2RL that means Mixed multi-task training or separate training followed by model Merging for Reinforcement Learning, and the homepage is at https://github.com/mosAI25/M2RL", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u591a\u9886\u57df\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u4e2d\u4e0d\u540c\u8bad\u7ec3\u8303\u5f0f\u7684\u6bd4\u8f83\uff0c\u53d1\u73b0\u8de8\u9886\u57dfRLVR\u5b58\u5728\u76f8\u4e92\u589e\u76ca\u6548\u5e94\uff0c\u7279\u522b\u662f\u63a8\u7406\u5bc6\u96c6\u578b\u9886\u57df\u4e4b\u95f4\u8868\u73b0\u51fa\u534f\u540c\u4f5c\u7528\u3002", "motivation": "\u5f53\u524d\u591a\u9886\u57df\u4e13\u5bb6\u7ea7\u6a21\u578b\u9700\u8981\u8de8\u9886\u57dfRLVR\u534f\u4f5c\uff0c\u4f46\u73b0\u6709\u4e24\u79cd\u4e3b\u8981\u8bad\u7ec3\u8303\u5f0f\uff08\u6df7\u5408\u591a\u4efb\u52a1RLVR\u548c\u5355\u72ec\u8bad\u7ec3\u540e\u6a21\u578b\u5408\u5e76\uff09\u7f3a\u4e4f\u8be6\u7ec6\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u4e0d\u540c\u8303\u5f0f\u5728\u591a\u9886\u57dfRLVR\u4e2d\u7684\u6548\u679c\u3002", "method": "\u9009\u62e9\u6570\u5b66\u3001\u7f16\u7a0b\u3001\u79d1\u5b66\u548c\u6307\u4ee4\u8ddf\u968f\u7b49\u591a\u4e2a\u5e38\u7528\u9ad8\u7ea7\u4efb\u52a1\u4f5c\u4e3a\u76ee\u6807\u9886\u57df\uff0c\u4f7f\u7528\u5f00\u6e90\u6570\u636e\u96c6\u8bbe\u8ba1\u5e7f\u6cdb\u7684\u5b9a\u6027\u548c\u5b9a\u91cf\u5b9e\u9a8c\uff0c\u5206\u6790\u6743\u91cd\u7a7a\u95f4\u51e0\u4f55\u3001\u6a21\u578b\u9884\u6d4b\u884c\u4e3a\u548c\u4fe1\u606f\u7ea6\u675f\u7b49\u5185\u90e8\u673a\u5236\u3002", "result": "\u53d1\u73b0\u8de8\u9886\u57dfRLVR\u5b58\u5728\u8f83\u5c11\u76f8\u4e92\u5e72\u6270\uff0c\u63a8\u7406\u5bc6\u96c6\u578b\u9886\u57df\u4e4b\u95f4\u8868\u73b0\u51fa\u76f8\u4e92\u534f\u540c\u6548\u5e94\uff0c\u4ece\u6743\u91cd\u7a7a\u95f4\u51e0\u4f55\u3001\u6a21\u578b\u9884\u6d4b\u884c\u4e3a\u548c\u4fe1\u606f\u7ea6\u675f\u89d2\u5ea6\u5206\u6790\u4e86\u76f8\u4e92\u589e\u76ca\u7684\u5185\u90e8\u673a\u5236\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u9886\u57dfRLVR\u8bad\u7ec3\u8303\u5f0f\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\uff0c\u63ed\u793a\u4e86\u8de8\u9886\u57df\u534f\u540c\u6548\u5e94\u7684\u5b58\u5728\uff0c\u7279\u522b\u662f\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e4b\u95f4\u7684\u76f8\u4e92\u589e\u76ca\uff0c\u5bf9\u6784\u5efa\u901a\u7528\u591a\u9886\u57df\u4e13\u5bb6\u6a21\u578b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.12586", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12586", "abs": "https://arxiv.org/abs/2602.12586", "authors": ["Joshua Ong Jun Leang", "Yu Zhao", "Mihaela C\u0103t\u0103lina Stoian", "Wenda Li", "Shay B. Cohen", "Eleonora Giunchiglia"], "title": "Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models", "comment": "8 pages, preprint", "summary": "While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). McDiffuSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders. Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while McDiffuSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs.", "AI": {"tldr": "McDiffuSE\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4f18\u5316\u63a9\u7801\u6269\u6563\u6a21\u578b\u4e2d\u7684\u69fd\u586b\u5145\u987a\u5e8f\uff0c\u901a\u8fc7\u524d\u77bb\u6a21\u62df\u8bc4\u4f30\u90e8\u5206\u5b8c\u6210\u60c5\u51b5\uff0c\u5728\u6570\u5b66\u548c\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u57fa\u4e8e\u63a9\u7801\u6269\u6563\u6a21\u578b\u7684\u8ba1\u5212-\u586b\u5145\u89e3\u7801\u5728\u6570\u5b66\u548c\u4ee3\u7801\u63a8\u7406\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u6027\u80fd\u5bf9\u69fd\u586b\u5145\u987a\u5e8f\u9ad8\u5ea6\u654f\u611f\uff0c\u5bfc\u81f4\u8f93\u51fa\u65b9\u5dee\u8f83\u5927\u3002\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u6765\u4f18\u5316\u586b\u5145\u987a\u5e8f\u4ee5\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\u3002", "method": "\u63d0\u51faMcDiffuSE\u6846\u67b6\uff0c\u5c06\u69fd\u9009\u62e9\u5efa\u6a21\u4e3a\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4f18\u5316\u586b\u5145\u987a\u5e8f\u3002\u901a\u8fc7\u524d\u77bb\u6a21\u62df\u8bc4\u4f30\u90e8\u5206\u5b8c\u6210\u60c5\u51b5\uff0c\u5728\u627f\u8bfa\u524d\u7cfb\u7edf\u63a2\u7d22\u751f\u6210\u987a\u5e8f\u7684\u7ec4\u5408\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5e73\u5747\u6bd4\u81ea\u56de\u5f52\u57fa\u7ebf\u63d0\u53473.2%\uff0c\u6bd4\u57fa\u7ebf\u8ba1\u5212-\u586b\u5145\u65b9\u6cd5\u63d0\u53478.0%\u3002\u5728MBPP\u4e0a\u83b7\u5f9719.5%\u7684\u663e\u8457\u63d0\u5347\uff0c\u5728MATH500\u4e0a\u63d0\u53474.9%\u3002\u5206\u6790\u53d1\u73b0McDiffuSE\u4e3b\u8981\u9075\u5faa\u987a\u5e8f\u751f\u6210\uff0c\u4f46\u7ed3\u5408\u975e\u987a\u5e8f\u751f\u6210\u5bf9\u6700\u5927\u5316\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u89c4\u5212\u662f\u63d0\u5347\u63a9\u7801\u6269\u6563\u6a21\u578b\u751f\u6210\u8d28\u91cf\u7684\u6709\u6548\u65b9\u6cd5\u3002\u7814\u7a76\u53d1\u73b0\u8f83\u5927\u7684\u63a2\u7d22\u5e38\u6570\uff08\u800c\u975e\u66f4\u591a\u6a21\u62df\uff09\u5bf9\u4e8e\u514b\u670d\u6a21\u578b\u7f6e\u4fe1\u5ea6\u504f\u5dee\u548c\u53d1\u73b0\u6709\u6548\u987a\u5e8f\u662f\u5fc5\u8981\u7684\u3002"}}
{"id": "2602.12662", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.12662", "abs": "https://arxiv.org/abs/2602.12662", "authors": ["Ruihan Yang", "Fanghua Ye", "Xiang We", "Ruoqing Zhao", "Kang Luo", "Xinbo Xu", "Bo Zhao", "Ruotian Ma", "Shanyi Wang", "Zhaopeng Tu", "Xiaolong Li", "Deqing Yang", "Linus"], "title": "Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigidity is inefficient for long-horizon tasks, where cognitive demands vary significantly from step to step, with some requiring strategic planning and others only routine execution. In this paper, we introduce CogRouter, a framework that trains agents to dynamically adapt cognitive depth at each step. Grounded in ACT-R theory, we design four hierarchical cognitive levels ranging from instinctive responses to strategic planning. Our two-stage training approach includes Cognition-aware Supervised Fine-tuning (CoSFT) to instill stable level-specific patterns, and Cognition-aware Policy Optimization (CoPO) for step-level credit assignment via confidence-aware advantage reweighting. The key insight is that appropriate cognitive depth should maximize the confidence of the resulting action. Experiments on ALFWorld and ScienceWorld demonstrate that CogRouter achieves state-of-the-art performance with superior efficiency. With Qwen2.5-7B, it reaches an 82.3% success rate, outperforming GPT-4o (+40.3%), OpenAI-o3 (+18.3%), and GRPO (+14.0%), while using 62% fewer tokens.", "AI": {"tldr": "CogRouter\u662f\u4e00\u4e2a\u8ba9LLM\u667a\u80fd\u4f53\u52a8\u6001\u8c03\u6574\u8ba4\u77e5\u6df1\u5ea6\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u8ba4\u77e5\u7ea7\u522b\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u6548\u51b3\u7b56\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u4f7f\u7528\u56fa\u5b9a\u7684\u8ba4\u77e5\u6a21\u5f0f\uff1a\u975e\u601d\u8003\u6a21\u578b\u76f4\u63a5\u751f\u6210\u54cd\u5e94\uff0c\u601d\u8003\u6a21\u578b\u5219\u7edf\u4e00\u8fdb\u884c\u6df1\u5ea6\u63a8\u7406\u3002\u8fd9\u79cd\u521a\u6027\u5bf9\u4e8e\u957f\u89c6\u91ce\u4efb\u52a1\u6548\u7387\u4f4e\u4e0b\uff0c\u56e0\u4e3a\u4e0d\u540c\u6b65\u9aa4\u7684\u8ba4\u77e5\u9700\u6c42\u5dee\u5f02\u5f88\u5927\uff0c\u6709\u4e9b\u9700\u8981\u6218\u7565\u89c4\u5212\uff0c\u6709\u4e9b\u53ea\u9700\u5e38\u89c4\u6267\u884c\u3002", "method": "\u57fa\u4e8eACT-R\u7406\u8bba\u8bbe\u8ba1\u4e86\u56db\u4e2a\u5206\u5c42\u8ba4\u77e5\u7ea7\u522b\uff08\u4ece\u672c\u80fd\u53cd\u5e94\u5230\u6218\u7565\u89c4\u5212\uff09\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u8ba4\u77e5\u611f\u77e5\u76d1\u7763\u5fae\u8c03\uff08CoSFT\uff09\u5efa\u7acb\u7a33\u5b9a\u7684\u7ea7\u522b\u7279\u5b9a\u6a21\u5f0f\uff0c\u8ba4\u77e5\u611f\u77e5\u7b56\u7565\u4f18\u5316\uff08CoPO\uff09\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u611f\u77e5\u4f18\u52bf\u91cd\u52a0\u6743\u8fdb\u884c\u6b65\u9aa4\u7ea7\u4fe1\u7528\u5206\u914d\u3002\u6838\u5fc3\u6d1e\u5bdf\u662f\u9002\u5f53\u7684\u8ba4\u77e5\u6df1\u5ea6\u5e94\u6700\u5927\u5316\u6700\u7ec8\u884c\u52a8\u7684\u7f6e\u4fe1\u5ea6\u3002", "result": "\u5728ALFWorld\u548cScienceWorld\u5b9e\u9a8c\u4e2d\uff0cCogRouter\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u4e14\u6548\u7387\u4f18\u8d8a\u3002\u4f7f\u7528Qwen2.5-7B\u6a21\u578b\uff0c\u8fbe\u523082.3%\u7684\u6210\u529f\u7387\uff0c\u4f18\u4e8eGPT-4o\uff08+40.3%\uff09\u3001OpenAI-o3\uff08+18.3%\uff09\u548cGRPO\uff08+14.0%\uff09\uff0c\u540c\u65f6\u4f7f\u752862%\u66f4\u5c11\u7684token\u3002", "conclusion": "CogRouter\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8ba4\u77e5\u6df1\u5ea6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u667a\u80fd\u4f53\u5728\u957f\u89c6\u91ce\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u81ea\u9002\u5e94\u8ba4\u77e5\u7b56\u7565\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.12665", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12665", "abs": "https://arxiv.org/abs/2602.12665", "authors": ["Na\u00efm Es-sebbani", "Esteban Marquer", "Yakoub Salhi", "Zied Bouraoui"], "title": "Evaluating Robustness of Reasoning Models on Parameterized Logical Problems", "comment": null, "summary": "Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine satisfiability. We introduce a diagnostic benchmark for 2-SAT built from parameterized families of structured 2--CNF formulas, where satisfiability is characterized by the implication graph and can be tuned along interpretable axes. Our generators isolate distinct competencies and failure modes: (i) contradiction-cycle UNSAT cores with controllable size and imbalance, (ii) SAT instances with a prescribed fraction of free variables to control solution multiplicity, (iii) planted backbones that modulate propagation, (iv) late bridge clauses that couple otherwise monotone regions to probe sensitivity to ordering and revision, and (v) symmetry/duplication variants that test abstraction under renaming and redundant structure. We evaluate LLM-based reasoners on decision accuracy and assignment validity, and quantify robustness under semantics-preserving perturbations such as clause reordering, filler clauses, and variable renaming. Across models, we observe sharp performance transitions under targeted structural interventions even when surface statistics are held fixed, revealing brittleness regimes that are invisible to aggregate SAT accuracy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u63a8\u7406\u5668\u7684\u8bca\u65ad\u60272-SAT\u57fa\u51c6\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u516c\u5f0f\u5bb6\u65cf\u5206\u79bb\u8868\u9762\u96be\u5ea6\u4e0e\u7ed3\u6784\u73b0\u8c61\uff0c\u63ed\u793aLLM\u5728\u7279\u5b9a\u7ed3\u6784\u5e72\u9884\u4e0b\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u4f20\u7edfSAT\u57fa\u51c6\u5e38\u5c06\u8868\u9762\u96be\u5ea6\uff08\u957f\u5ea6\u3001\u63aa\u8f9e\u3001\u5b50\u53e5\u987a\u5e8f\uff09\u4e0e\u51b3\u5b9a\u53ef\u6ee1\u8db3\u6027\u7684\u7ed3\u6784\u73b0\u8c61\u6df7\u4e3a\u4e00\u8c08\uff0c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30LLM\u63a8\u7406\u5668\u7684\u771f\u5b9e\u80fd\u529b\u3002\u9700\u8981\u6784\u5efa\u80fd\u591f\u5206\u79bb\u8fd9\u4e9b\u56e0\u7d20\u7684\u8bca\u65ad\u6027\u57fa\u51c6\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u53c2\u6570\u53162-CNF\u516c\u5f0f\u5bb6\u65cf\u7684\u8bca\u65ad\u57fa\u51c6\uff0c\u901a\u8fc7\u4e94\u79cd\u751f\u6210\u5668\u9694\u79bb\u4e0d\u540c\u80fd\u529b\uff1a\u77db\u76fe\u5faa\u73afUNSAT\u6838\u5fc3\u3001\u63a7\u5236\u89e3\u591a\u6837\u6027\u7684SAT\u5b9e\u4f8b\u3001\u9884\u8bbe\u9aa8\u5e72\u53d8\u91cf\u3001\u5ef6\u8fdf\u6865\u63a5\u5b50\u53e5\u3001\u5bf9\u79f0/\u91cd\u590d\u53d8\u4f53\u3002\u8bc4\u4f30LLM\u5728\u51b3\u7b56\u51c6\u786e\u6027\u548c\u8d4b\u503c\u6709\u6548\u6027\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u6d4b\u8bd5\u8bed\u4e49\u4fdd\u6301\u6270\u52a8\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728\u8868\u9762\u7edf\u8ba1\u7279\u5f81\u56fa\u5b9a\u7684\u60c5\u51b5\u4e0b\uff0cLLM\u5728\u7279\u5b9a\u7ed3\u6784\u5e72\u9884\u4e0b\u8868\u73b0\u51fa\u6025\u5267\u7684\u6027\u80fd\u8f6c\u53d8\uff0c\u63ed\u793a\u4e86\u5728\u805a\u5408SAT\u51c6\u786e\u7387\u4e2d\u4e0d\u53ef\u89c1\u7684\u8106\u5f31\u6027\u533a\u57df\u3002\u4e0d\u540c\u6a21\u578b\u90fd\u663e\u793a\u51fa\u5bf9\u7ed3\u6784\u53d8\u5316\u7684\u654f\u611f\u6027\u3002", "conclusion": "\u8be5\u8bca\u65ad\u57fa\u51c6\u80fd\u591f\u6709\u6548\u63ed\u793aLLM\u63a8\u7406\u5668\u7684\u7ed3\u6784\u8106\u5f31\u6027\uff0c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbLLM\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u5de5\u5177\u3002\u7ed3\u6784\u5e72\u9884\u6bd4\u8868\u9762\u7279\u5f81\u66f4\u80fd\u66b4\u9732LLM\u7684\u63a8\u7406\u5c40\u9650\u6027\u3002"}}
{"id": "2602.12670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12670", "abs": "https://arxiv.org/abs/2602.12670", "authors": ["Xiangyi Li", "Wenbo Chen", "Yimin Liu", "Shenghan Zheng", "Xiaokun Chen", "Yifeng He", "Yubo Li", "Bingran You", "Haotian Shen", "Jiankai Sun", "Shuyi Wang", "Qunhong Zeng", "Di Wang", "Xuandong Zhao", "Yuanli Wang", "Roey Ben Chaim", "Zonglin Di", "Yipeng Gao", "Junwei He", "Yizhuo He", "Liqiang Jing", "Luyang Kong", "Xin Lan", "Jiachen Li", "Songlin Li", "Yijiang Li", "Yueqian Lin", "Xinyi Liu", "Xuanqing Liu", "Haoran Lyu", "Ze Ma", "Bowei Wang", "Runhui Wang", "Tianyu Wang", "Wengao Ye", "Yue Zhang", "Hanwen Xing", "Yiqi Xue", "Steven Dillmann", "Han-chung Lee"], "title": "SkillsBench: Benchmarking How Well Agent Skills Work Across Diverse Tasks", "comment": null, "summary": "Agent Skills are structured packages of procedural knowledge that augment LLM agents at inference time. Despite rapid adoption, there is no standard way to measure whether they actually help. We present SkillsBench, a benchmark of 86 tasks across 11 domains paired with curated Skills and deterministic verifiers. Each task is evaluated under three conditions: no Skills, curated Skills, and self-generated Skills. We test 7 agent-model configurations over 7,308 trajectories. Curated Skills raise average pass rate by 16.2 percentage points(pp), but effects vary widely by domain (+4.5pp for Software Engineering to +51.9pp for Healthcare) and 16 of 84 tasks show negative deltas. Self-generated Skills provide no benefit on average, showing that models cannot reliably author the procedural knowledge they benefit from consuming. Focused Skills with 2--3 modules outperform comprehensive documentation, and smaller models with Skills can match larger models without them.", "AI": {"tldr": "SkillsBench\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30Agent Skills\u5bf9LLM\u667a\u80fd\u4f53\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6280\u80fd\u80fd\u5e73\u5747\u63d0\u534716.2\u4e2a\u767e\u5206\u70b9\uff0c\u4f46\u6548\u679c\u56e0\u9886\u57df\u5dee\u5f02\u5927\uff0c\u81ea\u751f\u6210\u6280\u80fd\u65e0\u76ca\uff0c\u5c0f\u800c\u7cbe\u7684\u6280\u80fd\u4f18\u4e8e\u5168\u9762\u6587\u6863\uff0c\u5c0f\u6a21\u578b\u914d\u6280\u80fd\u53ef\u5ab2\u7f8e\u5927\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1Agent Skills\uff08\u7ed3\u6784\u5316\u7a0b\u5e8f\u77e5\u8bc6\u5305\uff09\u5728\u63a8\u7406\u65f6\u589e\u5f3aLLM\u667a\u80fd\u4f53\u65b9\u9762\u88ab\u8fc5\u901f\u91c7\u7528\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u6807\u51c6\u65b9\u6cd5\u6765\u8861\u91cf\u5b83\u4eec\u662f\u5426\u771f\u6b63\u6709\u6548\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6280\u80fd\u5bf9\u667a\u80fd\u4f53\u6027\u80fd\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u63d0\u51faSkillsBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b11\u4e2a\u9886\u57df\u768486\u4e2a\u4efb\u52a1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u914d\u5907\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6280\u80fd\u548c\u786e\u5b9a\u6027\u9a8c\u8bc1\u5668\u3002\u5728\u4e09\u79cd\u6761\u4ef6\u4e0b\u8bc4\u4f30\uff1a\u65e0\u6280\u80fd\u3001\u7cbe\u5fc3\u8bbe\u8ba1\u6280\u80fd\u3001\u81ea\u751f\u6210\u6280\u80fd\u3002\u6d4b\u8bd57\u79cd\u667a\u80fd\u4f53-\u6a21\u578b\u914d\u7f6e\uff0c\u51717,308\u6761\u8f68\u8ff9\u3002", "result": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6280\u80fd\u5e73\u5747\u901a\u8fc7\u7387\u63d0\u534716.2\u4e2a\u767e\u5206\u70b9\uff0c\u4f46\u6548\u679c\u5dee\u5f02\u663e\u8457\uff1a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u4ec5\u63d0\u53474.5\u4e2a\u767e\u5206\u70b9\uff0c\u533b\u7597\u9886\u57df\u63d0\u534751.9\u4e2a\u767e\u5206\u70b9\uff0c84\u4e2a\u4efb\u52a1\u4e2d\u670916\u4e2a\u663e\u793a\u8d1f\u589e\u957f\u3002\u81ea\u751f\u6210\u6280\u80fd\u5e73\u5747\u65e0\u76ca\u3002\u5305\u542b2-3\u4e2a\u6a21\u5757\u7684\u805a\u7126\u6280\u80fd\u4f18\u4e8e\u5168\u9762\u6587\u6863\u3002\u914d\u5907\u6280\u80fd\u7684\u5c0f\u6a21\u578b\u6027\u80fd\u53ef\u5ab2\u7f8e\u65e0\u6280\u80fd\u7684\u5927\u6a21\u578b\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684Agent Skills\u80fd\u663e\u8457\u63d0\u5347LLM\u667a\u80fd\u4f53\u6027\u80fd\uff0c\u4f46\u6548\u679c\u9ad8\u5ea6\u4f9d\u8d56\u9886\u57df\u548c\u4efb\u52a1\u7279\u6027\u3002\u6a21\u578b\u65e0\u6cd5\u53ef\u9760\u5730\u751f\u6210\u5b83\u4eec\u80fd\u4ece\u4e2d\u53d7\u76ca\u7684\u7a0b\u5e8f\u77e5\u8bc6\u3002\u5c0f\u800c\u7cbe\u7684\u6280\u80fd\u8bbe\u8ba1\u7b56\u7565\u66f4\u6709\u6548\uff0c\u6280\u80fd\u914d\u7f6e\u53ef\u4f7f\u5c0f\u6a21\u578b\u8fbe\u5230\u5927\u6a21\u578b\u6c34\u5e73\u3002"}}
{"id": "2602.12748", "categories": ["cs.AI", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.12748", "abs": "https://arxiv.org/abs/2602.12748", "authors": ["Tobias Labarta", "Nhi Hoang", "Maximilian Dreyer", "Jim Berend", "Oleg Hein", "Jackie Ma", "Wojciech Samek", "Sebastian Lapuschkin"], "title": "X-SYS: A Reference Architecture for Interactive Explanation Systems", "comment": "18 pages, 8 figures", "summary": "The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system capabilities that maintain explanation usability across repeated queries, evolving models and data, and governance constraints. We argue that operationalizing XAI requires treating explainability as an information systems problem where user interaction demands induce specific system requirements. We introduce X-SYS, a reference architecture for interactive explanation systems, that guides (X)AI researchers, developers and practitioners in connecting interactive explanation user interfaces (XUI) with system capabilities. X-SYS organizes around four quality attributes named STAR (scalability, traceability, responsiveness, and adaptability), and specifies a five-component decomposition (XUI Services, Explanation Services, Model Services, Data Services, Orchestration and Governance). It maps interaction patterns to system capabilities to decouple user interface evolution from backend computation. We implement X-SYS through SemanticLens, a system for semantic search and activation steering in vision-language models. SemanticLens demonstrates how contract-based service boundaries enable independent evolution, offline/online separation ensures responsiveness, and persistent state management supports traceability. Together, this work provides a reusable blueprint and concrete instantiation for interactive explanation systems supporting end-to-end design under operational constraints.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faX-SYS\u53c2\u8003\u67b6\u6784\uff0c\u5c06\u53ef\u89e3\u91caAI\u4ece\u7b97\u6cd5\u95ee\u9898\u8f6c\u53d8\u4e3a\u4fe1\u606f\u7cfb\u7edf\u95ee\u9898\uff0c\u901a\u8fc7STAR\u8d28\u91cf\u5c5e\u6027\u548c\u4e94\u7ec4\u4ef6\u5206\u89e3\uff0c\u4e3a\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7cfb\u7edf\u63d0\u4f9b\u53ef\u91cd\u7528\u84dd\u56fe\uff0c\u5e76\u5728SemanticLens\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91caAI\u7814\u7a76\u867d\u7136\u63d0\u51fa\u4e86\u4f17\u591a\u6280\u672f\u65b9\u6cd5\uff0c\u4f46\u5c06\u53ef\u89e3\u91ca\u6027\u90e8\u7f72\u4e3a\u5b9e\u9645\u7cfb\u7edf\u4ecd\u9762\u4e34\u6311\u6218\u3002\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7cfb\u7edf\u9700\u8981\u5408\u9002\u7684\u7b97\u6cd5\u548c\u7cfb\u7edf\u80fd\u529b\uff0c\u4ee5\u5728\u91cd\u590d\u67e5\u8be2\u3001\u6a21\u578b\u6570\u636e\u6f14\u8fdb\u548c\u6cbb\u7406\u7ea6\u675f\u4e0b\u4fdd\u6301\u89e3\u91ca\u53ef\u7528\u6027\u3002\u4f5c\u8005\u8ba4\u4e3a\u9700\u8981\u5c06\u53ef\u89e3\u91caAI\u89c6\u4e3a\u4fe1\u606f\u7cfb\u7edf\u95ee\u9898\uff0c\u7528\u6237\u4ea4\u4e92\u9700\u6c42\u4f1a\u5f15\u53d1\u7279\u5b9a\u7684\u7cfb\u7edf\u8981\u6c42\u3002", "method": "\u63d0\u51faX-SYS\u53c2\u8003\u67b6\u6784\uff0c\u56f4\u7ed5STAR\u56db\u4e2a\u8d28\u91cf\u5c5e\u6027\uff08\u53ef\u6269\u5c55\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\u3001\u54cd\u5e94\u6027\u3001\u9002\u5e94\u6027\uff09\u7ec4\u7ec7\uff0c\u6307\u5b9a\u4e94\u7ec4\u4ef6\u5206\u89e3\uff08XUI\u670d\u52a1\u3001\u89e3\u91ca\u670d\u52a1\u3001\u6a21\u578b\u670d\u52a1\u3001\u6570\u636e\u670d\u52a1\u3001\u7f16\u6392\u4e0e\u6cbb\u7406\uff09\u3002\u901a\u8fc7\u5c06\u4ea4\u4e92\u6a21\u5f0f\u6620\u5c04\u5230\u7cfb\u7edf\u80fd\u529b\uff0c\u5b9e\u73b0\u7528\u6237\u754c\u9762\u6f14\u8fdb\u4e0e\u540e\u7aef\u8ba1\u7b97\u7684\u89e3\u8026\u3002\u5728SemanticLens\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u8be5\u67b6\u6784\uff0c\u5c55\u793a\u57fa\u4e8e\u5951\u7ea6\u7684\u670d\u52a1\u8fb9\u754c\u3001\u79bb\u7ebf/\u5728\u7ebf\u5206\u79bb\u548c\u6301\u4e45\u72b6\u6001\u7ba1\u7406\u7b49\u673a\u5236\u3002", "result": "X-SYS\u4e3a\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u7684\u84dd\u56fe\uff0cSemanticLens\u7cfb\u7edf\u4f5c\u4e3a\u5177\u4f53\u5b9e\u4f8b\u5316\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u5951\u7ea6\u5f0f\u670d\u52a1\u8fb9\u754c\u652f\u6301\u72ec\u7acb\u6f14\u8fdb\u3001\u79bb\u7ebf/\u5728\u7ebf\u5206\u79bb\u786e\u4fdd\u54cd\u5e94\u6027\u3001\u6301\u4e45\u72b6\u6001\u7ba1\u7406\u652f\u6301\u53ef\u8ffd\u6eaf\u6027\u3002\u8be5\u5de5\u4f5c\u4e3a\u5728\u64cd\u4f5c\u7ea6\u675f\u4e0b\u652f\u6301\u7aef\u5230\u7aef\u8bbe\u8ba1\u7684\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7cfb\u7edf\u63d0\u4f9b\u4e86\u67b6\u6784\u6307\u5bfc\u3002", "conclusion": "\u5c06\u53ef\u89e3\u91caAI\u64cd\u4f5c\u5316\u9700\u8981\u5c06\u5176\u89c6\u4e3a\u4fe1\u606f\u7cfb\u7edf\u95ee\u9898\uff0cX-SYS\u53c2\u8003\u67b6\u6784\u901a\u8fc7STAR\u8d28\u91cf\u5c5e\u6027\u548c\u4e94\u7ec4\u4ef6\u5206\u89e3\uff0c\u4e3a(X)AI\u7814\u7a76\u8005\u3001\u5f00\u53d1\u8005\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u8fde\u63a5\u4ea4\u4e92\u5f0f\u89e3\u91ca\u7528\u6237\u754c\u9762\u4e0e\u7cfb\u7edf\u80fd\u529b\u7684\u6307\u5bfc\u6846\u67b6\uff0c\u652f\u6301\u5728\u64cd\u4f5c\u7ea6\u675f\u4e0b\u7684\u7aef\u5230\u7aef\u7cfb\u7edf\u8bbe\u8ba1\u3002"}}
{"id": "2602.12963", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.12963", "abs": "https://arxiv.org/abs/2602.12963", "authors": ["Alfred Harwood", "Jose Faustino", "Alex Altair"], "title": "Information-theoretic analysis of world models in optimal reward maximizers", "comment": "28 pages, 0 figures. Not submitted to any conference yet", "summary": "An important question in the field of AI is the extent to which successful behaviour requires an internal representation of the world. In this work, we quantify the amount of information an optimal policy provides about the underlying environment. We consider a Controlled Markov Process (CMP) with $n$ states and $m$ actions, assuming a uniform prior over the space of possible transition dynamics. We prove that observing a deterministic policy that is optimal for any non-constant reward function then conveys exactly $n \\log m$ bits of information about the environment. Specifically, we show that the mutual information between the environment and the optimal policy is $n \\log m$ bits. This bound holds across a broad class of objectives, including finite-horizon, infinite-horizon discounted, and time-averaged reward maximization. These findings provide a precise information-theoretic lower bound on the \"implicit world model'' necessary for optimality.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u4fe1\u606f\u8bba\u65b9\u6cd5\u91cf\u5316\u4e86\u6700\u4f18\u7b56\u7565\u5bf9\u73af\u5883\u4fe1\u606f\u7684\u63ed\u793a\u7a0b\u5ea6\uff0c\u8bc1\u660e\u4e86\u786e\u5b9a\u6027\u6700\u4f18\u7b56\u7565\u6070\u597d\u4f20\u9012n log m\u6bd4\u7279\u7684\u73af\u5883\u4fe1\u606f", "motivation": "\u7814\u7a76AI\u9886\u57df\u4e2d\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\uff1a\u6210\u529f\u884c\u4e3a\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u9700\u8981\u5185\u90e8\u4e16\u754c\u8868\u793a\u3002\u91cf\u5316\u6700\u4f18\u7b56\u7565\u63d0\u4f9b\u7684\u5173\u4e8e\u5e95\u5c42\u73af\u5883\u7684\u4fe1\u606f\u91cf\uff0c\u4e3a\u7406\u89e3\"\u9690\u5f0f\u4e16\u754c\u6a21\u578b\"\u63d0\u4f9b\u7406\u8bba\u57fa\u7840", "method": "\u91c7\u7528\u53d7\u63a7\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u6a21\u578b\uff0c\u5047\u8bben\u4e2a\u72b6\u6001\u548cm\u4e2a\u52a8\u4f5c\uff0c\u5728\u53ef\u80fd\u7684\u8f6c\u79fb\u52a8\u6001\u7a7a\u95f4\u4e0a\u91c7\u7528\u5747\u5300\u5148\u9a8c\u3002\u901a\u8fc7\u4fe1\u606f\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u89c2\u5bdf\u786e\u5b9a\u6027\u6700\u4f18\u7b56\u7565\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u4f55\u975e\u5e38\u6570\u5956\u52b1\u51fd\u6570\u7684\u6700\u4f18\u786e\u5b9a\u6027\u7b56\u7565\uff0c\u6070\u597d\u4f20\u9012n log m\u6bd4\u7279\u7684\u73af\u5883\u4fe1\u606f\u3002\u8be5\u754c\u9650\u9002\u7528\u4e8e\u591a\u79cd\u76ee\u6807\u51fd\u6570\uff0c\u5305\u62ec\u6709\u9650\u65f6\u57df\u3001\u65e0\u9650\u65f6\u57df\u6298\u6263\u548c\u65f6\u95f4\u5e73\u5747\u5956\u52b1\u6700\u5927\u5316", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u6700\u4f18\u6027\u6240\u9700\u7684\"\u9690\u5f0f\u4e16\u754c\u6a21\u578b\"\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u4fe1\u606f\u8bba\u4e0b\u754c\uff0c\u8868\u660e\u6700\u4f18\u7b56\u7565\u5fc5\u7136\u7f16\u7801\u4e86\u7279\u5b9a\u91cf\u7684\u73af\u5883\u7ed3\u6784\u4fe1\u606f"}}
{"id": "2602.13093", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13093", "abs": "https://arxiv.org/abs/2602.13093", "authors": ["Yubo Li", "Ramayya Krishnan", "Rema Padman"], "title": "Consistency of Large Reasoning Models Under Multi-Turn Attacks", "comment": null, "summary": "Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e869\u4e2a\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u63a8\u7406\u80fd\u529b\u80fd\u63d0\u4f9b\u4e00\u5b9a\u4f46\u975e\u5b8c\u5168\u7684\u9c81\u68d2\u6027\uff0c\u6240\u6709\u6a21\u578b\u90fd\u6709\u72ec\u7279\u7684\u8106\u5f31\u6027\u7279\u5f81\uff0c\u5e76\u8bc6\u522b\u51fa5\u79cd\u4e3b\u8981\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u591a\u8f6e\u5bf9\u6297\u538b\u529b\u4e0b\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u7814\u7a76\u8005\u5e0c\u671b\u8bc4\u4f30\u63a8\u7406\u6a21\u578b\u5728\u9762\u5bf9\u5bf9\u6297\u653b\u51fb\u65f6\u7684\u8868\u73b0\uff0c\u4e86\u89e3\u63a8\u7406\u80fd\u529b\u662f\u5426\u80fd\u81ea\u52a8\u5e26\u6765\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e869\u4e2a\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u8f68\u8ff9\u5206\u6790\u8bc6\u522b\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u6d4b\u8bd5\u4e86\u7f6e\u4fe1\u5ea6\u611f\u77e5\u54cd\u5e94\u751f\u6210\uff08CARG\uff09\u9632\u5fa1\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u63a8\u7406\u63d0\u4f9b\u6709\u610f\u4e49\u4f46\u4e0d\u5b8c\u5168\u7684\u9c81\u68d2\u6027\uff0c\u63a8\u7406\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u6307\u4ee4\u8c03\u4f18\u57fa\u7ebf\uff1b2\uff09\u6240\u6709\u6a21\u578b\u90fd\u6709\u72ec\u7279\u7684\u8106\u5f31\u6027\u7279\u5f81\uff0c\u8bef\u5bfc\u6027\u5efa\u8bae\u666e\u904d\u6709\u6548\uff0c\u793e\u4f1a\u538b\u529b\u5177\u6709\u6a21\u578b\u7279\u5f02\u6027\uff1b3\uff09\u8bc6\u522b\u51fa5\u79cd\u5931\u8d25\u6a21\u5f0f\uff08\u81ea\u6211\u6000\u7591\u3001\u793e\u4f1a\u4ece\u4f17\u3001\u5efa\u8bae\u52ab\u6301\u3001\u60c5\u7eea\u6613\u611f\u6027\u3001\u63a8\u7406\u75b2\u52b3\uff09\uff0c\u524d\u4e24\u79cd\u536050%\u5931\u8d25\uff1b4\uff09CARG\u9632\u5fa1\u5bf9\u63a8\u7406\u6a21\u578b\u5931\u6548\uff0c\u56e0\u4e3a\u6269\u5c55\u63a8\u7406\u8f68\u8ff9\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u968f\u673a\u7f6e\u4fe1\u5ea6\u5d4c\u5165\u53cd\u800c\u4f18\u4e8e\u9488\u5bf9\u6027\u63d0\u53d6\u3002", "conclusion": "\u63a8\u7406\u80fd\u529b\u4e0d\u4f1a\u81ea\u52a8\u5e26\u6765\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u9632\u5fa1\u65b9\u6cd5\u9700\u8981\u4e3a\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u6839\u672c\u6027\u91cd\u65b0\u8bbe\u8ba1\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u63a8\u7406\u6a21\u578b\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u4e3a\u672a\u6765\u9c81\u68d2\u63a8\u7406\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2602.13135", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.13135", "abs": "https://arxiv.org/abs/2602.13135", "authors": ["Emanuele De Angelis", "Fabio Fioravanti", "Maria Chiara Meo", "Alberto Pettorossi", "Maurizio Proietti", "Francesca Toni"], "title": "Constrained Assumption-Based Argumentation Frameworks", "comment": "Extended version with proofs and additional results of the full paper accepted at the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026). DOI: https://doi.org/10.65109/KRAP9309", "summary": "Assumption-based Argumentation (ABA) is a well-established form of structured argumentation. ABA frameworks with an underlying atomic language are widely studied, but their applicability is limited by a representational restriction to ground (variable-free) arguments and attacks built from propositional atoms. In this paper, we lift this restriction and propose a novel notion of constrained ABA (CABA), whose components, as well as arguments built from them, may include constrained variables, ranging over possibly infinite domains. We define non-ground semantics for CABA, in terms of various notions of non-ground attacks. We show that the new semantics conservatively generalise standard ABA semantics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ea6\u675fABA\uff08CABA\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u7ea6\u675f\u53d8\u91cf\u6765\u6269\u5c55\u4f20\u7edfABA\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u975e\u5730\u9762\uff08\u5305\u542b\u53d8\u91cf\uff09\u7684\u8bba\u8bc1\u548c\u653b\u51fb\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5047\u8bbe\u7684\u8bba\u8bc1\uff08ABA\uff09\u6846\u67b6\u901a\u5e38\u5c40\u9650\u4e8e\u539f\u5b50\u8bed\u8a00\u548c\u5730\u9762\uff08\u65e0\u53d8\u91cf\uff09\u8bba\u8bc1\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u8868\u793a\u80fd\u529b\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u9700\u8981\u6269\u5c55ABA\u6846\u67b6\u4ee5\u652f\u6301\u5305\u542b\u7ea6\u675f\u53d8\u91cf\u7684\u975e\u5730\u9762\u8bba\u8bc1\u3002", "method": "\u63d0\u51fa\u7ea6\u675fABA\uff08CABA\uff09\u6846\u67b6\uff0c\u5141\u8bb8\u7ec4\u4ef6\u548c\u8bba\u8bc1\u4e2d\u5305\u542b\u7ea6\u675f\u53d8\u91cf\uff0c\u8fd9\u4e9b\u53d8\u91cf\u53ef\u4ee5\u5728\u53ef\u80fd\u65e0\u9650\u7684\u57df\u4e0a\u53d6\u503c\u3002\u5b9a\u4e49\u4e86\u57fa\u4e8e\u5404\u79cd\u975e\u5730\u9762\u653b\u51fb\u6982\u5ff5\u7684CABA\u975e\u5730\u9762\u8bed\u4e49\u3002", "result": "\u65b0\u7684CABA\u8bed\u4e49\u80fd\u591f\u4fdd\u5b88\u5730\u63a8\u5e7f\u6807\u51c6ABA\u8bed\u4e49\uff0c\u8bc1\u660e\u65b0\u6846\u67b6\u5728\u8868\u8fbe\u80fd\u529b\u589e\u5f3a\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u4f20\u7edfABA\u7684\u517c\u5bb9\u6027\u3002", "conclusion": "CABA\u6846\u67b6\u6210\u529f\u6269\u5c55\u4e86\u4f20\u7edfABA\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u901a\u8fc7\u5f15\u5165\u7ea6\u675f\u53d8\u91cf\u652f\u6301\u975e\u5730\u9762\u8bba\u8bc1\uff0c\u4e3a\u7ed3\u6784\u5316\u8bba\u8bc1\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u8868\u793a\u5de5\u5177\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u73b0\u6709\u7406\u8bba\u7684\u5411\u540e\u517c\u5bb9\u6027\u3002"}}
{"id": "2602.13166", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13166", "abs": "https://arxiv.org/abs/2602.13166", "authors": ["Hugo Henry", "Arthur Tsai", "Kelly Cohen"], "title": "Optimal Take-off under Fuzzy Clearances", "comment": "12 pages, 12 figures, conference paper", "summary": "This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limitations of classical optimal control under uncertainty and the need for interpretable decision making in safety critical aviation systems, we design a three stage Takagi Sugeno Kang fuzzy layer that modulates constraint radii, urgency levels, and activation decisions based on regulatory separation minima and airworthiness guidelines from FAA and EASA. These fuzzy-derived clearances are then incorporated as soft constraints into an optimal control problem solved using the FALCON toolbox and IPOPT. The framework aims to reduce unnecessary recomputations by selectively activating obstacle avoidance updates while maintaining compliance with aviation procedures. A proof of concept implementation using a simplified aircraft model demonstrates that the approach can generate optimal trajectories with computation times of 2,3 seconds per iteration in a single threaded MATLAB environment, suggesting feasibility for near real time applications. However, our experiments revealed a critical software incompatibility in the latest versions of FALCON and IPOPT, in which the Lagrangian penalty term remained identically zero, preventing proper constraint enforcement. This behavior was consistent across scenarios and indicates a solver toolbox regression rather than a modeling flaw. Future work includes validating this effect by reverting to earlier software versions, optimizing the fuzzy membership functions using evolutionary methods, and extending the system to higher fidelity aircraft models and stochastic obstacle environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u969c\u788d\u7269\u907f\u8ba9\u67b6\u6784\uff0c\u5c06\u6700\u4f18\u63a7\u5236\u4e0e\u6a21\u7cca\u89c4\u5219\u7cfb\u7edf\u7ed3\u5408\uff0c\u4e3a\u65e0\u4eba\u673a\u63d0\u4f9b\u81ea\u9002\u5e94\u7ea6\u675f\u5904\u7406\uff0c\u4f46\u53d1\u73b0\u8f6f\u4ef6\u517c\u5bb9\u6027\u95ee\u9898\u5bfc\u81f4\u7ea6\u675f\u65e0\u6cd5\u6b63\u5e38\u6267\u884c\u3002", "motivation": "\u4f20\u7edf\u6700\u4f18\u63a7\u5236\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u4ee5\u53ca\u822a\u7a7a\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u9700\u8981\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u5236\u5b9a\uff0c\u4fc3\u4f7f\u5f00\u53d1\u8fd9\u79cd\u6df7\u5408\u67b6\u6784\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e09\u9636\u6bb5Takagi-Sugeno-Kang\u6a21\u7cca\u5c42\uff0c\u57fa\u4e8eFAA\u548cEASA\u7684\u76d1\u7ba1\u5206\u79bb\u6700\u5c0f\u503c\u548c\u9002\u822a\u6307\u5357\uff0c\u8c03\u5236\u7ea6\u675f\u534a\u5f84\u3001\u7d27\u6025\u7ea7\u522b\u548c\u6fc0\u6d3b\u51b3\u7b56\uff0c\u7136\u540e\u5c06\u6a21\u7cca\u63a8\u5bfc\u7684\u51c0\u7a7a\u4f5c\u4e3a\u8f6f\u7ea6\u675f\u7eb3\u5165\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u4f7f\u7528FALCON\u5de5\u5177\u7bb1\u548cIPOPT\u6c42\u89e3\u3002", "result": "\u6982\u5ff5\u9a8c\u8bc1\u663e\u793a\u6bcf\u6b21\u8fed\u4ee3\u8ba1\u7b97\u65f6\u95f4\u4e3a2-3\u79d2\uff0c\u5177\u6709\u8fd1\u5b9e\u65f6\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u53d1\u73b0FALCON\u548cIPOPT\u6700\u65b0\u7248\u672c\u5b58\u5728\u8f6f\u4ef6\u4e0d\u517c\u5bb9\u95ee\u9898\uff0c\u62c9\u683c\u6717\u65e5\u60e9\u7f5a\u9879\u6052\u4e3a\u96f6\uff0c\u5bfc\u81f4\u7ea6\u675f\u65e0\u6cd5\u6b63\u5e38\u6267\u884c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u8f6f\u4ef6\u517c\u5bb9\u6027\u95ee\u9898\u9700\u8981\u89e3\u51b3\u3002\u672a\u6765\u5de5\u4f5c\u5305\u62ec\u9a8c\u8bc1\u8f6f\u4ef6\u56de\u5f52\u95ee\u9898\u3001\u4f18\u5316\u6a21\u7cca\u96b6\u5c5e\u51fd\u6570\uff0c\u4ee5\u53ca\u6269\u5c55\u5230\u66f4\u9ad8\u4fdd\u771f\u5ea6\u98de\u673a\u6a21\u578b\u548c\u968f\u673a\u969c\u788d\u73af\u5883\u3002"}}
