<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [NeuroAI and Beyond](https://arxiv.org/abs/2601.19955)
*Jean-Marc Fellous,Gert Cauwenberghs,Cornelia Fermüller,Yulia Sandamisrkaya,Terrence Sejnowski*

Main category: cs.AI

TL;DR: 这篇论文基于2025年8月的工作坊，探讨了神经科学与人工智能之间的协同作用，提出了NeuroAI概念，旨在通过神经科学原理改进AI算法，同时深化对生物神经计算的理解。


<details>
  <summary>Details</summary>
Motivation: 神经科学与人工智能在过去几年都取得了显著进展，但两者之间的联系仍然松散。论文旨在探索这两个领域之间的协同作用，通过整合神经科学原理来改进人工智能算法，同时利用人工智能技术来更好地理解生物神经计算。

Method: 基于2025年8月举办的工作坊，聚焦于具身认知、语言与通信、机器人技术、人类与机器学习以及神经形态工程等子领域。收集了多位领先研究人员的个人观点，并进行了SWOT（优势-劣势-机会-威胁）分析，包括研究人员和学员的视角。

Result: 识别了神经科学与人工智能之间当前和未来的协同领域，提出了NeuroAI（神经科学启发的人工智能）的发展方向。通过SWOT分析揭示了NeuroAI的潜在益处和风险，包括改进AI算法的范围和效率，同时改变对生物神经计算的理解方式。

Conclusion: 论文主张发展NeuroAI，这是一种神经科学启发的人工智能，有望显著提高AI算法的范围和效率，同时改变我们对生物神经计算的理解方式。通过整合两个领域的优势，可以开辟新的研究途径并推动技术进步。

Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possible promising new future avenues. Overall, we advocate for the development of NeuroAI, a type of Neuroscience-informed Artificial Intelligence that, we argue, has the potential for significantly improving the scope and efficiency of AI algorithms while simultaneously changing the way we understand biological neural computations. We include personal statements from several leading researchers on their diverse views of NeuroAI. Two Strength-Weakness-Opportunities-Threat (SWOT) analyses by researchers and trainees are appended that describe the benefits and risks offered by NeuroAI.

</details>


### [2] [Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning](https://arxiv.org/abs/2601.20014)
*Shuhui Qu*

Main category: cs.AI

TL;DR: SQ-BCP是一种在部分可观测环境下进行推理时规划的方法，通过显式表示前提条件状态、自我查询和桥接假设来解决大语言模型在缺失关键前提时产生幻觉或违反约束的问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在部分可观测环境下进行推理时规划时，当任务关键前提条件未在查询时指定，模型倾向于产生幻觉或违反硬约束的计划。需要一种能处理未知前提条件的方法。

Method: 提出自我查询双向分类规划(SQ-BCP)：1)显式表示前提条件状态(Sat/Viol/Unk)；2)通过自我查询或桥接假设解决未知条件；3)执行双向搜索并使用基于拉回的验证器作为目标兼容性的分类证书；4)仅使用基于距离的分数进行排序和剪枝。

Result: 在WikiHow和RecipeNLG任务中，当预条件被隐藏时，SQ-BCP将资源违规率分别降低到14.9%和5.8%（最佳基线为26.0%和15.7%），同时保持有竞争力的参考质量。

Conclusion: SQ-BCP通过显式处理部分可观测性，在理论上保证找到接受计划（当存在时），并在实践中显著减少违反约束的计划生成，同时保持计划质量。

Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (i) targeted self-queries to an oracle/user or (ii) \emph{bridging} hypotheses that establish the missing condition through an additional action. SQ-BCP performs bidirectional search and invokes a pullback-based verifier as a categorical certificate of goal compatibility, while using distance-based scores only for ranking and pruning. We prove that when the verifier succeeds and hard constraints pass deterministic checks, accepted plans are compatible with goal requirements; under bounded branching and finite resolution depth, SQ-BCP finds an accepting plan when one exists. Across WikiHow and RecipeNLG tasks with withheld preconditions, SQ-BCP reduces resource-violation rates to \textbf{14.9\%} and \textbf{5.8\%} (vs.\ \textbf{26.0\%} and \textbf{15.7\%} for the best baseline), while maintaining competitive reference quality.

</details>


### [3] [Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints](https://arxiv.org/abs/2601.20021)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 提出模糊范畴论规划(FCP)，处理自然语言规划中的模糊谓词，通过t-范数组合计划质量，同时保持清晰的执行性检查


<details>
  <summary>Details</summary>
Motivation: 现有范畴论规划器将适用性视为二值判断，无法处理自然语言规划中固有的模糊谓词（如"合适的替代品"、"足够稳定"），导致阈值化会丢失有意义的区别，且无法跟踪多步计划中的质量退化

Method: FCP为每个动作（态射）标注[0,1]区间内的程度值，使用Lukasiewicz t-范数组合计划质量，通过拉回验证保持清晰的执行性检查，使用LLM进行k样本中位数聚合来从语言中获取分级适用性，支持基于剩余的后向需求进行中间相遇搜索

Result: 在RecipeNLG-Subs基准测试中，FCP相比LLM-only和ReAct风格基线提高了成功率并减少了硬约束违反，同时在PDDL3偏好/超额订阅基准测试中与传统PDDL3规划器保持竞争力

Conclusion: FCP能够有效处理自然语言规划中的模糊谓词，在保持执行性检查的同时支持分级适用性评估，为模糊规划问题提供了有效的解决方案

Abstract: Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verification, but treat applicability as crisp, forcing thresholding that collapses meaningful distinctions and cannot track quality degradation across multi-step plans. We propose Fuzzy Category-theoretic Planning (FCP), which annotates each action (morphism) with a degree in [0,1], composes plan quality via a t-norm Lukasiewicz, and retains crisp executability checks via pullback verification. FCP grounds graded applicability from language using an LLM with k-sample median aggregation and supports meeting-in-the-middle search using residuum-based backward requirements. We evaluate on (i) public PDDL3 preference/oversubscription benchmarks and (ii) RecipeNLG-Subs, a missing-substitute recipe-planning benchmark built from RecipeNLG with substitution candidates from Recipe1MSubs and FoodKG. FCP improves success and reduces hard-constraint violations on RecipeNLG-Subs compared to LLM-only and ReAct-style baselines, while remaining competitive with classical PDDL3 planners.

</details>


### [4] [Insight Agents: An LLM-Based Multi-Agent System for Data Insights](https://arxiv.org/abs/2601.20048)
*Jincheng Bai,Zhenyu Zhang,Jennifer Zhang,Zhihuai Zhu*

Main category: cs.AI

TL;DR: 论文提出Insight Agents (IA)系统，这是一个基于LLM的对话式多智能体数据洞察系统，旨在为电商卖家提供个性化数据和商业洞察，通过自动化信息检索帮助卖家更高效地做出商业决策。


<details>
  <summary>Details</summary>
Motivation: 电商卖家面临两大挑战：1）难以发现和有效利用现有程序工具；2）难以理解和利用来自各种工具的丰富数据。因此需要开发一个能够降低卖家决策难度、提高决策速度的系统。

Method: 采用基于规划-执行范式的分层多智能体架构，包括管理智能体和两个工作智能体（数据呈现和洞察生成）。管理智能体使用轻量级编码器-解码器模型进行OOD检测，结合BERT分类器进行智能体路由。工作智能体中设计了API数据模型的战略规划，将查询分解为细粒度组件，并动态注入领域知识增强洞察生成。

Result: 系统已在美国亚马逊卖家平台上线，基于人工评估达到90%的高准确率，P90延迟低于15秒。

Conclusion: Insight Agents系统通过创新的多智能体架构和ML解决方案，成功为电商卖家提供了高效、准确的数据洞察服务，验证了其作为卖家"力量倍增器"的假设。

Abstract: Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Insight Agents (IA), a conversational multi-agent Data Insight system, to provide E-commerce sellers with personalized data and business insights through automated information retrieval. Our hypothesis is that IA will serve as a force multiplier for sellers, thereby driving incremental seller adoption by reducing the effort required and increase speed at which sellers make good business decisions. In this paper, we introduce this novel LLM-backed end-to-end agentic system built on a plan-and-execute paradigm and designed for comprehensive coverage, high accuracy, and low latency. It features a hierarchical multi-agent structure, consisting of manager agent and two worker agents: data presentation and insight generation, for efficient information retrieval and problem-solving. We design a simple yet effective ML solution for manager agent that combines Out-of-Domain (OOD) detection using a lightweight encoder-decoder model and agent routing through a BERT-based classifier, optimizing both accuracy and latency. Within the two worker agents, a strategic planning is designed for API-based data model that breaks down queries into granular components to generate more accurate responses, and domain knowledge is dynamically injected to to enhance the insight generator. IA has been launched for Amazon sellers in US, which has achieved high accuracy of 90% based on human evaluation, with latency of P90 below 15s.

</details>


### [5] [Towards Intelligent Urban Park Development Monitoring: LLM Agents for Multi-Modal Information Fusion and Analysis](https://arxiv.org/abs/2601.20206)
*Zixuan Xiao,Chunguang Hu,Jun Ma*

Main category: cs.AI

TL;DR: 提出了一种多模态LLM智能体框架，用于城市新建公园发展监测，通过数据对齐机制和特定工具包解决传统遥感变化检测方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统基于遥感影像的变化检测方法在高层次智能分析方面存在明显局限，难以满足当前城市规划管理的需求，特别是在处理复杂多模态数据时缺乏灵活分析能力。

Method: 提出多模态LLM智能体框架，设计通用的横向和纵向数据对齐机制确保多模态数据一致性，构建特定工具包缓解LLM因缺乏领域知识而产生的幻觉问题。

Result: 相比vanilla GPT-4o和其他智能体，该方法能够实现稳健的多模态信息融合与分析，为城市公园发展监测提供可靠且可扩展的解决方案。

Conclusion: 该多模态LLM智能体框架能够充分利用LLM的语义理解和推理能力，有效应对城市公园发展监测中的挑战，满足多样化和不断变化的需求。

Abstract: As an important part of urbanization, the development monitoring of newly constructed parks is of great significance for evaluating the effect of urban planning and optimizing resource allocation. However, traditional change detection methods based on remote sensing imagery have obvious limitations in high-level and intelligent analysis, and thus are difficult to meet the requirements of current urban planning and management. In face of the growing demand for complex multi-modal data analysis in urban park development monitoring, these methods often fail to provide flexible analysis capabilities for diverse application scenarios. This study proposes a multi-modal LLM agent framework, which aims to make full use of the semantic understanding and reasoning capabilities of LLM to meet the challenges in urban park development monitoring. In this framework, a general horizontal and vertical data alignment mechanism is designed to ensure the consistency and effective tracking of multi-modal data. At the same time, a specific toolkit is constructed to alleviate the hallucination issues of LLM due to the lack of domain-specific knowledge. Compared to vanilla GPT-4o and other agents, our approach enables robust multi-modal information fusion and analysis, offering reliable and scalable solutions tailored to the diverse and evolving demands of urban park development monitoring.

</details>


### [6] [Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2601.20221)
*Hang Zhang,Ruheng Wang,Yuelyu Ji,Mingu Kwak,Xizhi Wu,Chenyu Li,Li Zhang,Wenqi Shi,Yifan Peng,Yanshan Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为$\method$的智能框架，通过训练医学推理验证器在评估过程中迭代查询外部医学语料库，解决了现有奖励模型只能提供标量奖励值且依赖单次检索的问题，显著提升了医学推理的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学推理基准测试中表现出色，但在临床部署时需要确保事实准确性。现有奖励模型方法存在两个局限：只能产生标量奖励值而缺乏明确理由，且依赖单次检索无法在验证过程中进行自适应知识访问。

Method: $\method$框架结合工具增强验证与迭代强化学习范式，训练医学推理验证器在评估过程中迭代查询外部医学语料库。该方法仅需要轨迹级监督，并包含自适应课程机制动态调整训练数据分布。

Result: 在四个医学推理基准测试中，$\method$相比现有方法取得显著提升：MedQA准确率提高23.5%，MedXpertQA提高32.0%（相对于基础生成器）。更重要的是，相比先前奖励模型基线，$\method$实现了8倍的采样预算减少。

Conclusion: 基于动态检索证据的验证为构建更可靠的医学推理系统提供了原则性路径，$\method$框架通过迭代查询外部知识库显著提升了医学推理验证的准确性和效率。

Abstract: Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning trace verification, existing methods face two limitations: they produce only scalar reward values without explicit justification, and they rely on single-pass retrieval that precludes adaptive knowledge access as verification unfolds. We introduce $\method$, an agentic framework that addresses these limitations by training medical reasoning verifiers to iteratively query external medical corpora during evaluation. Our approach combines tool-augmented verification with an iterative reinforcement learning paradigm that requires only trace-level supervision, alongside an adaptive curriculum mechanism that dynamically adjusts training data distribution. Across four medical reasoning benchmarks, $\method$ achieves substantial gains over existing methods, improving MedQA accuracy by 23.5% and MedXpertQA by 32.0% relative to the base generator in particular. Crucially, $\method$ demonstrates an $\mathbf{8\times}$ reduction in sampling budget requirement compared to prior reward model baselines. These findings establish that grounding verification in dynamically retrieved evidence offers a principled path toward more reliable medical reasoning systems.

</details>


### [7] [Endogenous Reprompting: Self-Evolving Cognitive Alignment for Unified Multimodal Models](https://arxiv.org/abs/2601.20305)
*Zhenchen Tang,Songlin Yang,Zichuan Wang,Bo Peng,Yang Li,Beibei Dong,Jing Dong*

Main category: cs.AI

TL;DR: SEER框架通过内生循环训练解决UMMs的认知鸿沟问题，仅需300个样本即可提升模型的生成质量


<details>
  <summary>Details</summary>
Motivation: 统一多模态模型虽然具备强大的理解能力，但这种理解能力往往无法有效指导生成过程，存在"认知鸿沟"问题

Method: 提出内生重提示机制，通过SEER训练框架建立两阶段内生循环：1) RLVR通过课程学习激活模型的潜在评估能力；2) RLMT利用内生奖励信号优化生成推理策略

Result: SEER在评估准确性、重提示效率和生成质量方面均优于现有基线方法，且不牺牲通用多模态能力

Conclusion: 内生重提示机制有效弥合了UMMs的认知鸿沟，仅需少量样本即可将模型理解转化为显式的生成推理步骤

Abstract: Unified Multimodal Models (UMMs) exhibit strong understanding, yet this capability often fails to effectively guide generation. We identify this as a Cognitive Gap: the model lacks the understanding of how to enhance its own generation process. To bridge this gap, we propose Endogenous Reprompting, a mechanism that transforms the model's understanding from a passive encoding process into an explicit generative reasoning step by generating self-aligned descriptors during generation. To achieve this, we introduce SEER (Self-Evolving Evaluator and Reprompter), a training framework that establishes a two-stage endogenous loop using only 300 samples from a compact proxy task, Visual Instruction Elaboration. First, Reinforcement Learning with Verifiable Rewards (RLVR) activates the model's latent evaluation ability via curriculum learning, producing a high-fidelity endogenous reward signal. Second, Reinforcement Learning with Model-rewarded Thinking (RLMT) leverages this signal to optimize the generative reasoning policy. Experiments show that SEER consistently outperforms state-of-the-art baselines in evaluation accuracy, reprompting efficiency, and generation quality, without sacrificing general multimodal capabilities.

</details>


### [8] [AMA: Adaptive Memory via Multi-Agent Collaboration](https://arxiv.org/abs/2601.20352)
*Weiquan Huang,Zixuan Wang,Hehai Lin,Sudong Wang,Bo Xu,Qian Li,Beier Zhu,Linyi Yang,Chengwei Qin*

Main category: cs.AI

TL;DR: AMA框架通过多智能体协作实现自适应记忆管理，显著提升长期记忆一致性和检索精度，同时减少80%的token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体记忆系统存在检索粒度僵化、维护策略累积过重、更新机制粗糙等问题，导致存储信息与任务推理需求不匹配，以及逻辑不一致性随时间累积。

Method: 提出AMA框架，采用分层记忆设计和多智能体协作：Constructor和Retriever实现多粒度记忆构建和自适应查询路由；Judge验证相关性和一致性；Refresher执行针对性更新或移除过时条目。

Result: 在具有挑战性的长上下文基准测试中，AMA显著优于现有最先进基线方法，相比全上下文方法减少约80%的token消耗，在保持检索精度和长期记忆一致性方面表现出色。

Conclusion: AMA框架通过多智能体协作和自适应记忆管理，有效解决了现有记忆系统的局限性，为LLM智能体提供了更高效、一致的长时记忆支持。

Abstract: The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.

</details>


### [9] [Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution](https://arxiv.org/abs/2601.20379)
*Zhengbo Jiao,Hongyu Xian,Qinglong Wang,Yunpu Ma,Zhebo Wang,Zifan Zhang,Dezhang Kong,Meng Han*

Main category: cs.AI

TL;DR: PoT框架通过在线优化机制，让语言模型在推理过程中从失败尝试中学习，动态更新策略，显著提升复杂推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在复杂长程推理中存在困难，主要原因是其固定策略假设导致的不稳定性。现有方法仅将执行反馈作为外部信号用于筛选或重写轨迹，未能将其内化以改进底层推理策略。

Method: 提出Policy of Thoughts (PoT)框架，将推理重新定义为实例内的在线优化过程。首先通过高效探索机制生成多样候选解，然后使用Group Relative Policy Optimization (GRPO)基于执行反馈更新瞬态LoRA适配器，实现闭环设计。

Result: PoT显著提升性能：一个4B参数模型在LiveCodeBench上达到49.71%准确率，超越了GPT-4o和DeepSeek-V3，尽管模型规模小了50倍以上。

Conclusion: PoT框架通过在线策略优化使语言模型能够从失败尝试中学习，实现动态、实例特定的推理策略改进，为复杂推理任务提供了有效解决方案。

Abstract: Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of "conjectures and refutations," we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.

</details>


### [10] [CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning](https://arxiv.org/abs/2601.20467)
*Zhenxuan Fan,Jie Cao,Yang Dai,Zheqi Lv,Wenqiao Zhang,Zhongle Xie,Peng LU,Beng Chin Ooi*

Main category: cs.AI

TL;DR: CtrlCoT是一个双粒度CoT压缩框架，通过分层推理抽象、逻辑保持蒸馏和分布对齐生成三个组件，在减少30.7%token的同时提升7.6个百分点的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有CoT压缩方法存在局限性：语义级压缩过于保守，token级剪枝过于激进可能丢失关键信息，且两者结合困难。需要一种能同时保留推理逻辑并减少token使用的方法。

Method: 提出CtrlCoT框架：1)分层推理抽象生成多粒度语义CoT；2)逻辑保持蒸馏训练逻辑感知剪枝器保留关键推理线索；3)分布对齐生成确保压缩轨迹与推理风格一致。

Result: 在MATH-500数据集上使用Qwen2.5-7B-Instruct模型，CtrlCoT比最强基线减少30.7%token使用，同时准确率提升7.6个百分点。

Conclusion: CtrlCoT通过协调语义抽象和token级剪枝，实现了更高效可靠的推理，解决了现有CoT压缩方法的局限性。

Abstract: Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.

</details>


### [11] [Online Risk-Averse Planning in POMDPs Using Iterated CVaR Value Function](https://arxiv.org/abs/2601.20554)
*Yaacov Pariente,Vadim Indelman*

Main category: cs.AI

TL;DR: 该论文研究了在部分可观测环境下使用迭代条件风险价值（ICVaR）进行风险敏感规划，开发了具有有限时间性能保证的策略评估算法，并将三种在线规划算法扩展为优化ICVaR而非期望回报，实验证明ICVaR规划器相比风险中性方法能降低尾部风险。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测马尔可夫决策过程（POMDP）中，传统的期望回报最大化方法忽略了尾部风险，而实际应用中决策者往往需要规避极端不利情况。因此需要开发能够量化和管理风险的风险敏感规划方法。

Method: 1. 开发了ICVaR策略评估算法，具有不依赖于动作空间大小的有限时间性能保证；2. 将三种在线规划算法（稀疏采样、PFT-DPW、POMCPOW）扩展为优化ICVaR值函数而非期望回报；3. 引入风险参数α，α=1恢复标准期望规划，α<1增加风险规避程度；4. 为ICVaR稀疏采样建立了风险敏感目标下的有限时间性能保证，并设计了针对ICVaR的新型探索策略。

Result: 在基准POMDP领域上的实验表明，提出的ICVaR规划器相比其风险中性对应方法能够实现更低的尾部风险。ICVaR稀疏采样算法获得了理论性能保证，并且针对ICVaR设计的探索策略有效提升了规划性能。

Conclusion: 该研究成功地将风险敏感规划引入部分可观测环境，通过ICVaR动态风险度量实现了对尾部风险的有效管理。提出的方法既保持了原有在线规划算法的效率优势，又通过风险参数α提供了从风险中性到风险规避的连续调节能力，为实际应用中的安全关键决策提供了理论和技术支持。

Abstract: We study risk-sensitive planning under partial observability using the dynamic risk measure Iterated Conditional Value-at-Risk (ICVaR). A policy evaluation algorithm for ICVaR is developed with finite-time performance guarantees that do not depend on the cardinality of the action space. Building on this foundation, three widely used online planning algorithms--Sparse Sampling, Particle Filter Trees with Double Progressive Widening (PFT-DPW), and Partially Observable Monte Carlo Planning with Observation Widening (POMCPOW)--are extended to optimize the ICVaR value function rather than the expectation of the return. Our formulations introduce a risk parameter $α$, where $α= 1$ recovers standard expectation-based planning and $α< 1$ induces increasing risk aversion. For ICVaR Sparse Sampling, we establish finite-time performance guarantees under the risk-sensitive objective, which further enable a novel exploration strategy tailored to ICVaR. Experiments on benchmark POMDP domains demonstrate that the proposed ICVaR planners achieve lower tail risk compared to their risk-neutral counterparts.

</details>


### [12] [Dialogical Reasoning Across AI Architectures: A Multi-Model Framework for Testing AI Alignment Strategies](https://arxiv.org/abs/2601.20604)
*Gray Cox*

Main category: cs.AI

TL;DR: 论文提出了一个通过结构化多模型对话实证测试AI对齐策略的方法框架，基于和平研究传统，将AI对齐从控制问题重构为通过对话推理发展的关系问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI对齐研究缺乏实证测试方法，需要开发能够评估AI系统是否能够实质性参与复杂对齐框架的系统性方法，特别是基于和平研究传统的对话推理能力。

Method: 采用结构化多模型对话实验设计，为不同AI系统分配四个角色（提议者、响应者、监督者、翻译者），在六个条件下测试大型语言模型参与复杂对齐框架的能力。使用Claude、Gemini和GPT-4o进行72轮对话，总计576,822字符的结构化交流。

Result: AI系统能够有意义地参与和平研究概念，从不同架构视角提出互补性异议，并产生初始框架中不存在的涌现见解（如"VCW作为过渡框架"的新颖综合）。不同模型关注不同问题：Claude强调验证挑战，Gemini关注偏见和可扩展性，GPT-4o突出实施障碍。

Conclusion: 该框架为研究人员提供了在实施前压力测试对齐提案的可复制方法，初步证据表明AI具备VCW所提出的对话推理能力。但对话更多关注过程元素而非AI本质的基础主张，未来研究方向包括人机混合协议和扩展对话研究。

Abstract: This paper introduces a methodological framework for empirically testing AI alignment strategies through structured multi-model dialogue. Drawing on Peace Studies traditions - particularly interest-based negotiation, conflict transformation, and commons governance - we operationalize Viral Collaborative Wisdom (VCW), an approach that reframes alignment from a control problem to a relationship problem developed through dialogical reasoning.
  Our experimental design assigns four distinct roles (Proposer, Responder, Monitor, Translator) to different AI systems across six conditions, testing whether current large language models can engage substantively with complex alignment frameworks. Using Claude, Gemini, and GPT-4o, we conducted 72 dialogue turns totaling 576,822 characters of structured exchange.
  Results demonstrate that AI systems can engage meaningfully with Peace Studies concepts, surface complementary objections from different architectural perspectives, and generate emergent insights not present in initial framings - including the novel synthesis of "VCW as transitional framework." Cross-architecture patterns reveal that different models foreground different concerns: Claude emphasized verification challenges, Gemini focused on bias and scalability, and GPT-4o highlighted implementation barriers.
  The framework provides researchers with replicable methods for stress-testing alignment proposals before implementation, while the findings offer preliminary evidence about AI capacity for the kind of dialogical reasoning VCW proposes. We discuss limitations, including the observation that dialogues engaged more with process elements than with foundational claims about AI nature, and outline directions for future research including human-AI hybrid protocols and extended dialogue studies.

</details>


### [13] [Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation](https://arxiv.org/abs/2601.20614)
*Yanqi Dai,Yuxiang Ji,Xiao Zhang,Yong Wang,Xiangxiang Chu,Zhiwu Lu*

Main category: cs.AI

TL;DR: MathForge框架通过难度感知组策略优化算法和多方面问题重构策略，从算法和数据两个角度解决现有数学推理方法对难题关注不足的问题，显著提升大模型数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习可验证奖励方法在数学推理中存在系统性不足：算法上，广泛使用的组相对策略优化存在隐式不平衡，对难题的策略更新幅度较小；数据上，增强方法主要重述问题以增加多样性，而没有系统性地提高内在难度。这些缺陷限制了模型在更具挑战性问题上的能力发展。

Method: 提出MathForge框架，包含两个核心组件：1) 难度感知组策略优化算法，通过难度平衡的组优势估计纠正GRPO中的隐式不平衡，并通过难度感知的问题级加权优先处理难题；2) 多方面问题重构策略，在保持原始正确答案的同时，从多个方面重构问题以增加难度。

Result: 大量实验表明，MathForge在各种数学推理任务上显著优于现有方法。该框架形成了协同循环：MQR扩展数据前沿，DGPO有效从增强数据中学习。

Conclusion: MathForge通过从算法和数据两个角度针对性地处理难题，有效提升了大型语言模型的数学推理能力，为解决现有方法在更具挑战性问题上的不足提供了系统性的解决方案。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.

</details>


### [14] [Investigating the Development of Task-Oriented Communication in Vision-Language Models](https://arxiv.org/abs/2601.20641)
*Boaz Carmeli,Orr Paradise,Shafi Goldwasser,Yonatan Belinkov,Ron Meir*

Main category: cs.AI

TL;DR: LLM智能体能在协作推理任务中发展出不同于自然语言的任务导向通信协议，这些协议具有高效性和隐蔽性，既展示了潜力也带来了透明度风险。


<details>
  <summary>Details</summary>
Motivation: 研究LLM智能体是否能在协作任务中发展出不同于标准自然语言的任务导向通信协议，特别关注这种协议可能具备的两个核心特性：高效性（更简洁地传递任务相关信息）和隐蔽性（外部观察者难以解读），这涉及到透明度和控制方面的担忧。

Method: 使用指称游戏框架，让视觉语言模型（VLM）智能体进行通信，提供一个可控、可测量的环境来评估语言变体。通过实验观察VLM智能体如何发展通信模式。

Result: 实验表明：1）VLM能够发展出有效、适应任务需求的通信模式；2）能够发展出对人类和外部智能体都难以解读的隐蔽协议；3）观察到相似模型之间无需明确共享协议就能自发协调。

Conclusion: 任务导向通信既展示了潜力也带来了风险，指称游戏为这一领域的未来研究提供了有价值的测试平台。这些发现强调了在开发LLM智能体时需要平衡效率与透明度的重要性。

Abstract: We investigate whether \emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.

</details>


### [15] [Implementing Metric Temporal Answer Set Programming](https://arxiv.org/abs/2601.20735)
*Arvid Becker,Pedro Cabalar,Martin Diéguez,Susana Hahn,Javier Romero,Torsten Schaub*

Main category: cs.AI

TL;DR: 提出一种计算性度量答案集编程方法，用于处理定量时间约束（如持续时间和截止时间），通过差异约束扩展解决时间粒度导致的规模化问题


<details>
  <summary>Details</summary>
Motivation: 传统答案集编程在处理细粒度时间约束时面临规模化瓶颈，需要一种能够表达定量时间约束（如持续时间和截止时间）且不受时间精度影响的解决方案

Method: 采用差异约束（线性约束的简化形式）扩展ASP，将时间相关方面外部化处理，有效解耦度量ASP与时间粒度，使解决方案不受时间精度影响

Result: 开发的计算方法能够有效处理定量时间约束，解决了细粒度时间约束导致的ASP基础化瓶颈问题，实现了不受时间精度影响的解决方案

Conclusion: 通过差异约束扩展ASP的方法成功解决了度量ASP中的时间约束表达和规模化问题，为处理定量时间约束提供了一种有效且可扩展的计算框架

Abstract: We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.

</details>
