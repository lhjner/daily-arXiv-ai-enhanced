<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 24]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Agentic Business Process Management Systems](https://arxiv.org/abs/2601.18833)
*Marlon Dumas,Fredrik Milani,David Chapela-Campa*

Main category: cs.AI

TL;DR: 生成式AI和智能体技术正在推动BPM从自动化向自主化转变，从设计驱动转向数据驱动管理，提出了集成自主性、推理和学习能力的A-BPMS架构愿景。


<details>
  <summary>Details</summary>
Motivation: 生成式AI和智能体AI的兴起为BPM领域带来了新的变革浪潮，但这一波与前几波自动化技术不同，它需要从自动化转向自主化，从设计驱动管理转向数据驱动管理，这需要重新思考BPM系统的架构和功能。

Method: 基于流程挖掘技术建立基础，使智能体能够感知流程状态、推理改进机会并采取行动；提出Agentic Business Process Management Systems (A-BPMS)的架构愿景，这是一种集成自主性、推理和学习能力的新型平台。

Result: 提出了支持从人工驱动到完全自主流程连续体的系统架构，重新定义了流程自动化和治理的边界，为下一代BPM系统的发展指明了方向。

Conclusion: 生成式AI和智能体技术正在推动BPM向自主化、数据驱动管理转变，A-BPMS将成为集成自主性、推理和学习能力的新一代平台，支持从人工驱动到完全自主的流程连续体，重新定义流程自动化和治理的边界。

Abstract: Since the early 90s, the evolution of the Business Process Management (BPM) discipline has been punctuated by successive waves of automation technologies. Some of these technologies enable the automation of individual tasks, while others focus on orchestrating the execution of end-to-end processes. The rise of Generative and Agentic Artificial Intelligence (AI) is opening the way for another such wave. However, this wave is poised to be different because it shifts the focus from automation to autonomy and from design-driven management of business processes to data-driven management, leveraging process mining techniques. This position paper, based on a keynote talk at the 2025 Workshop on AI for BPM, outlines how process mining has laid the foundations on top of which agents can sense process states, reason about improvement opportunities, and act to maintain and optimize performance. The paper proposes an architectural vision for Agentic Business Process Management Systems (A-BPMS): a new class of platforms that integrate autonomy, reasoning, and learning into process management and execution. The paper contends that such systems must support a continuum of processes, spanning from human-driven to fully autonomous, thus redefining the boundaries of process automation and governance.

</details>


### [2] [LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties](https://arxiv.org/abs/2601.18846)
*Urban Skvorc,Niki van Stein,Moritz Seiler,Britta Grimme,Thomas Bäck,Heike Trautmann*

Main category: cs.AI

TL;DR: 使用LLM在进化循环中生成具有明确高层景观特征的优化问题，通过ELA属性预测器评估，引入ELA空间适应度共享机制增加多样性，生成的函数扩展了BBOB实例空间


<details>
  <summary>Details</summary>
Motivation: 现有测试套件（如BBOB）的结构多样性有限，阻碍了连续黑盒优化的基准测试，需要能够生成具有明确高层景观特征的优化问题的方法

Method: 使用LLaMEA框架，通过自然语言描述目标属性（多模态、可分离性、盆地大小同质性、搜索空间同质性、全局-局部最优对比）引导LLM生成问题代码，在循环中使用ELA属性预测器评分，引入ELA空间适应度共享机制增加种群多样性

Result: 生成的函数确实表现出预期的结构特征，t-SNE嵌入显示它们扩展了BBOB实例空间而不是形成无关的聚类，创建了一个广泛、可解释、可复现的基准问题库

Conclusion: 该方法成功生成了具有明确景观特征的优化问题，扩展了基准测试的多样性，为景观分析和自动算法选择等下游任务提供了有价值的工具

Abstract: Benchmarking in continuous black-box optimisation is hindered by the limited structural diversity of existing test suites such as BBOB. We explore whether large language models embedded in an evolutionary loop can be used to design optimisation problems with clearly defined high-level landscape characteristics. Using the LLaMEA framework, we guide an LLM to generate problem code from natural-language descriptions of target properties, including multimodality, separability, basin-size homogeneity, search-space homogeneity and globallocal optima contrast. Inside the loop we score candidates through ELA-based property predictors. We introduce an ELA-space fitness-sharing mechanism that increases population diversity and steers the generator away from redundant landscapes. A complementary basin-of-attraction analysis, statistical testing and visual inspection, verifies that many of the generated functions indeed exhibit the intended structural traits. In addition, a t-SNE embedding shows that they expand the BBOB instance space rather than forming an unrelated cluster. The resulting library provides a broad, interpretable, and reproducible set of benchmark problems for landscape analysis and downstream tasks such as automated algorithm selection.

</details>


### [3] [Explainable Uncertainty Quantification for Wastewater Treatment Energy Prediction via Interval Type-2 Neuro-Fuzzy System](https://arxiv.org/abs/2601.18897)
*Qusai Khaled,Bahjat Mallak,Uzay Kaymak,Laura Genga*

Main category: cs.AI

TL;DR: 开发IT2-ANFIS模型用于污水处理厂能耗预测，提供可解释的不确定性量化，优于传统点预测方法


<details>
  <summary>Details</summary>
Motivation: 污水处理厂能耗占全球电力1-3%，需要准确预测以优化运营。现有机器学习模型只能提供点预测，缺乏可解释的不确定性量化，这在安全关键基础设施的风险感知决策中至关重要

Method: 开发区间二型自适应神经模糊推理系统（IT2-ANFIS），通过模糊规则结构生成可解释的预测区间。框架在三个层次分解不确定性：特征级（识别引入模糊性的变量）、规则级（分析局部模型置信度）、实例级（量化整体预测不确定性）

Result: 在墨尔本水务东部处理厂数据集上验证，IT2-ANFIS达到与一阶ANFIS相当的预测性能，同时显著减少训练运行方差，并提供可解释的不确定性估计，将预测置信度直接与运营条件和输入变量关联

Conclusion: IT2-ANFIS为污水处理厂能耗预测提供了可解释的不确定性量化框架，支持风险感知决策，有助于优化运营和可持续发展

Abstract: Wastewater treatment plants consume 1-3% of global electricity, making accurate energy forecasting critical for operational optimization and sustainability. While machine learning models provide point predictions, they lack explainable uncertainty quantification essential for risk-aware decision-making in safety-critical infrastructure. This study develops an Interval Type-2 Adaptive Neuro-Fuzzy Inference System (IT2-ANFIS) that generates interpretable prediction intervals through fuzzy rule structures. Unlike black-box probabilistic methods, the proposed framework decomposes uncertainty across three levels: feature-level, footprint of uncertainty identify which variables introduce ambiguity, rule-level analysis reveals confidence in local models, and instance-level intervals quantify overall prediction uncertainty. Validated on Melbourne Water's Eastern Treatment Plant dataset, IT2-ANFIS achieves comparable predictive performance to first order ANFIS with substantially reduced variance across training runs, while providing explainable uncertainty estimates that link prediction confidence directly to operational conditions and input variables.

</details>


### [4] [RIFT: Reordered Instruction Following Testbed To Evaluate Instruction Following in Singular Multistep Prompt Structures](https://arxiv.org/abs/2601.18924)
*Andrew Jaffe,Noah Reicin,Jinho D. Choi*

Main category: cs.AI

TL;DR: 论文提出RIFT测试框架，通过重新排序提示结构来评估大语言模型的指令跟随能力，发现模型对顺序连续性有强烈依赖，跳跃式提示下准确率下降高达72%。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在复杂工作流中的应用日益增多，但其维持指令流的能力尚未充分探索。现有基准测试将任务复杂性与结构顺序混为一谈，难以分离提示拓扑结构对性能的影响。

Method: 引入RIFT（重新排序指令跟随测试平台），使用重新表述的Jeopardy!问答对，测试两种提示结构：线性提示（顺序进行）和跳跃提示（内容相同但需要非顺序遍历）。在6个最先进的开源LLMs上进行10,000次评估。

Result: 在跳跃条件下，准确率相比基线下降高达72%，显示出对位置连续性的强烈依赖。约50%的失败源于指令顺序违反和语义漂移，表明当前架构将指令跟随内化为顺序模式而非推理技能。

Conclusion: 结构敏感性是当前架构的基本限制，对需要非顺序控制流的应用（如工作流自动化和多智能体系统）有直接影响。这表明LLMs需要更强大的推理能力来处理非顺序指令结构。

Abstract: Large Language Models (LLMs) are increasingly relied upon for complex workflows, yet their ability to maintain flow of instructions remains underexplored. Existing benchmarks conflate task complexity with structural ordering, making it difficult to isolate the impact of prompt topology on performance. We introduce RIFT, Reordered Instruction Following Testbed, to assess instruction following by disentangling structure from content. Using rephrased Jeopardy! question-answer pairs, we test LLMs across two prompt structures: linear prompts, which progress sequentially, and jumping prompts, which preserve identical content but require non-sequential traversal. Across 10,000 evaluations spanning six state-of-the-art open-source LLMs, accuracy dropped by up to 72% under jumping conditions (compared to baseline), revealing a strong dependence on positional continuity. Error analysis shows that approximately 50% of failures stem from instruction-order violations and semantic drift, indicating that current architectures internalize instruction following as a sequential pattern rather than a reasoning skill. These results reveal structural sensitivity as a fundamental limitation in current architectures, with direct implications for applications requiring non-sequential control flow such as workflow automation and multi-agent systems.

</details>


### [5] [Neural Theorem Proving for Verification Conditions: A Real-World Benchmark](https://arxiv.org/abs/2601.18944)
*Qiyuan Xu,Xiaokun Luan,Renxi Wang,Joshua Ong Jun Leang,Peixin Wang,Haonan Li,Wenda Li,Conrad Watt*

Main category: cs.AI

TL;DR: 该论文提出了首个针对程序验证中验证条件（VC）自动证明的神经定理证明基准NTP4VC，从真实项目生成多语言测试用例，评估LLMs在VC证明中的表现，发现仍有显著挑战。


<details>
  <summary>Details</summary>
Motivation: 程序验证中的验证条件自动证明是主要瓶颈，现有自动定理证明器无法处理困难的VC，导致需要大量手动证明。虽然神经定理证明在数学竞赛中取得成功，但在程序验证中的应用尚未充分探索，缺乏专门针对VC证明的基准。

Method: 提出NTP4VC基准，从Linux和Contiki-OS内核等真实项目中，利用Why3和Frama-C工业流水线生成语义等价的测试用例，覆盖Isabelle、Lean和Rocq三种形式语言。评估通用大语言模型和专门针对定理证明微调的模型。

Result: 评估结果显示，虽然大语言模型在VC证明中显示出潜力，但在程序验证方面仍面临显著挑战，表明存在巨大的研究差距和机会。

Conclusion: 这是首个针对程序验证中验证条件自动证明的神经定理证明基准，揭示了LLMs在该领域的潜力和局限性，为未来研究指明了方向。

Abstract: Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.

</details>


### [6] [Uncertainty-Aware 3D Emotional Talking Face Synthesis with Emotion Prior Distillation](https://arxiv.org/abs/2601.19112)
*Nanhan Shen,Zhilei Liu*

Main category: cs.AI

TL;DR: UA-3DTalk提出了一种不确定性感知的3D情感说话人脸合成方法，通过情感先验蒸馏解决现有方法在音频-视觉情感对齐和多视图融合方面的不足，在情感对齐、唇部同步和渲染质量上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D情感说话人脸合成方法存在两个关键问题：1) 音频-视觉情感对齐不佳，表现为音频情感提取困难和对情感微表情控制不足；2) 采用一刀切的多视图融合策略，忽略了不确定性和特征质量差异，损害了渲染质量。

Method: UA-3DTalk包含三个核心模块：1) 先验提取模块将音频解耦为内容同步特征和个性化特征；2) 情感蒸馏模块引入多模态注意力加权融合机制和4D高斯编码，实现细粒度音频情感提取和情感微表情精确控制；3) 基于不确定性的形变模块使用不确定性块估计视图特定的不确定度，实现自适应多视图融合，并结合多头解码器优化高斯基元。

Result: 在常规和情感数据集上的大量实验表明，UA-3DTalk在情感对齐（E-FID提升5.2%）、唇部同步（SyncC提升3.1%）和渲染质量（LPIPS提升0.015）方面均优于DEGSTalk和EDTalk等最先进方法。

Conclusion: UA-3DTalk通过情感先验蒸馏和不确定性感知的多视图融合策略，有效解决了3D情感说话人脸合成中的关键挑战，在情感对齐、唇部同步和渲染质量方面取得了显著改进。

Abstract: Emotional Talking Face synthesis is pivotal in multimedia and signal processing, yet existing 3D methods suffer from two critical challenges: poor audio-vision emotion alignment, manifested as difficult audio emotion extraction and inadequate control over emotional micro-expressions; and a one-size-fits-all multi-view fusion strategy that overlooks uncertainty and feature quality differences, undermining rendering quality. We propose UA-3DTalk, Uncertainty-Aware 3D Emotional Talking Face Synthesis with emotion prior distillation, which has three core modules: the Prior Extraction module disentangles audio into content-synchronized features for alignment and person-specific complementary features for individualization; the Emotion Distillation module introduces a multi-modal attention-weighted fusion mechanism and 4D Gaussian encoding with multi-resolution code-books, enabling fine-grained audio emotion extraction and precise control of emotional micro-expressions; the Uncertainty-based Deformation deploys uncertainty blocks to estimate view-specific aleatoric (input noise) and epistemic (model parameters) uncertainty, realizing adaptive multi-view fusion and incorporating a multi-head decoder for Gaussian primitive optimization to mitigate the limitations of uniform-weight fusion. Extensive experiments on regular and emotional datasets show UA-3DTalk outperforms state-of-the-art methods like DEGSTalk and EDTalk by 5.2% in E-FID for emotion alignment, 3.1% in SyncC for lip synchronization, and 0.015 in LPIPS for rendering quality. Project page: https://mrask999.github.io/UA-3DTalk

</details>


### [7] [Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach](https://arxiv.org/abs/2601.19122)
*Weiran Guo,Bing Bo,Shaoxiang Wu,Jingsheng Yang*

Main category: cs.AI

TL;DR: 提出一种基于强化学习的对抗性数据增强方法，通过训练查询模型生成针对函数调用模型弱点的对抗性查询，提升LLM函数调用能力的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有提升LLM函数调用能力的方法依赖手动标注或模型自动生成的数据进行微调，缺乏针对性设计，受限于固定模式和数据分布，限制了函数调用LLM的泛化性和鲁棒性。

Method: 提出新颖的对抗性数据增强方法，使用强化学习训练查询模型生成专门挑战函数调用模型的对抗性查询。采用零和博弈框架，查询模型和函数调用模型进行迭代交替训练。

Result: 该方法能够系统性地识别和针对函数调用LLM的弱点，推动开发更鲁棒的函数调用模型，为识别和纠正LLM与外部工具交互能力的弱点提供系统性方法。

Conclusion: 基于强化学习的对抗性数据增强方法有效解决了现有函数调用能力提升方法的局限性，通过针对性生成对抗性查询，显著增强了LLM函数调用能力的泛化性和鲁棒性。

Abstract: Function call capabilities have become crucial for Large Language Models (LLMs), enabling them to interact more effectively with external tools and APIs. Existing methods for improving the function call capabilities of LLMs rely on data obtained either through manual annotation or automated generation by models, and use this data to finetune the LLMs. However, these methods often lack targeted design and are constrained by fixed patterns and data distributions, which limits their effectiveness in enhancing the generalization and robustness of function call LLMs. To address this limitation, we propose a novel adversarial data augmentation method that employs reinforcement learning to systematically identify and target the weaknesses of function call LLMs. Our training framework introduces a query model trained with reinforcement learning (RL) to generate adversarial queries that are specifically designed to challenge function call (FC) models. This approach adopts a zero sum game formulation, where the query model and the FC model engage in iterative alternating training. Overall, our method advances the development of more robust FC models and provides a systematic way to identify and correct weaknesses in the ability of LLMs to interact with external tools.

</details>


### [8] [TS-Debate: Multimodal Collaborative Debate for Zero-Shot Time Series Reasoning](https://arxiv.org/abs/2601.19151)
*Patara Trirat,Jin Myung Kwak,Jay Heo,Heejun Lee,Sung Ju Hwang*

Main category: cs.AI

TL;DR: TS-Debate：一种用于零样本时间序列推理的模态专业化多智能体辩论框架，通过专门的文本、视觉和数值专家智能体协作，结合验证-冲突-校准机制，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在时间序列分析中表现出潜力但存在局限性，包括数值保真度不足、模态干扰以及跨模态集成缺乏原则性方法

Method: TS-Debate采用模态专业化的多智能体辩论框架，包含文本上下文、视觉模式和数值信号三个专家智能体，通过结构化辩论协议协调交互，使用验证-冲突-校准机制评估智能体主张，支持轻量级代码执行和数值查找进行程序化验证

Result: 在涵盖三个公共基准测试的20个任务中，TS-Debate相比强基线（包括所有智能体观察所有输入的标准多模态辩论）实现了持续且显著的性能提升

Conclusion: TS-Debate框架能够保持模态保真度、暴露冲突证据并减轻数值幻觉，无需任务特定的微调，为时间序列推理提供了一种有效的零样本解决方案

Abstract: Recent progress at the intersection of large language models (LLMs) and time series (TS) analysis has revealed both promise and fragility. While LLMs can reason over temporal structure given carefully engineered context, they often struggle with numeric fidelity, modality interference, and principled cross-modal integration. We present TS-Debate, a modality-specialized, collaborative multi-agent debate framework for zero-shot time series reasoning. TS-Debate assigns dedicated expert agents to textual context, visual patterns, and numerical signals, preceded by explicit domain knowledge elicitation, and coordinates their interaction via a structured debate protocol. Reviewer agents evaluate agent claims using a verification-conflict-calibration mechanism, supported by lightweight code execution and numerical lookup for programmatic verification. This architecture preserves modality fidelity, exposes conflicting evidence, and mitigates numeric hallucinations without task-specific fine-tuning. Across 20 tasks spanning three public benchmarks, TS-Debate achieves consistent and significant performance improvements over strong baselines, including standard multimodal debate in which all agents observe all inputs.

</details>


### [9] [LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge](https://arxiv.org/abs/2601.19155)
*Qiujun Li,Zijin Xiao,Xulin Wang,Zhidan Ma,Cheng Yang,Haifeng Li*

Main category: cs.AI

TL;DR: LocationAgent是一个用于图像地理定位的分层智能体，采用RER架构（推理器-执行器-记录器）和外部工具验证地理证据，在零样本设置下性能显著优于现有方法30%以上。


<details>
  <summary>Details</summary>
Motivation: 现有图像地理定位方法通常通过监督训练或基于轨迹的强化微调将位置知识和推理模式内化为静态记忆，容易在开放世界设置或需要动态知识的场景中出现事实幻觉和泛化瓶颈。

Method: 提出分层定位智能体LocationAgent，核心思想是在模型中保留分层推理逻辑，同时将地理证据验证卸载到外部工具。采用RER架构（推理器-执行器-记录器）实现分层推理，通过角色分离和上下文压缩防止多步推理中的漂移问题。构建线索探索工具套件提供多样化证据支持位置推理。引入CCL-Bench（中国城市位置基准）数据集解决数据泄露和中文数据稀缺问题。

Result: 大量实验表明，LocationAgent在零样本设置下显著优于现有方法至少30%。

Conclusion: 通过将分层推理逻辑保留在模型中，同时将地理证据验证卸载到外部工具，LocationAgent有效解决了现有方法在开放世界设置中的事实幻觉和泛化瓶颈问题，在图像地理定位任务上取得了显著性能提升。

Abstract: Image geolocation aims to infer capture locations based on visual content. Fundamentally, this constitutes a reasoning process composed of \textit{hypothesis-verification cycles}, requiring models to possess both geospatial reasoning capabilities and the ability to verify evidence against geographic facts. Existing methods typically internalize location knowledge and reasoning patterns into static memory via supervised training or trajectory-based reinforcement fine-tuning. Consequently, these methods are prone to factual hallucinations and generalization bottlenecks in open-world settings or scenarios requiring dynamic knowledge. To address these challenges, we propose a Hierarchical Localization Agent, called LocationAgent. Our core philosophy is to retain hierarchical reasoning logic within the model while offloading the verification of geographic evidence to external tools. To implement hierarchical reasoning, we design the RER architecture (Reasoner-Executor-Recorder), which employs role separation and context compression to prevent the drifting problem in multi-step reasoning. For evidence verification, we construct a suite of clue exploration tools that provide diverse evidence to support location reasoning. Furthermore, to address data leakage and the scarcity of Chinese data in existing datasets, we introduce CCL-Bench (China City Location Bench), an image geolocation benchmark encompassing various scene granularities and difficulty levels. Extensive experiments demonstrate that LocationAgent significantly outperforms existing methods by at least 30\% in zero-shot settings.

</details>


### [10] [Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement](https://arxiv.org/abs/2601.19170)
*Wangyang Ying,Yanchi Liu,Xujiang Zhao,Wei Cheng,Zhengzhang Chen,Wenchao Yu,Yanjie Fu,Haifeng Chen*

Main category: cs.AI

TL;DR: 提出一个名为\model{}的多智能体框架，通过结构化和逻辑化反馈迭代优化，从自然语言中自动提取工作流程序图


<details>
  <summary>Details</summary>
Motivation: 从自然语言自动提取工作流程序图是一个有前景但尚未充分探索的领域，需要同时保证结构有效性和逻辑一致性。虽然最近的大语言模型在程序图提取方面显示出潜力，但它们经常产生结构不良或逻辑流误解的结果。

Method: 提出\model{}多智能体框架，将程序图提取制定为多轮推理过程，包含三个迭代阶段：1) 图构建智能体进行图提取；2) 模拟智能体诊断和解释结构缺陷；3) 语义智能体对齐流程逻辑与源文本语言线索之间的语义。重要反馈以自然语言形式优先表达并注入后续提示中。

Result: 实验表明，\model{}在结构正确性和逻辑一致性方面相比强基线方法取得了显著改进。

Conclusion: 该框架通过模块化设计使智能体能够针对不同类型的错误进行优化，无需监督或参数更新，实现了可解释和可控的细化过程。

Abstract: Automatically extracting workflows as procedural graphs from natural language is promising yet underexplored, demanding both structural validity and logical alignment. While recent large language models (LLMs) show potential for procedural graph extraction, they often produce ill-formed structures or misinterpret logical flows. We present \model{}, a multi-agent framework that formulates procedural graph extraction as a multi-round reasoning process with dedicated structural and logical refinement. The framework iterates through three stages: (1) a graph extraction phase with the graph builder agent, (2) a structural feedback phase in which a simulation agent diagnoses and explains structural defects, and (3) a logical feedback phase in which a semantic agent aligns semantics between flow logic and linguistic cues in the source text. Important feedback is prioritized and expressed in natural language, which is injected into subsequent prompts, enabling interpretable and controllable refinement. This modular design allows agents to target distinct error types without supervision or parameter updates. Experiments demonstrate that \model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.

</details>


### [11] [CollectiveKV: Decoupling and Sharing Collaborative Information in Sequential Recommendation](https://arxiv.org/abs/2601.19178)
*Jingyu Li,Zhaocheng Du,Qianhui Zhu,kaiyuan Li,Zhicheng Zhang,Song-Li Wu,Chaolang Li,Pengwen Dai*

Main category: cs.AI

TL;DR: 提出CollectiveKV方法，通过跨用户共享KV缓存来大幅压缩存储开销，同时保持或提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 序列推荐系统中Transformer注意力机制的计算复杂度随序列长度增长，KV缓存技术虽能降低推理延迟但带来巨大存储开销，特别是对于大规模用户和长历史序列。研究发现不同用户的KV序列存在显著相似性，表明KV中存在可共享的协作信号。

Method: 通过SVD分析发现KV信息可分为可跨用户共享的大部分信息和少量用户特定信息。提出CollectiveKV方法：1) 通过可学习的全局KV池捕获跨用户共享信息；2) 推理时每个用户从池中检索高维共享KV，与低维用户特定KV拼接得到最终KV。

Result: 在5个序列推荐模型和3个数据集上的实验表明，该方法能将KV缓存压缩到原始大小的0.8%，同时保持甚至提升模型性能。

Conclusion: CollectiveKV通过跨用户KV共享机制有效解决了序列推荐系统中KV缓存存储开销大的问题，实现了高效的KV压缩，为实际部署提供了可行方案。

Abstract: Sequential recommendation models are widely used in applications, yet they face stringent latency requirements. Mainstream models leverage the Transformer attention mechanism to improve performance, but its computational complexity grows with the sequence length, leading to a latency challenge for long sequences. Consequently, KV cache technology has recently been explored in sequential recommendation systems to reduce inference latency. However, KV cache introduces substantial storage overhead in sequential recommendation systems, which often have a large user base with potentially very long user history sequences. In this work, we observe that KV sequences across different users exhibit significant similarities, indicating the existence of collaborative signals in KV. Furthermore, we analyze the KV using singular value decomposition (SVD) and find that the information in KV can be divided into two parts: the majority of the information is shareable across users, while a small portion is user-specific. Motivated by this, we propose CollectiveKV, a cross-user KV sharing mechanism. It captures the information shared across users through a learnable global KV pool. During inference, each user retrieves high-dimensional shared KV from the pool and concatenates them with low-dimensional user-specific KV to obtain the final KV. Experiments on five sequential recommendation models and three datasets show that our method can compress the KV cache to only 0.8% of its original size, while maintaining or even enhancing model performance.

</details>


### [12] [CoReTab: Improving Multimodal Table Understanding with Code-driven Reasoning](https://arxiv.org/abs/2601.19193)
*Van-Quang Nguyen,Takayuki Okatani*

Main category: cs.AI

TL;DR: CoReTab：基于代码驱动的推理框架，通过生成可执行的Python代码来提升多模态表格理解的多步推理能力，显著优于现有基准。


<details>
  <summary>Details</summary>
Motivation: 现有多模态表格理解数据集（如MMTab）主要提供简短的事实性答案，缺乏明确的多步推理监督。在这些数据集上训练的模型生成简短回答，准确率不足且可解释性有限，无法清晰展示模型得出最终答案的推理过程。

Method: 提出CoReTab代码驱动推理框架，将多步推理与可执行的Python代码相结合，生成可扩展、可解释且自动可验证的标注。使用该框架构建包含115K验证样本的数据集（平均每个响应529个token），并通过三阶段流水线微调开源多模态大语言模型。

Result: 在17个MMTab基准测试（涵盖表格问答、事实验证和表格结构理解）上评估模型。相比基于MMTab训练的基线模型，在三个任务上分别获得+6.2%、+5.7%和+25.6%的显著提升，同时产生透明且可验证的推理轨迹。

Conclusion: CoReTab作为一个稳健且可泛化的监督框架，有效提升了多模态表格理解中的多步推理能力，通过代码驱动的方法实现了更好的准确性、可解释性和可验证性。

Abstract: Existing datasets for multimodal table understanding, such as MMTab, primarily provide short factual answers without explicit multi-step reasoning supervision. Models trained on these datasets often generate brief responses that offers insufficient accuracy and limited interpretability into how these models arrive at the final answer. We introduce CoReTab, a code-driven reasoning framework that produces scalable, interpretable, and automatically verifiable annotations by coupling multi-step reasoning with executable Python code. Using the CoReTab framework, we curate a dataset of 115K verified samples averaging 529 tokens per response and fine-tune open-source MLLMs through a three-stage pipeline. We evaluate the resulting model trained on CoReTab across 17 MMTab benchmarks spanning table question answering, fact verification, and table structure understanding. Our model achieves significant gains of +6.2%, +5.7%, and +25.6%, respectively, over MMTab-trained baselines, while producing transparent and verifiable reasoning traces. These results establish CoReTab as a robust and generalizable supervision framework for improving multi-step reasoning in multimodal table understanding.

</details>


### [13] [MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning](https://arxiv.org/abs/2601.19204)
*Zhixi Cai,Fucai Ke,Kevin Leo,Sukai Huang,Maria Garcia de la Banda,Peter J. Stuckey,Hamid Rezatofighi*

Main category: cs.AI

TL;DR: MATA是一个用于视觉推理的多智能体分层可训练自动机系统，通过可训练的超智能体选择顶级状态转移，每个智能体运行基于规则的子自动机，共享内存实现透明执行历史，在多个视觉推理基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型虽然感知能力强，但隐含推理难以解释，在复杂查询上容易产生幻觉。组合方法提高了可解释性，但大多依赖单一智能体或手工设计的流程，无法决定何时在互补智能体之间协作或在重叠智能体之间竞争。

Method: 提出MATA（多智能体分层可训练自动机），这是一个分层有限状态自动机表示的多智能体系统。顶层转移由可训练的超智能体选择，每个智能体对应超自动机中的一个状态，运行小型基于规则的子自动机进行可靠的微控制。所有智能体读写共享内存，产生透明的执行历史。为监督超智能体的转移策略，构建转移轨迹树并转换为内存到下一状态对，形成MATA-SFT-90K数据集用于监督微调。

Result: 在多个视觉推理基准测试中，MATA相比单一模型和组合基线方法取得了最先进的结果。微调后的LLM作为转移策略能够理解查询和智能体的能力，能够高效选择最优智能体解决任务。

Conclusion: MATA通过多智能体分层可训练自动机框架，在保持可解释性的同时提高了视觉推理的性能，解决了现有方法在协作与竞争决策方面的局限性，为透明可靠的视觉推理提供了有效解决方案。

Abstract: Recent vision-language models have strong perceptual ability but their implicit reasoning is hard to explain and easily generates hallucinations on complex queries. Compositional methods improve interpretability, but most rely on a single agent or hand-crafted pipeline and cannot decide when to collaborate across complementary agents or compete among overlapping ones. We introduce MATA (Multi-Agent hierarchical Trainable Automaton), a multi-agent system presented as a hierarchical finite-state automaton for visual reasoning whose top-level transitions are chosen by a trainable hyper agent. Each agent corresponds to a state in the hyper automaton, and runs a small rule-based sub-automaton for reliable micro-control. All agents read and write a shared memory, yielding transparent execution history. To supervise the hyper agent's transition policy, we build transition-trajectory trees and transform to memory-to-next-state pairs, forming the MATA-SFT-90K dataset for supervised finetuning (SFT). The finetuned LLM as the transition policy understands the query and the capacity of agents, and it can efficiently choose the optimal agent to solve the task. Across multiple visual reasoning benchmarks, MATA achieves the state-of-the-art results compared with monolithic and compositional baselines. The code and dataset are available at https://github.com/ControlNet/MATA.

</details>


### [14] [Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection](https://arxiv.org/abs/2601.19245)
*Yongxin Deng,Zhen Fang,Yixuan Li,Ling Chen*

Main category: cs.AI

TL;DR: 本文提出了一种可泛化的幻觉检测方法，通过分析多轮对话中的不确定性波动来区分幻觉和事实性回答，在跨域场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法在同一领域内表现良好，但在跨域场景中泛化能力差。本文研究一个被忽视的重要问题——可泛化幻觉检测，旨在在单一领域数据上训练检测器，同时确保在相关领域中的鲁棒性能。

Method: 通过模拟大语言模型初始回答后的多轮对话，发现幻觉引发的对话普遍表现出比事实性对话更大的不确定性波动。基于此现象提出SpikeScore评分，量化多轮对话中的突变波动。通过理论分析和实证验证，证明SpikeScore在跨域场景中能有效区分幻觉和非幻觉回答。

Result: 在多个大语言模型和基准测试上的实验表明，基于SpikeScore的检测方法在跨域泛化方面优于代表性基线方法，超越了先进的面向泛化的方法，验证了该方法在跨域幻觉检测中的有效性。

Conclusion: 本文提出的SpikeScore方法通过分析多轮对话中的不确定性波动，实现了强大的跨域幻觉检测能力，为解决大语言模型在实际应用中的幻觉检测泛化问题提供了有效解决方案。

Abstract: Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this paper, we study an important yet overlooked problem, termed generalizable hallucination detection (GHD), which aims to train hallucination detectors on data from a single domain while ensuring robust performance across diverse related domains. In studying GHD, we simulate multi-turn dialogues following LLMs initial response and observe an interesting phenomenon: hallucination-initiated multi-turn dialogues universally exhibit larger uncertainty fluctuations than factual ones across different domains. Based on the phenomenon, we propose a new score SpikeScore, which quantifies abrupt fluctuations in multi-turn dialogues. Through both theoretical analysis and empirical validation, we demonstrate that SpikeScore achieves strong cross-domain separability between hallucinated and non-hallucinated responses. Experiments across multiple LLMs and benchmarks demonstrate that the SpikeScore-based detection method outperforms representative baselines in cross-domain generalization and surpasses advanced generalization-oriented methods, verifying the effectiveness of our method in cross-domain hallucination detection.

</details>


### [15] [GLOVE: Global Verifier for LLM Memory-Environment Realignment](https://arxiv.org/abs/2601.19249)
*Xingkun Yin,Hongyang Du*

Main category: cs.AI

TL;DR: GLOVE框架通过相对真理概念和主动探测记忆不一致性，实现无监督记忆更新，提升LLM在动态环境中的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM记忆增强方法假设记忆有效性可通过外部评估器或内部认知建立，但在实际动态漂移环境中这些假设往往失效，需要更鲁棒的记忆验证机制。

Method: 提出GLOVE框架，引入相对真理概念，通过主动探测检索记忆与新鲜观察之间的不一致性，实现无监督记忆验证和更新，不依赖外部监督或强模型内省。

Result: 在网页导航、规划和控制等多样化基准测试中，加入受控环境漂移后，GLOVE显著提高了智能体成功率。

Conclusion: GLOVE为LLM记忆系统提供了新的设计维度，通过相对真理验证实现记忆-环境重新对齐，为构建能够自我进化的认知智能体提供了鲁棒路径。

Abstract: Most existing memory-enhanced Large Language Model (LLM) approaches implicitly assume that memory validity can be established either through external evaluators that provide task-specific success signals or through internal model cognition, such as reflection, for editing memory entries. However, these assumptions often break down in practical environments with dynamic drifts. We propose the Global Verifier (GLOVE), a framework that introduces a new design dimension for LLM memory systems by establishing a relative notion of truth. Through active probing to detect inconsistencies between retrieved memories and fresh observations, GLOVE enables memory-environment realignment by verifying and updating memory without access to ground-truth supervision or strong reliance on model introspection. We evaluate GLOVE on diverse benchmarks spanning web navigation, planning, and control, augmented with controlled environmental drifts that introduce non-stationarity beyond the original benchmark settings. Our results show that GLOVE substantially improves agent success rates, suggesting a robust pathway to cognitive agents capable of self-evolving.

</details>


### [16] [RPO:Reinforcement Fine-Tuning with Partial Reasoning Optimization](https://arxiv.org/abs/2601.19404)
*Hongzhu Yi,Xinming Wang,Zhenghao zhang,Tianyu Zong,Yuanxiang Wang,Jun Xie,Tao Yu,Haopeng Jin,Zhepeng Wang,Kaixin Xu,Feng Chen,Jiahuan Chen,Yujia Yang,Zhenyu Guan,Bingkang Shi,Jungang Xu*

Main category: cs.AI

TL;DR: RPO是一种部分推理优化的强化微调算法，通过仅生成推理路径的后缀来减少约95%的token生成，显著降低训练时间开销，同时保持与完整路径算法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型强化微调算法需要从输入查询开始生成完整的推理轨迹，这在训练rollout阶段会产生巨大的计算开销。为了解决这个问题，作者分析了推理路径不同部分对最终结果正确性的影响。

Method: 提出RPO（部分推理优化的强化微调）算法，这是一种即插即用的强化微调方法。与传统生成完整推理路径不同，RPO通过经验缓存生成推理路径的后缀进行训练。在训练rollout阶段，这种方法能大幅减少token生成。

Result: RPO在训练rollout阶段减少了约95%的token生成，显著降低了理论时间开销。相比完整路径强化微调算法，RPO将1.5B模型的训练时间减少了90%，7B模型减少了72%。同时能与GRPO、DAPO等典型算法集成，在保持性能的同时实现训练加速。

Conclusion: RPO是一种高效的强化微调算法，通过部分推理优化策略显著减少了训练计算开销，同时保持了模型性能，为大规模语言模型的高效训练提供了实用解决方案。

Abstract: Within the domain of large language models, reinforcement fine-tuning algorithms necessitate the generation of a complete reasoning trajectory beginning from the input query, which incurs significant computational overhead during the rollout phase of training. To address this issue, we analyze the impact of different segments of the reasoning path on the correctness of the final result and, based on these insights, propose Reinforcement Fine-Tuning with Partial Reasoning Optimization (RPO), a plug-and-play reinforcement fine-tuning algorithm. Unlike traditional reinforcement fine-tuning algorithms that generate full reasoning paths, RPO trains the model by generating suffixes of the reasoning path using experience cache. During the rollout phase of training, RPO reduces token generation in this phase by approximately 95%, greatly lowering the theoretical time overhead. Compared with full-path reinforcement fine-tuning algorithms, RPO reduces the training time of the 1.5B model by 90% and the 7B model by 72%. At the same time, it can be integrated with typical algorithms such as GRPO and DAPO, enabling them to achieve training acceleration while maintaining performance comparable to the original algorithms. Our code is open-sourced at https://github.com/yhz5613813/RPO.

</details>


### [17] [Fuzzy expert system for the process of collecting and purifying acidic water: a digital twin approach](https://arxiv.org/abs/2601.19527)
*Temirbolat Maratuly,Pakizar Shamoi,Timur Samigulin*

Main category: cs.AI

TL;DR: 本文提出了一种结合数字孪生的模糊专家系统，用于控制酸性水净化过程，通过模拟人类推理来维持关键参数在期望水平，使非专业人员也能有效操作。


<details>
  <summary>Details</summary>
Motivation: 酸性水净化对于减少排放、降低腐蚀风险、实现处理水再利用和降低运营成本至关重要。自动化净化过程可以减少人工参与，降低工人安全风险。酸性水中含有硫化氢、二氧化碳等酸性成分，若不妥善处理会对环境造成严重威胁并加速设备腐蚀。

Method: 开发了结合数字孪生的模糊专家系统，使用Honeywell UniSim Design R492建立数字孪生模拟真实工业行为，通过MATLAB进行阀门动态系统辨识，利用OPC DA实现模拟器与控制器实时数据交换。模糊控制器采用分程控制策略控制两个阀门，在21种不同初始压力条件下使用5种去模糊化策略进行了105个测试场景。

Result: 系统性能通过误差指标（MSE、RMSE、MAE、IAE、ISE、ITAE）和动态响应指标（超调量、欠调量、上升时间、下降时间、稳定时间、稳态误差）进行评估。开发了基于Python Streamlit框架的Web仿真界面。

Conclusion: 虽然本文以酸性水处理为例进行演示，但所提出的模糊专家系统具有通用性，能够简化控制策略，使初级或非专业人员也能有效与系统交互。

Abstract: Purifying sour water is essential for reducing emissions, minimizing corrosion risks, enabling the reuse of treated water in industrial or domestic applications, and ultimately lowering operational costs. Moreover, automating the purification process helps reduce the risk of worker harm by limiting human involvement. Crude oil contains acidic components such as hydrogen sulfide, carbon dioxide, and other chemical compounds. During processing, these substances are partially released into sour water. If not properly treated, sour water poses serious environmental threats and accelerates the corrosion of pipelines and equipment. This paper presents a fuzzy expert system, combined with a custom-generated digital twin, developed from a documented industrial process to maintain key parameters at desired levels by mimicking human reasoning. The control strategy is designed to be simple and intuitive, allowing junior or non-expert personnel to interact with the system effectively. The digital twin was developed using Honeywell UniSim Design R492 to simulate real industrial behavior accurately. Valve dynamics were modeled through system identification in MATLAB, and real-time data exchange between the simulator and controller was established using OPC DA. The fuzzy controller applies split-range control to two valves and was tested under 21 different initial pressure conditions using five distinct defuzzification strategies, resulting in a total of 105 unique test scenarios. System performance was evaluated using both error-based metrics (MSE, RMSE, MAE, IAE, ISE, ITAE) and dynamic response metrics, including overshoot, undershoot, rise time, fall time, settling time, and steady-state error. A web-based simulation interface was developed in Python using the Streamlit framework. Although demonstrated here for sour water treatment, the proposed fuzzy expert system is general-purpose.

</details>


### [18] [Benchmarks Saturate When The Model Gets Smarter Than The Judge](https://arxiv.org/abs/2601.19532)
*Marthe Ballon,Andres Algaba,Brecht Verbeken,Vincent Ginis*

Main category: cs.AI

TL;DR: Omni-MATH-2是一个经过人工修订的数学数据集，包含4181个精确答案问题和247个带标签的非标准问题，旨在减少数据集噪声并提供更精确的模型性能评估。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型基准测试存在数据集不准确和评估方法不可靠的问题，这些问题削弱了基准测试的有效性，需要更干净的数据集和可靠的评估方法来准确衡量模型性能。

Method: 通过人工审核Omni-MATH数据集，确保LaTeX可编译性、可解性和可验证性，添加缺失的图形或信息，标记需要证明、估计或图像的问题，并移除杂乱内容。创建了包含精确答案子集和带标签非标准子集的Omni-MATH-2数据集。

Result: 数据集修订显著减少了数据集引起的噪声。通过比较GPT-5 mini与原始Omni-Judge，发现评估者之间存在显著差异，Omni-Judge在96.4%的评估分歧中出错。随着问题难度增加，需要更胜任的评估者来防止评估错误掩盖模型间的真实差异。

Conclusion: 数据集质量和评估者可靠性对于开发准确的模型性能基准都至关重要。当前评估方法无法识别带标签问题子集的失败模式，表明需要同时改进数据集质量和评估机制。

Abstract: Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset ($n{=}4181$) and a tagged, non-standard subset ($n{=}247$). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in $96.4\%$ of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance.

</details>


### [19] [Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search](https://arxiv.org/abs/2601.19622)
*Thomas Bömer,Nico Koltermann,Max Disselnmeyer,Bastian Amberg,Anne Meyer*

Main category: cs.AI

TL;DR: 本文提出A-CEoH框架，通过将A*算法代码融入提示词，利用上下文学习自动生成启发式函数，在UPMP和SPP问题上表现优于专家设计的手工启发式。


<details>
  <summary>Details</summary>
Motivation: 传统启发式函数需要专家手工设计，耗时且依赖专业知识。大语言模型和进化框架的发展为自动化启发式设计提供了可能，本文旨在探索如何利用这些技术自动生成A*搜索的引导启发式。

Method: 扩展EoH框架，提出A-CEoH方法，采用领域无关的提示增强策略，将A*算法代码融入提示词以利用上下文学习，在Unit-Load Pre-Marshalling Problem和滑动拼图问题两个领域进行验证。

Result: 计算实验表明，A-CEoH能显著提升生成启发式的质量，在测试的两个问题领域中都表现优异，甚至超越了专家设计的手工启发式。

Conclusion: A-CEoH框架成功实现了启发式函数的自动化生成，通过将算法代码融入提示词的上下文学习策略，能够产生高质量的启发式，为自动化启发式设计提供了有效途径。

Abstract: Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.

</details>


### [20] [Agentic Design Patterns: A System-Theoretic Framework](https://arxiv.org/abs/2601.19752)
*Minh-Dung Dao,Quy Minh Le,Hoang Thanh Lam,Duc-Trong Le,Quoc-Viet Pham,Barry O'Sullivan,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: 本文提出了一种基于系统理论的AI智能体工程化方法，包括一个五子系统框架和12种设计模式，用于解决智能体系统设计中的可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于基础模型的AI智能体系统存在幻觉、推理能力差等问题，且设计往往缺乏系统性理论支撑，导致应用不可靠且脆弱。现有设计模式分类缺乏严谨的系统理论基础，难以实际实施。

Method: 提出系统理论框架，将智能体系统解构为五个核心交互功能子系统：推理与世界模型、感知与接地、行动执行、学习与适应、智能体间通信。基于此架构，映射出12种智能体设计模式，分为基础型、认知与决策型、执行与交互型、适应与学习型四类。

Result: 通过ReAct框架的案例研究展示了该框架的实用性，表明所提出的设计模式能够纠正系统性架构缺陷，为研究人员和工程师提供了标准化的设计语言和方法论。

Conclusion: 这项工作为智能体设计提供了基础语言和结构化方法，能够标准化研究人员和工程师之间的设计交流，从而构建更模块化、可理解和可靠的自主系统。

Abstract: With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introducing a principled methodology for engineering robust AI agents. We propose two primary contributions: first, a novel system-theoretic framework that deconstructs an agentic AI system into five core, interacting functional subsystems: Reasoning & World Model, Perception & Grounding, Action Execution, Learning & Adaptation, and Inter-Agent Communication. Second, derived from this architecture and directly mapped to a comprehensive taxonomy of agentic challenges, we present a collection of 12 agentic design patterns. These patterns - categorised as Foundational, Cognitive & Decisional, Execution & Interaction, and Adaptive & Learning - offer reusable, structural solutions to recurring problems in agent design. The utility of the framework is demonstrated by a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. This work provides a foundational language and a structured methodology to standardise agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems.

</details>


### [21] [GAVEL: Towards rule-based safety through activation monitoring](https://arxiv.org/abs/2601.19768)
*Shir Rozenfeld,Rahul Pankajakshan,Itay Zloczower,Eyal Lenga,Gilad Gressel,Yisroel Mirsky*

Main category: cs.AI

TL;DR: 论文提出基于规则的激活安全新范式，将LLM激活建模为可组合的认知元素，通过谓词规则实时检测违规行为，实现高精度、可解释、可审计的AI治理。


<details>
  <summary>Details</summary>
Motivation: 现有基于激活的安全监控方法存在精度低、灵活性差、缺乏可解释性等问题，无法有效检测和预防表面文本不明显的危险行为，需要新的解决方案。

Method: 提出基于规则的激活安全范式：1）将激活建模为认知元素（CEs）——细粒度、可解释的因素；2）构建在CEs上的谓词规则系统；3）实时检测违规行为；4）提供可配置、可更新的安全框架。

Result: 基于组合规则的激活安全方法提高了检测精度，支持领域定制化，为可扩展、可解释、可审计的AI治理奠定了基础。将开源GAVEL框架和自动规则创建工具。

Conclusion: 基于规则的激活安全范式通过认知元素建模和谓词规则检测，解决了现有方法的局限性，实现了更精确、灵活、可解释的AI安全监控，推动了AI治理的发展。

Abstract: Large language models (LLMs) are increasingly paired with activation-based monitoring to detect and prevent harmful behaviors that may not be apparent at the surface-text level. However, existing activation safety approaches, trained on broad misuse datasets, struggle with poor precision, limited flexibility, and lack of interpretability. This paper introduces a new paradigm: rule-based activation safety, inspired by rule-sharing practices in cybersecurity. We propose modeling activations as cognitive elements (CEs), fine-grained, interpretable factors such as ''making a threat'' and ''payment processing'', that can be composed to capture nuanced, domain-specific behaviors with higher precision. Building on this representation, we present a practical framework that defines predicate rules over CEs and detects violations in real time. This enables practitioners to configure and update safeguards without retraining models or detectors, while supporting transparency and auditability. Our results show that compositional rule-based activation safety improves precision, supports domain customization, and lays the groundwork for scalable, interpretable, and auditable AI governance. We will release GAVEL as an open-source framework and provide an accompanying automated rule creation tool.

</details>


### [22] [An Interpretable Recommendation Model for Psychometric Data, With an Application to Gerontological Primary Care](https://arxiv.org/abs/2601.19824)
*Andre Paulino de Lima,Paula Castro,Suzana Carvalho Vaz de Andrade,Rosa Maria Marcucci,Ruth Caldeira de Melo,Marcelo Garcia Manzato*

Main category: cs.AI

TL;DR: 该研究提出了一种针对老年初级医疗保健的推荐系统模型，利用心理测量数据结构生成可视化解释，帮助医疗专业人员制定个性化护理计划。


<details>
  <summary>Details</summary>
Motivation: 医疗环境中推荐系统面临多重挑战：缺乏公开临床数据、用户难以理解推荐原因、遵循推荐存在风险、以及效果不确定性。特别是在老年初级医疗保健领域，随着人口老龄化，对信息技术解决方案的需求日益增长。

Method: 开发了一种推荐模型，利用心理测量数据结构生成忠实于模型且对医疗专业人员可解释的可视化解释。研究聚焦于老年初级医疗保健这一细分领域，通过巴西研究合作伙伴收集的医疗数据集进行离线性能评估，并进行用户研究评估模型生成的可视化解释的可解释性。

Result: 离线性能评估显示模型在医疗数据集上表现良好，用户研究结果表明模型生成的可视化解释具有良好的可解释性，能够帮助医疗专业人员理解推荐依据。

Conclusion: 提出的推荐模型能够推动推荐系统在老年初级医疗保健领域的应用，这一领域随着人口结构变化，需求、机会和信息技术需求都将显著增长。

Abstract: There are challenges that must be overcome to make recommender systems useful in healthcare settings. The reasons are varied: the lack of publicly available clinical data, the difficulty that users may have in understanding the reasons why a recommendation was made, the risks that may be involved in following that recommendation, and the uncertainty about its effectiveness. In this work, we address these challenges with a recommendation model that leverages the structure of psychometric data to provide visual explanations that are faithful to the model and interpretable by care professionals. We focus on a narrow healthcare niche, gerontological primary care, to show that the proposed recommendation model can assist the attending professional in the creation of personalised care plans. We report results of a comparative offline performance evaluation of the proposed model on healthcare datasets that were collected by research partners in Brazil, as well as the results of a user study that evaluates the interpretability of the visual explanations the model generates. The results suggest that the proposed model can advance the application of recommender systems in this healthcare niche, which is expected to grow in demand , opportunities, and information technology needs as demographic changes become more pronounced.

</details>


### [23] [Routing End User Queries to Enterprise Databases](https://arxiv.org/abs/2601.19825)
*Saikrishna Sudarshan,Tanay Kulkarni,Manasi Patwardhan,Lovekesh Vig,Ashwin Srinivasan,Tanmay Tulsidas Verlekar*

Main category: cs.AI

TL;DR: 该研究针对企业多数据库环境中的自然语言查询路由问题，通过扩展现有NL-to-SQL数据集构建真实基准，提出基于推理的模块化重排序策略，在各项指标上优于嵌入方法和直接LLM提示基线。


<details>
  <summary>Details</summary>
Motivation: 在多数据库企业环境中，随着数据库规模增大和领域重叠，查询路由变得越来越困难，特别是面对模糊查询时，需要更结构化、更鲁棒的基于推理的解决方案。

Method: 提出模块化、推理驱动的重排序策略，显式建模模式覆盖、结构连接性和细粒度语义对齐，而不是仅依赖嵌入或直接LLM提示。

Result: 所提出的方法在所有指标上一致优于嵌入方法和直接LLM提示基线，特别是在大规模、领域重叠的数据库存储库和模糊查询场景下表现更佳。

Conclusion: 研究表明，通过显式建模数据库结构特征和语义对齐的推理驱动方法，能够有效解决多数据库环境中的查询路由挑战，为实际企业应用提供了更可靠的解决方案。

Abstract: We address the task of routing natural language queries in multi-database enterprise environments. We construct realistic benchmarks by extending existing NL-to-SQL datasets. Our study shows that routing becomes increasingly challenging with larger, domain-overlapping DB repositories and ambiguous queries, motivating the need for more structured and robust reasoning-based solutions. By explicitly modelling schema coverage, structural connectivity, and fine-grained semantic alignment, the proposed modular, reasoning-driven reranking strategy consistently outperforms embedding-only and direct LLM-prompting baselines across all the metrics.

</details>


### [24] [Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models](https://arxiv.org/abs/2601.19834)
*Jialong Wu,Xiaoying Zhang,Hongyi Yuan,Xiangcheng Zhang,Tianhao Huang,Changjing He,Chaoyi Deng,Renrui Zhang,Youbin Wu,Mingsheng Long*

Main category: cs.AI

TL;DR: 该研究首次系统探讨视觉生成在推理中的价值，提出视觉优势假说：对于物理世界相关任务，视觉生成能更自然地作为世界模型，而纯语言模型会遭遇表示限制或先验知识不足的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在数学和编程等抽象领域已达到专家水平，但在物理和空间智能等需要丰富表示和先验知识的领域仍远落后于人类。统一多模态模型的出现引发了人们对基于互补多模态路径的更类人推理的兴趣，但其具体效益尚不明确。

Method: 从世界模型视角出发，理论层面将内部世界建模形式化为CoT推理的核心组件，分析不同形式世界模型的区别；实证层面识别需要交错视觉-语言CoT推理的任务，构建新的评估套件VisWorld-Eval，并在最先进的统一多模态模型上进行控制实验。

Result: 在有利于视觉世界建模的任务上，交错CoT显著优于纯语言CoT，但在其他任务上没有明显优势。这验证了视觉优势假说，阐明了多模态世界建模的潜力。

Conclusion: 该研究明确了多模态世界建模对于构建更强大、更类人的多模态AI的潜力，为理解视觉生成在推理中的作用提供了首个原则性研究框架。

Abstract: Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-level performance in formal and abstract domains such as mathematics and programming has been achieved in current systems by relying predominantly on verbal reasoning. However, they still lag far behind humans in domains like physical and spatial intelligence, which require richer representations and prior knowledge. The emergence of unified multimodal models (UMMs) capable of both verbal and visual generation has therefore sparked interest in more human-like reasoning grounded in complementary multimodal pathways, though their benefits remain unclear. From a world-model perspective, this paper presents the first principled study of when and how visual generation benefits reasoning. Our key position is the visual superiority hypothesis: for certain tasks--particularly those grounded in the physical world--visual generation more naturally serves as world models, whereas purely verbal world models encounter bottlenecks arising from representational limitations or insufficient prior knowledge. Theoretically, we formalize internal world modeling as a core component of CoT reasoning and analyze distinctions among different forms of world models. Empirically, we identify tasks that necessitate interleaved visual-verbal CoT reasoning, constructing a new evaluation suite, VisWorld-Eval. Controlled experiments on a state-of-the-art UMM show that interleaved CoT significantly outperforms purely verbal CoT on tasks that favor visual world modeling, but offers no clear advantage otherwise. Together, this work clarifies the potential of multimodal world modeling for more powerful, human-like multimodal AI.

</details>
