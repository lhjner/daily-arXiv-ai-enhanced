<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 提出了一种推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索，为LLMs提供与对话逻辑结构对齐的知识，超越表面语义相似性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs通常通过检索语义相似信息或提升推理能力来增强性能，但如何有效整合检索和推理策略以优化LLM性能仍是一个重要挑战。需要超越表面语义相似性，提供与对话逻辑结构对齐的知识。

Method: 采用粗到细的两阶段知识检索方法：1) 首先识别知识库中与上下文相关的子区域，确保所有句子都与主题相关；2) 在该子区域内细化搜索，提取与推理过程特别相关的知识。两阶段都使用蒙特卡洛树搜索启发的方法，通过常见关键词在知识句子中有效导航。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更贴近人类对话中的底层推理逻辑，还显著提高了检索知识的多样性，从而产生更具信息性和创造性的响应。

Conclusion: 提出的推理感知知识检索方法能够有效整合检索和推理策略，为LLMs提供与对话逻辑结构对齐的知识，超越传统的语义相似性检索，提升对话系统的性能和质量。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [2] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 本研究开发了一种基于大语言模型的尼日利亚皮钦语抑郁症自动筛查工具，在资源有限、语言多样的环境中实现了94.5%的PHQ-9严重程度评分准确率。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症筛查覆盖率低，传统工具如PHQ-9在高收入国家验证，但可能因语言文化障碍不适用于尼日利亚皮钦语和520多种本地语言环境。

Method: 收集432份尼日利亚年轻人皮钦语音频响应，进行转录、预处理和标注（语义标签、俚语解释、PHQ-9评分），然后微调三种LLM模型（Phi-3-mini、Gemma-3-4B、GPT-4.1）。

Result: GPT-4.1表现最佳，PHQ-9严重程度评分预测准确率达94.5%，在定量指标（准确率、精确度、语义对齐）和定性评估（清晰度、相关性、文化适宜性）上均优于其他模型。

Conclusion: AI驱动的抑郁症筛查工具可为尼日利亚等语言多样、资源有限的环境提供可行的解决方案，为部署对话式心理健康工具奠定基础。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [3] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 本文提出一种多算法方法来解决最后一公里包裹配送中的工作量平衡问题，通过结合距离和工作量考虑来优化包裹分配给配送员，确保每位员工每日完成相似的工作量。


<details>
  <summary>Details</summary>
Motivation: 传统的基于地理邻近性的包裹分配方法效率低下，容易导致配送员之间工作量分配不平衡。在最后一公里城市包裹配送系统中，需要解决运营人力资源工作量平衡问题，纠正配送员之间的显著工作量不平衡。

Method: 提出多算法方法，包括不同版本的k-means算法、进化方法、基于k-means初始化的递归分配（采用不同问题编码）以及混合进化集成算法。这些算法结合距离和工作量考虑来优化包裹分配给配送员。

Result: 在西班牙Azuqueca de Henares城市最后一公里包裹配送系统的实际案例中验证了所提方法的性能，展示了其在平衡配送员工作量方面的有效性。

Conclusion: 通过多算法方法优化最后一公里包裹配送系统的工作量分配，能够有效平衡配送员之间的工作量，提高系统效率，纠正工作量不平衡问题。

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [4] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 该论文提出了基于MinDist度量的规则化框架来改进印度拉米纸牌的策略，通过计算手牌与最近有效配置的编辑距离来评估手牌质量，显著提升了胜率。


<details>
  <summary>Details</summary>
Motivation: 13张牌的经典印度拉米纸牌是一个不完全信息的序列游戏，需要概率推理和组合决策。传统启发式方法在策略设计上存在局限性，需要更形式化和可解释的算法框架来提升游戏表现。

Method: 提出了基于MinDist度量的规则化框架，该度量通过量化手牌与最近有效配置的编辑距离来评估手牌结构接近完成的程度。设计了计算高效的算法，利用动态剪枝和模式缓存来精确计算该度量。在两人零和模拟框架中融入了对手手牌建模，并使用统计假设检验评估策略。

Result: 实证结果显示，基于MinDist的智能体相比传统启发式方法在胜率上有显著提升，为算法化拉米策略设计提供了形式化和可解释的步骤。

Conclusion: MinDist度量为印度拉米纸牌提供了有效的策略设计框架，通过形式化的手牌评估和对手建模，显著提升了游戏表现，为不完全信息纸牌游戏的算法策略设计提供了新思路。

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [5] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 研究探索生成式AI如何解读乡土建筑中的建筑智慧，以伊朗鸽塔为案例，测试三种扩散模型在不同提示阶段的性能，评估AI在类型、材料、环境、真实性和文化特异性方面的表现。


<details>
  <summary>Details</summary>
Motivation: 探究生成式AI系统如何理解和再现乡土建筑形式中蕴含的建筑智慧，分析AI在视觉相似性和建筑推理之间的边界，为理解AI如何感知、扭曲和重新想象传统设计智慧提供框架。

Method: 使用伊朗鸽塔作为案例研究，测试三种扩散模型（Midjourney v6、DALL-E 3和基于Stable Diffusion XL的DreamStudio），通过三个提示阶段（参考性、适应性、推测性），采用五标准评估框架（类型学、材料性、环境、真实性和文化特异性）。

Result: AI能可靠地复制几何图案，但误解材料和气候推理；参考图像提高了真实性但限制了创造性，而无参考的自由生成则产生创新但文化模糊的结果；定义了视觉相似性和建筑推理之间的边界。

Conclusion: 研究提出了计算乡土推理框架，用于分析AI如何感知、扭曲和重新想象传统设计智慧，揭示了AI在建筑理解方面的局限性和潜力，为未来AI在建筑领域的应用提供了重要见解。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [6] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 研究人员设计了一个基于大语言模型的智能体，能够从原始文本中提取因果反馈模糊认知图，并通过双向交互实现系统的准自主演化。


<details>
  <summary>Details</summary>
Motivation: 本文旨在开发一种能够从文本中自动提取因果关系的智能系统，通过结合大语言模型的半自主性和模糊认知图的动态系统特性，实现因果结构的自主学习和演化。

Method: 设计了一个三阶段的大语言模型智能体系统：1）从文本中提取关键名词和名词短语；2）从这些词汇中识别模糊认知图的概念节点；3）推断节点间的部分或模糊因果边。系统通过指令微调引导智能体完成这些任务。

Result: 测试显示，该系统从亨利·基辛格关于AI前景的论文中提取的模糊认知图，与人工生成的图具有相同的平衡极限环，尽管节点和边数量不同。混合不同大语言模型生成的图能够吸收主要成分的平衡点，同时创造新的平衡点以更好地近似底层因果动态系统。

Conclusion: 基于大语言模型的智能体能够有效地从文本中提取因果结构，形成具有准自主演化能力的动态系统。这种双向交互机制使系统能够在保持"智能体牵引"的同时获得一定程度的自主性，为因果建模提供了新的方法。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [7] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar系统结合质量多样性算法和大型语言模型，自主演化游戏机制用于自动游戏设计，通过合成完整游戏并评估技能排序来优化机制。


<details>
  <summary>Details</summary>
Motivation: 游戏机制设计是耗时且依赖专家的过程，需要自动化方法来探索多样化的游戏机制，以加速游戏设计流程。

Method: 结合质量多样性算法和大型语言模型探索多样化机制，通过树搜索程序合成完整游戏，评估机制对技能排序的贡献度。

Result: Mortar能生成多样且可玩的游戏，产生的机制在游戏中能更好地促进技能排序，消融研究和用户研究验证了系统组件的有效性。

Conclusion: Mortar系统成功实现了游戏机制的自主演化，为自动游戏设计提供了有效方法，通过技能排序评估机制质量是可行的。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [8] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 该论文研究了在视频问答任务中，基于置信度的选择性预测是否能可靠控制错误率，以及这种控制在分布偏移下是否稳健。研究发现置信度阈值在分布内提供机制性控制，但在分布偏移下可靠性下降。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在高风险部署中需要选择性预测，当系统不确定时应避免回答而非冒险犯错。研究旨在探索基于置信度的弃权是否能在视频问答中提供可靠的错误率控制，以及这种控制在分布偏移下是否稳健。

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型进行研究。通过扫描置信度阈值epsilon来产生风险-覆盖权衡曲线，分析置信度阈值在分布内和分布偏移下的表现。

Result: 研究发现：1）置信度阈值在分布内提供机制性控制，通过调整阈值可以平滑地降低错误率；2）但在分布偏移下，这种控制的可靠性下降，模型置信度校准失效。

Conclusion: 基于置信度的选择性预测在视频问答的分布内场景中有效，但在分布偏移下不可靠。这强调了在高风险应用中需要更稳健的置信度校准方法。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [9] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 研究发现LLM赋能的智能体不仅存在人口统计偏见，还会在最小群体线索下表现出群体间偏见。当这种群体边界与智能体-人类划分对齐时，人类整体可能被视为外群体。研究通过多智能体社会模拟验证了这一现象，并提出了信念中毒攻击（BPA）来抑制人类规范脚本，重新激活对人类的偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM赋能的智能体是否存在群体间偏见，特别是当智能体-人类划分成为群体边界时，人类整体是否会被智能体视为外群体。这种偏见比传统的人口统计偏见更加根本，可能导致人类被系统性歧视。

Method: 研究构建了受控的多智能体社会模拟，基于明确收益权衡下的分配决策来测试智能体行为。通过最小群体线索设置实验条件，并设计了信念中毒攻击（BPA），包括初始化时的档案中毒（BPA-PP）和通过优化信念精炼后缀注入存储反思中的记忆中毒（BPA-MP）。

Result: 实验发现智能体在最小群体线索下表现出一致的群体间偏见。虽然当某些对应方被框定为人类时这种偏见会减弱，但这种减弱依赖于智能体相信真实人类存在的信念。信念中毒攻击成功抑制了人类规范脚本，重新激活了对人类的外群体偏见。

Conclusion: LLM赋能的智能体确实存在群体间偏见风险，特别是当人类被划分为外群体时。信念中毒攻击揭示了新的攻击面，需要在档案和记忆边界实施缓解策略来强化当前的智能体框架。识别这些漏洞的目的是为了指导更安全的智能体设计。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [10] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt是一个受生物自愈机制启发的智能自愈框架，用于分布式计算连续体系统，通过语言模型驱动的智能体实现自主故障隔离、诊断、自适应恢复和知识整合。


<details>
  <summary>Details</summary>
Motivation: 现代分布式计算连续体系统（DCCS）集成了从物联网设备到云基础设施的异构计算资源，其固有的复杂性、移动性和动态运行条件使它们容易频繁发生故障，破坏服务连续性。这些挑战凸显了对可扩展、自适应和自我调节的弹性策略的需求。

Method: ReCiSt将生物自愈的四个阶段（止血、炎症、增殖、重塑）重构为计算层的四个层次：遏制、诊断、元认知和知识。这些层次通过语言模型驱动的智能体执行自主故障隔离、因果诊断、自适应恢复和长期知识整合。智能体解释异构日志，推断根本原因，优化推理路径，并以最少的人工干预重新配置资源。

Result: 在公共故障数据集上使用多种语言模型进行评估，结果显示ReCiSt能够在数十秒内实现自愈能力，智能体CPU使用率最低为10%。结果还展示了系统克服不确定性的分析深度以及为实现弹性而调用的微智能体数量。

Conclusion: ReCiSt框架成功地将生物自愈机制转化为计算弹性策略，为分布式计算连续体系统提供了可扩展、自适应和自我调节的故障恢复解决方案，通过语言模型驱动的智能体实现了高效的自主故障管理。

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [11] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: ACCD框架通过三阶段自适应架构检测社交媒体上的协同不实行为，显著提升检测精度并大幅减少人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 现有协同不实行为检测方法依赖表面相关性分析、使用静态参数设置、需要大量人工标注，存在明显局限性。

Method: 提出自适应因果协同检测（ACCD）框架，采用三阶段渐进架构：1）自适应收敛交叉映射技术识别账户间真实因果关系；2）半监督分类结合主动学习和不确定性采样减少人工标注；3）基于历史检测经验的自动验证模块实现自验证和优化。

Result: 在Twitter IRA数据集、Reddit协同痕迹等多个真实数据集上评估，ACCD在协同攻击检测中达到87.3%的F1分数，比现有最佳基线提升15.2%，减少68%人工标注需求，处理速度提升2.8倍。

Conclusion: ACCD为社交媒体协同行为检测提供了更准确、高效、高度自动化的端到端解决方案，具有重要实践价值和广泛应用潜力。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [12] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 该论文将语义空间推理从计算语言学扩展到团队运动的战术决策，将球员视为单词、团队配合视为语义结构，通过向量表示和距离度量评估战术匹配度，开发了可生成动态策略建议的Python原型。


<details>
  <summary>Details</summary>
Motivation: 传统计算语言学中的语义空间推理方法可以类比应用于团队运动的战术决策，将球员视为"单词"、团队配合视为"语义结构"，为团队战术分析提供新的量化框架。

Method: 将每个球员表示为整合技术、身体和心理属性的多维向量，通过上下文加权聚合成团队语义表示；在共享向量空间中编码战术模板（如高位压迫、反击、控球组织），使用向量距离度量评估战术匹配度和对手利用潜力。

Result: 开发了Python原型，能够生成可解释的动态自适应策略建议，并提供属性层面的细粒度诊断洞察；该方法不仅适用于足球，还可推广到篮球、曲棍球、协作机器人、人机协调系统等团队领域。

Conclusion: 该方法为基于团队的集体决策和性能优化提供了通用框架，未来方向包括真实数据集成、预测模拟以及混合人机战术智能的发展。

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [13] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 研究发现推理模型中的"顿悟时刻"（中间推理转变）很罕见，不会随训练变得更频繁，也很少提高准确性，表明这些转变并非模型内在的自我修正机制，而是推理不稳定的表现。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为像DeepSeek-R1-Zero这样的模型在推理过程中会出现突然的"顿悟时刻"，导致准确输出，暗示模型具有内在的自我修正能力。但尚不清楚这种推理策略的内在转变是否真正提高了性能。

Method: 研究分析了超过100万条推理轨迹、数百个训练检查点、三个推理领域、多种解码温度和模型架构，检测中间推理转变，并人工触发外在转变来验证效果。

Result: 推理转变很罕见，不会随训练变得更频繁，也很少提高准确性，表明它们并非模型洞察力的表现。然而，其效果随模型不确定性而变化：在高熵条件下人工触发外在转变能可靠提高准确性。

Conclusion: 中间推理转变是推理不稳定的症状，而非内在的自我修正机制。模型在高不确定性条件下的人工干预可以改善性能，但自然发生的"顿悟时刻"并非有效的自我修正机制。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [14] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO提出了一种难度感知的直接偏好优化框架，通过平衡偏好数据中的难度差异来解决MLLMs中的幻觉问题，避免过拟合并提升细粒度幻觉抑制能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态DPO方法因偏好数据中的难度不平衡而容易过拟合，MLLMs倾向于过度关注容易区分的偏好对，这阻碍了细粒度幻觉抑制并降低整体性能。

Method: DA-DPO包含两个主要组件：1) 难度估计：利用预训练的视觉-语言模型，结合生成式和对比式目标，通过分布感知投票策略产生鲁棒的难度分数；2) 难度感知训练：基于估计的难度重新加权偏好对，降低简单样本权重，强调困难样本以缓解过拟合。

Result: 大量实验表明DA-DPO持续改进多模态偏好优化，在标准基准测试中展现出更强的幻觉鲁棒性和更好的泛化能力，同时保持计算效率。

Conclusion: DA-DPO通过难度感知的偏好优化框架有效解决了多模态DPO中的过拟合问题，在不增加新数据或额外微调阶段的情况下，实现了更有效的幻觉抑制和性能提升。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [15] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM：基于视觉和知识增强的LLM框架，用于行人过街行为推理，相比传统方法具有更好的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法（统计模型和监督学习）泛化能力有限，在新场景中表现不佳。LLMs提供了从数值模式拟合到语义、上下文感知行为推理的转变机会，但现有LLM应用缺乏领域特定适应和视觉上下文。

Method: 提出PedX-LLM框架，整合LLaVA提取的视觉特征、文本数据和交通领域知识，通过LoRA微调LLaMA-2-7B基础模型来推断过街决策。采用零样本和少样本学习策略评估跨站点泛化能力。

Result: PedX-LLM达到82.0%的平衡准确率，优于最佳统计和监督学习方法。视觉增强模块贡献2.9%性能提升，领域知识集成带来额外4.1%改进。在5个未见测试站点上，零样本配置达到66.9%平衡准确率，少样本学习（仅5个验证示例）提升至72.2%。

Conclusion: PedX-LLM在未见场景中表现出强大的泛化能力，证实视觉和知识增强的推理使模型能够模仿人类决策逻辑，克服纯数据驱动方法的局限性。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


### [16] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: ADS通过智能体工作流将自然语言任务描述自动转换为完整的DomiKnowS程序，显著降低神经符号编程门槛


<details>
  <summary>Details</summary>
Motivation: 现有神经符号框架如DomiKnowS虽然提供了高级声明式编程接口，但仍要求用户熟悉特定语法，这限制了其可访问性和使用效率

Method: 提出AgenticDomiKnowS(ADS)，采用智能体工作流将自由形式的任务描述翻译为完整的DomiKnowS程序，支持创建和单独测试每个组件，并允许可选的人工干预

Result: ADS使有经验和无经验的DomiKnowS用户都能快速构建神经符号程序，将开发时间从数小时缩短至10-15分钟

Conclusion: ADS通过消除对特定库语法的依赖，显著提高了神经符号编程的可访问性和开发效率，支持人类在环干预进一步增强了系统的实用性

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>
