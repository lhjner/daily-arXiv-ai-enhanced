<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 22]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models](https://arxiv.org/abs/2512.23850)
*Rahul Baxi*

Main category: cs.AI

TL;DR: 本文提出DDFT评估框架，用于衡量语言模型在语义压缩和对抗性干扰下的认知稳健性，发现模型规模与稳健性无关，而错误检测能力是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型评估主要测量理想条件下的知识掌握情况，但无法评估模型在现实压力下的稳健性。传统基准测试如MMLU和TruthfulQA无法区分模型是缺乏知识还是验证机制在信息退化或对抗性攻击下崩溃。

Method: 提出DDFT（Drill-Down and Fabricate Test）评估协议，采用两系统认知模型：语义系统生成流畅文本，认知验证器验证事实准确性。评估9个前沿模型在8个知识领域和5个压缩级别下的表现（共1800次轮级评估）。

Result: 认知稳健性与传统设计范式正交：参数数量（r=0.083, p=0.832）和架构类型（r=0.153, p=0.695）均不能显著预测稳健性。错误检测能力强烈预测整体稳健性（rho=-0.817, p=0.007）。旗舰模型尽管规模大但表现脆弱，而小型模型可能实现稳健性能。

Conclusion: DDFT框架为评估语言模型在关键应用部署前的认知稳健性提供了理论基础和实用工具，挑战了模型规模与可靠性关系的传统假设，表明训练方法和验证机制对稳健性更为关键。

Abstract: Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.

</details>


### [2] [CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution](https://arxiv.org/abs/2512.23880)
*Xu Huang,Junwu Chen,Yuxing Fei,Zhuohan Li,Philippe Schwaller,Gerbrand Ceder*

Main category: cs.AI

TL;DR: CASCADE是一个自我进化的LLM智能体框架，通过持续学习和自我反思机制，使AI能够掌握复杂外部工具并积累可执行技能，在科学任务中实现从"LLM+工具使用"到"LLM+技能获取"的转变。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体依赖预定义工具或脆弱的工具生成，限制了其在复杂科学任务中的能力和适应性。需要一种能够自主学习和适应新工具的框架。

Method: CASCADE框架通过两种元技能实现自我进化：1) 持续学习（通过网页搜索和代码提取）；2) 自我反思（通过内省和知识图谱探索）。该框架还支持人机协作和记忆巩固。

Result: 在SciSkillBench基准测试（116个材料科学和化学研究任务）中，使用GPT-5的CASCADE实现了93.3%的成功率，而没有进化机制的情况下仅为35.4%。框架在实际应用中展示了计算分析、自主实验室实验和论文选择性复制的能力。

Conclusion: CASCADE通过积累可跨智能体和科学家共享的可执行技能，推动了可扩展的AI辅助科学研究，代表了从"LLM+工具使用"向"LLM+技能获取"的重要转变。

Abstract: Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + tool use" to "LLM + skill acquisition". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.

</details>


### [3] [A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming](https://arxiv.org/abs/2512.23932)
*Ioanna Gemou,Evangelos Lamprou*

Main category: cs.AI

TL;DR: McCoy框架结合大语言模型与回答集编程，通过LLM将医学文献转化为ASP代码，结合患者数据进行疾病诊断，实现可解释的预测系统。


<details>
  <summary>Details</summary>
Motivation: 准确的疾病预测对及时干预、有效治疗和减少医疗并发症至关重要。虽然符号AI已在医疗保健中应用，但由于构建高质量知识库需要大量努力，其采用仍然有限。

Method: McCoy框架结合大型语言模型与回答集编程：1) 使用LLM将医学文献翻译成ASP代码；2) 将生成的ASP代码与患者数据结合；3) 使用ASP求解器处理以获得最终诊断。

Result: 初步结果显示McCoy在小规模疾病诊断任务上表现出色，创建了一个强大且可解释的预测框架，充分利用了两种范式的优势。

Conclusion: McCoy框架成功克服了符号AI在医疗领域应用的主要障碍，通过结合LLM和ASP技术，实现了自动化的知识库构建和可解释的疾病诊断系统。

Abstract: Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.

</details>


### [4] [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](https://arxiv.org/abs/2512.24008)
*Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury*

Main category: cs.AI

TL;DR: SPARK是一个基于多智能体LLM的个性化搜索框架，通过角色化智能体协作实现动态检索和个性化，模拟人类信息寻求行为的复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统个性化搜索系统受限于静态用户画像和单一检索流程，难以捕捉用户动态、多维的信息需求变化，需要更灵活、细粒度的个性化方法。

Method: 定义角色空间（角色、专业知识、任务上下文、领域），引入角色协调器动态激活相关智能体，每个智能体执行独立的检索增强生成过程，配备长短期记忆存储和上下文感知推理模块，通过结构化通信协议实现智能体间协作。

Result: 框架产生了关于协调效率、个性化质量和认知负载分布的可测试预测，同时包含自适应学习机制用于持续角色优化，为下一代搜索系统提供了理论基础。

Conclusion: SPARK通过细粒度智能体专业化与协作检索的结合，为能够捕捉人类信息寻求行为复杂性、流动性和上下文敏感性的下一代搜索系统提供了重要见解。

Abstract: Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in which coordinated persona-based large language model (LLM) agents deliver task-specific retrieval and emergent personalization. SPARK formalizes a persona space defined by role, expertise, task context, and domain, and introduces a Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents. Each agent executes an independent retrieval-augmented generation process, supported by dedicated long- and short-term memory stores and context-aware reasoning modules. Inter-agent collaboration is facilitated through structured communication protocols, including shared memory repositories, iterative debate, and relay-style knowledge transfer. Drawing on principles from cognitive architectures, multi-agent coordination theory, and information retrieval, SPARK models how emergent personalization properties arise from distributed agent behaviors governed by minimal coordination rules. The framework yields testable predictions regarding coordination efficiency, personalization quality, and cognitive load distribution, while incorporating adaptive learning mechanisms for continuous persona refinement. By integrating fine-grained agent specialization with cooperative retrieval, SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.

</details>


### [5] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow是一个自进化智能体框架，通过将LLM集成到"计划-执行-总结"认知范式中，显著提升进化效率，在算法发现和机器学习管道优化中优于现有基线方法达60%。


<details>
  <summary>Details</summary>
Motivation: 传统进化方法在从静态大语言模型向自改进智能体过渡时存在结构化推理不足的问题，现有方法在高维代码空间中面临早熟收敛和低效探索的挑战。

Method: LoongFlow框架整合LLM到"计划-执行-总结"认知范式，采用混合进化记忆系统，结合多岛模型、MAP-Elites和自适应玻尔兹曼选择，平衡探索与利用的权衡。

Result: 在AlphaEvolve基准测试和Kaggle竞赛中，LoongFlow在进化效率上比OpenEvolve、ShinkaEvolve等领先基线提升高达60%，并能发现更优的解决方案。

Conclusion: LoongFlow代表了自主科学发现的重要进展，能够以更低的计算成本生成专家级解决方案，解决了传统进化方法在结构化推理方面的局限性。

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


### [6] [Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks](https://arxiv.org/abs/2512.24156)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.AI

TL;DR: 提出了一种无需训练的图基方法，用于解决ARC-AGI-3基准中的交互推理任务。该方法通过视觉帧处理结合系统化的状态空间探索，在稀疏反馈环境中显著优于前沿LLM方法。


<details>
  <summary>Details</summary>
Motivation: ARC-AGI-3基准包含类似游戏的任务，需要智能体通过有限交互推断任务机制并适应逐渐增加的复杂性。现有最先进的LLM无法可靠解决这些任务，因此需要探索新的方法。

Method: 结合基于视觉的帧处理与系统化的状态空间探索，使用图结构表示。方法包括：1）将视觉帧分割为有意义的组件；2）基于视觉显著性优先处理动作；3）维护探索状态和转换的有向图；4）通过跟踪已访问状态和已测试动作，优先选择到未测试状态-动作对的最短路径。

Result: 在ARC-AGI-3预览挑战中，该方法解决了6个游戏中52个级别的中位数30个级别，在私有排行榜上排名第3，显著优于前沿的LLM智能体。

Conclusion: 即使没有学习，显式的图结构探索也可以作为交互推理的强大基线，并强调了在稀疏反馈环境中系统化状态跟踪和动作优先级的重要性，这些是当前LLM未能捕捉任务动态的关键方面。

Abstract: We present a training-free graph-based approach for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. ARC-AGI-3 comprises game-like tasks where agents must infer task mechanics through limited interactions, and adapt to increasing complexity as levels progress. Success requires forming hypotheses, testing them, and tracking discovered mechanics. The benchmark has revealed that state-of-the-art LLMs are currently incapable of reliably solving these tasks. Our method combines vision-based frame processing with systematic state-space exploration using graph-structured representations. It segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions. By tracking visited states and tested actions, the agent prioritizes actions that provide the shortest path to untested state-action pairs. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning and underscore the importance of systematic state tracking and action prioritization in sparse-feedback environments where current LLMs fail to capture task dynamics. The code is open source and available at https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore.

</details>


### [7] [Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment](https://arxiv.org/abs/2512.24263)
*Lijun Zhang,Lin Li,Wei Wei,Yajie Qi,Huizhong Song,Jun Wang,Yaodong Yang,Jiye Liang*

Main category: cs.AI

TL;DR: 本文提出了一种风险感知的逐步对齐方法（RSA），通过引入嵌套风险度量来增强语言模型安全对齐，有效抑制低概率高危害行为，同时保持模型的有用性。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法（如Safe RLHF和SACPO）通常采用风险中性范式，无法充分处理参考策略偏差带来的风险，且对罕见但可能灾难性的有害行为缺乏鲁棒性。

Method: 提出风险感知逐步对齐（RSA）方法，将安全对齐建模为token级别的风险感知约束策略优化问题，通过逐步对齐过程利用嵌套风险度量推导token级别的策略更新。

Result: 实验结果表明，该方法在保持高水平有用性的同时确保了强大的安全性，并显著抑制了尾部风险（低概率但高影响的不安全响应）。

Conclusion: RSA方法通过显式纳入风险感知，有效解决了现有安全对齐方法的局限性，在风险控制和模型性能之间取得了良好平衡。

Abstract: When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.

</details>


### [8] [What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?](https://arxiv.org/abs/2512.24497)
*Basile Terver,Tsung-Yen Yang,Jean Ponce,Adrien Bardes,Yann LeCun*

Main category: cs.AI

TL;DR: 该研究系统分析了基于JEPA世界模型的规划方法，通过实验确定了最优架构、训练目标和规划算法组合，提出的模型在导航和操作任务上超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: AI领域长期面临开发能够解决广泛物理任务并泛化到新环境的智能体挑战。现有方法通过世界模型和规划算法解决新任务，但规划通常在输入空间进行。最近方法在表示空间进行规划，承诺通过抽象无关细节实现更高效规划，但需要系统研究其技术选择。

Method: 将这类模型定义为JEPA-WMs，系统研究模型架构、训练目标和规划算法等关键组件。使用模拟环境和真实机器人数据进行实验，分析不同技术选择对规划成功率的影响。

Result: 通过实验确定了最优方法组合，提出的模型在导航和操作任务上超越了DINO-WM和V-JEPA-2-AC两个基准模型。代码、数据和检查点已开源。

Conclusion: JEPA-WMs家族中的技术选择对规划性能有显著影响，通过系统研究找到了最优组合，为表示空间规划方法提供了实证指导。

Abstract: A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at https://github.com/facebookresearch/jepa-wms.

</details>


### [9] [Evaluating the Reasoning Abilities of LLMs on Underrepresented Mathematics Competition Problems](https://arxiv.org/abs/2512.24505)
*Samuel Golladay,Majid Bani-Yaghoub*

Main category: cs.AI

TL;DR: 该研究分析了三个主流大语言模型（GPT-4o-mini、Gemini-2.0-Flash、DeepSeek-V3）在代表性不足的数学竞赛问题（密苏里大学数学竞赛）上的表现，发现DeepSeek-V3在所有三个数学领域（微积分、解析几何、离散数学）表现最佳，但所有模型在几何问题上都表现较弱。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多使用相同的数据集评估大语言模型的数学推理能力，这限制了研究结果的普适性，可能无法完全捕捉数学任务中的多样化挑战。本研究旨在分析大语言模型在代表性不足的数学竞赛问题上的表现，以更全面地了解其数学推理能力。

Method: 研究使用密苏里大学数学竞赛中的微积分、解析几何和离散数学问题，对三个主流大语言模型（GPT-4o-mini、Gemini-2.0-Flash、DeepSeek-V3）进行测试。将模型的回答与已知正确答案进行比较，以确定每个问题领域的准确性。同时分析模型的推理过程，探索不同问题类型和模型之间的错误模式。

Result: DeepSeek-V3在微积分、解析几何和离散数学三个类别中表现最佳，无论是推理过程还是最终答案的正确性。所有三个大语言模型在几何问题上都表现出明显的弱点。DeepSeek-V3的大多数错误归因于计算和逻辑错误，GPT-4o-mini经常出现逻辑和方法相关的错误，而Gemini则倾向于推理不完整和匆忙得出结论。

Conclusion: 在代表性不足的数学竞赛数据集上评估大语言模型可以提供对其独特错误模式的更深入洞察，并突显在结构化推理方面（特别是在几何领域）的持续挑战。这有助于更全面地理解大语言模型的数学推理能力局限性。

Abstract: Understanding the limitations of Large Language Models, or LLMs, in mathematical reasoning has been the focus of several recent studies. However, the majority of these studies use the same datasets for benchmarking, which limits the generalizability of their findings and may not fully capture the diverse challenges present in mathematical tasks. The purpose of the present study is to analyze the performance of LLMs on underrepresented mathematics competition problems. We prompted three leading LLMs, namely GPT-4o-mini, Gemini-2.0-Flash, and DeepSeek-V3, with the Missouri Collegiate Mathematics Competition problems in the areas of Calculus, Analytic Geometry, and Discrete Mathematics. The LLMs responses were then compared to the known correct solutions in order to determine the accuracy of the LLM for each problem domain. We also analyzed the LLMs reasoning to explore patterns in errors across problem types and models. DeepSeek-V3 has the best performance in all three categories of Calculus, Analytic Geometry, and Discrete Mathematics, both in reasoning and correct final answers. All three LLMs exhibited notably weak performance in Geometry. The majority of errors made by DeepSeek-V3 were attributed to computational and logical mistakes, whereas GPT-4o-mini frequently exhibited logical and approach-related errors. Gemini, on the other hand, tended to struggle with incomplete reasoning and drawing rushed conclusions. In conclusion, evaluating LLMs on underrepresented mathematics competition datasets can provide deeper insights into their distinct error patterns and highlight ongoing challenges in structured reasoning, particularly within the domain of Geometry.

</details>


### [10] [From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning](https://arxiv.org/abs/2512.24532)
*Amir Tahmasbi,Sadegh Majidi,Kazem Taram,Aniket Bera*

Main category: cs.AI

TL;DR: 论文提出两阶段方法提升大语言模型的空间推理能力：先通过监督微调学习基础空间变换，再通过GRPO框架训练LoRA适配器进行多步规划，在ASCII艺术环境中表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在通用语言能力上表现强劲，但在结构化环境中的空间变换和多步规划方面仍然存在困难，这限制了其在导航和规划等应用中的表现。

Method: 采用两阶段方法：1) 对基础空间变换（旋转、平移、缩放）进行监督微调，使模型具备基本空间物理知识；2) 冻结该物理感知模型，在GRPO框架内训练轻量级LoRA适配器，学习将这些基础模块组合用于谜题环境中的多步闭环规划。为此合成了ASCII艺术数据集并构建了相应的强化学习环境。

Result: 该方法在动态环境（有显式状态更新）和静态环境（模型必须依赖内部状态）中均一致优于基线模型，包括通用主干模型、物理感知模型和端到端RL模型。此外，该方法收敛更快，训练更稳定，注意力模式分析显示微调确实带来了空间理解的有意义改进。

Conclusion: 通过将空间推理分解为原子构建块及其组合的两阶段方法，有效提升了大语言模型在结构化环境中的空间推理能力，为导航和规划等应用提供了更可靠的解决方案。

Abstract: Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.

</details>


### [11] [Recursive Language Models](https://arxiv.org/abs/2512.24601)
*Alex L. Zhang,Tim Kraska,Omar Khattab*

Main category: cs.AI

TL;DR: RLMs是一种推理策略，让LLMs通过编程方式检查、分解和递归调用自身来处理任意长提示，显著提升长上下文任务性能


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型处理超长提示的局限性，突破模型上下文窗口的限制，提升长上下文任务的处理能力

Method: 提出递归语言模型（RLMs），将长提示视为外部环境，允许LLM编程式地检查、分解提示片段，并递归调用自身处理这些片段

Result: RLMs能处理超出模型上下文窗口两个数量级的输入，在四个不同的长上下文任务中，即使对于较短提示，也显著优于基础LLMs和常见长上下文框架，且查询成本相当或更低

Conclusion: RLMs为LLMs处理任意长提示提供了一种有效的推理时扩展方法，在保持成本效益的同时显著提升了长上下文任务的处理能力

Abstract: We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.

</details>


### [12] [Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization](https://arxiv.org/abs/2512.24609)
*Dong Qiu,Duo Xu,Limengxi Yue*

Main category: cs.AI

TL;DR: 提出一个强化学习增强的LLM多智能体框架，通过Dec-POMDP建模合作，采用CTDE训练，引入GRPO优化策略，在协作写作和编程任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在语言任务上表现良好，但在多智能体环境中缺乏协作意识，难以优化全局性能。需要解决LLM在多智能体协作中的协调问题。

Method: 1. 将合作建模为分散部分可观察马尔可夫决策过程(Dec-POMDP)；2. 采用集中训练分散执行(CTDE)框架；3. 引入组相对策略优化(GRPO)联合优化智能体策略；4. 设计简化联合奖励函数平衡任务质量、速度和协调成本。

Result: 1. 任务处理速度比单智能体基线提高3倍；2. 协作写作中结构/风格一致性达到98.7%；3. 编程任务测试通过率达到74.6%；4. 持续优于强大多智能体LLM基线。

Conclusion: 该框架为复杂工作流中的可靠协作提供了实用路径，显著提升了多智能体LLM的协作性能，在协作写作和编程任务上表现出色。

Abstract: Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.

</details>


### [13] [Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning](https://arxiv.org/abs/2512.24613)
*Zheyu Shi,Dong Qiu,Shanlong Yu*

Main category: cs.AI

TL;DR: 提出基于群体审议的多智能体对话模型，通过三层角色架构（生成、验证、整合）提升复杂推理能力，在多个数据集上显著提高多跳推理准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 单一大型语言模型在处理复杂推理任务时存在局限性，需要更有效的多智能体协作机制来提升推理质量和稳定性。

Method: 采用三层角色划分架构：观点生成智能体产生多样化推理视角，证据验证智能体检索外部知识并量化事实支持度，一致性仲裁智能体整合逻辑一致的结论。引入自博弈机制扩展多路径推理轨迹，检索增强模块动态补充外部知识，设计结合事实一致性和逻辑连贯性的复合奖励函数，应用改进的近端策略优化策略进行协同训练。

Result: 在HotpotQA上多跳推理准确率提升16.8%，在2WikiMultihopQA上提升14.3%，在MeetingBank上提升19.2%，一致性提高21.5%，推理效率优于主流多智能体方法。

Conclusion: 该模型为复杂推理任务提供了有效且稳定的解决方案，通过群体审议机制和多智能体协作显著提升了推理质量和效率。

Abstract: This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.

</details>


### [14] [Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions](https://arxiv.org/abs/2512.24679)
*Pengcheng Xia,Yixiang Huang,Chengjin Qin,Chengliang Liu*

Main category: cs.AI

TL;DR: 本文提出了一种多模态跨域混合融合模型，通过双重解耦框架分离模态不变与模态特定特征、域不变与域特定表示，结合跨域混合融合策略和三模态融合机制，提升电机故障诊断在未见工况下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有智能故障诊断方法在真实场景中面临性能下降问题，特别是当模型在未见工况下测试时。现有域适应方法依赖目标域样本，且大多数研究依赖单模态传感信号，忽视了多模态信息的互补性对提升模型泛化能力的作用。

Method: 提出多模态跨域混合融合模型，包含：1）双重解耦框架，分离模态不变与模态特定特征、域不变与域特定表示；2）跨域混合融合策略，随机混合跨域的模态信息以增强模态和域多样性；3）三模态融合机制，自适应整合多模态异构信息。

Result: 在感应电机故障诊断实验中，包括未见恒定工况和时变工况，该方法始终优于先进方法。全面的消融研究进一步验证了每个提出组件和多模态融合的有效性。

Conclusion: 该方法通过双重解耦和跨域混合融合，有效解决了多模态故障诊断中的域泛化问题，在未见工况下表现出优越性能，为智能故障诊断提供了新的解决方案。

Abstract: Intelligent fault diagnosis has become an indispensable technique for ensuring machinery reliability. However, existing methods suffer significant performance decline in real-world scenarios where models are tested under unseen working conditions, while domain adaptation approaches are limited to their reliance on target domain samples. Moreover, most existing studies rely on single-modal sensing signals, overlooking the complementary nature of multi-modal information for improving model generalization. To address these limitations, this paper proposes a multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis. A dual disentanglement framework is developed to decouple modality-invariant and modality-specific features, as well as domain-invariant and domain-specific representations, enabling both comprehensive multi-modal representation learning and robust domain generalization. A cross-domain mixed fusion strategy is designed to randomly mix modality information across domains for modality and domain diversity augmentation. Furthermore, a triple-modal fusion mechanism is introduced to adaptively integrate multi-modal heterogeneous information. Extensive experiments are conducted on induction motor fault diagnosis under both unseen constant and time-varying working conditions. The results demonstrate that the proposed method consistently outperforms advanced methods and comprehensive ablation studies further verify the effectiveness of each proposed component and multi-modal fusion. The code is available at: https://github.com/xiapc1996/MMDG.

</details>


### [15] [BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis](https://arxiv.org/abs/2512.24686)
*Songqi Zhou,Ruixue Liu,Boman Su,Jiazhou Wang,Yixing Wang,Benben Jiang*

Main category: cs.AI

TL;DR: 提出BatteryAgent框架，将物理知识特征与大语言模型推理能力结合，实现锂离子电池故障的智能诊断，超越传统二元分类方法


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法虽然检测精度高，但存在"黑盒"问题，缺乏可解释性，且受限于二元分类范式，无法提供根本原因分析和维护建议

Method: 提出三层框架：1)物理感知层提取10个基于电化学原理的特征；2)检测与归因层使用梯度提升决策树和SHAP量化特征贡献；3)推理与诊断层利用LLM作为智能体核心，构建"数值-语义"桥梁，结合SHAP归因和机理知识库生成综合诊断报告

Result: BatteryAgent有效纠正了边界样本的误分类，AUROC达到0.986，显著优于现有最先进方法，并将传统二元检测扩展到多类型可解释诊断

Conclusion: 该框架为电池安全管理提供了从"被动检测"到"智能诊断"的新范式转变，实现了故障类型、根本原因分析和维护建议的综合诊断能力

Abstract: Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their "black-box" nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a "numerical-semantic" bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from "passive detection" to "intelligent diagnosis" for battery safety management.

</details>


### [16] [Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences](https://arxiv.org/abs/2512.24829)
*Emmanuel Fashae,Michael Burke,Leimin Tian,Lingheng Meng,Pamela Carreno-Medrano*

Main category: cs.AI

TL;DR: 该研究提出了一个包含四个可解释维度的物体摆放偏好框架，并通过问卷验证了这些维度的心理区分度，最后将其集成到MCTS规划器中生成符合人类偏好的物体摆放方案。


<details>
  <summary>Details</summary>
Motivation: 当前基于人类演示的机器人家庭物体重排系统虽然能有效预测，但缺乏对人类决策背后可解释因素的洞察。研究者希望开发一个更透明、可解释的偏好模型来指导机器人规划。

Method: 1. 提出四个可解释的偏好维度：空间实用性、习惯便利性、语义连贯性、常识适当性；2. 设计并验证自报告问卷（63名参与者在线研究）；3. 将验证后的偏好维度集成到蒙特卡洛树搜索（MCTS）规划器中。

Result: 1. 问卷研究确认了四个维度的心理区分度和解释力（厨房和客厅两种场景）；2. 基于参与者偏好的MCTS规划器能生成合理的物体摆放方案，与参与者生成的方案高度一致。

Conclusion: 该研究贡献了一个紧凑、可解释的物体摆放偏好框架，并展示了如何将其操作化用于机器人规划，为开发更透明、符合人类偏好的机器人系统提供了理论基础。

Abstract: Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.

</details>


### [17] [GenZ: Foundational models as latent variable generators within traditional statistical models](https://arxiv.org/abs/2512.24834)
*Marko Jojic,Nebojsa Jojic*

Main category: cs.AI

TL;DR: GenZ提出了一种混合模型，通过可解释的语义特征桥接基础模型和统计建模，在房价预测和电影推荐任务中显著优于纯基础模型方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然具有广泛的领域知识，但往往无法捕捉对预测任务至关重要的数据集特定模式。现有方法过度依赖基础模型的领域理解，而忽略了数据集特有的统计规律。

Method: 通过迭代过程发现语义特征描述，对比统计建模误差识别的项目组。采用广义EM算法联合优化语义特征描述符和统计模型参数，将冻结的基础模型对项目的分类判断视为潜在二元特征的噪声观测。

Result: 在房价预测中，使用多模态列表数据发现的语义特征实现了12%的中位数相对误差，显著优于GPT-5基线的38%误差。在Netflix电影嵌入预测中，仅从语义描述就达到了0.59的余弦相似度，相当于传统协同过滤需要约4000个用户评分的性能。

Conclusion: GenZ成功地将基础模型的语义理解与统计建模相结合，发现了数据集特定的模式（如建筑细节预测当地住房市场、系列电影成员预测用户偏好），这些模式超越了单纯的基础模型领域知识。

Abstract: We present GenZ, a hybrid model that bridges foundational models and statistical modeling through interpretable semantic features. While large language models possess broad domain knowledge, they often fail to capture dataset-specific patterns critical for prediction tasks. Our approach addresses this by discovering semantic feature descriptions through an iterative process that contrasts groups of items identified via statistical modeling errors, rather than relying solely on the foundational model's domain understanding. We formulate this as a generalized EM algorithm that jointly optimizes semantic feature descriptors and statistical model parameters. The method prompts a frozen foundational model to classify items based on discovered features, treating these judgments as noisy observations of latent binary features that predict real-valued targets through learned statistical relationships. We demonstrate the approach on two domains: house price prediction (hedonic regression) and cold-start collaborative filtering for movie recommendations. On house prices, our model achieves 12\% median relative error using discovered semantic features from multimodal listing data, substantially outperforming a GPT-5 baseline (38\% error) that relies on the LLM's general domain knowledge. For Netflix movie embeddings, our model predicts collaborative filtering representations with 0.59 cosine similarity purely from semantic descriptions -- matching the performance that would require approximately 4000 user ratings through traditional collaborative filtering. The discovered features reveal dataset-specific patterns (e.g., architectural details predicting local housing markets, franchise membership predicting user preferences) that diverge from the model's domain knowledge alone.

</details>


### [18] [A study on constraint extraction and exception exclusion in care worker scheduling](https://arxiv.org/abs/2512.24853)
*Koki Suenaga,Tomohiro Furuta,Satoshi Ono*

Main category: cs.AI

TL;DR: 提出使用约束模板从养老机构管理者访谈中提取设施特定约束条件的方法，通过排除例外约束来优化排班生成


<details>
  <summary>Details</summary>
Motivation: 养老机构的排班条件因机构而异，需要通过与制定排班的管理者访谈来设计机构特定的约束条件，但现有约束提取技术缺乏处理例外约束的机制

Method: 使用约束模板提取各种组件的组合（如连续工作班次模式、员工组合等），模板可通过改变关注天数、员工数量和提取焦点（模式或频率）来提取多种约束，并包含排除例外约束的机制

Result: 实验表明，该方法成功创建了满足所有硬约束的排班，并通过避免提取例外约束减少了软约束违反次数

Conclusion: 提出的约束模板方法能够有效提取养老机构特定的排班约束，结合约束排除机制可生成更优的护理人员排班方案

Abstract: Technologies for automatically generating work schedules have been extensively studied; however, in long-term care facilities, the conditions vary between facilities, making it essential to interview the managers who create shift schedules to design facility-specific constraint conditions. The proposed method utilizes constraint templates to extract combinations of various components, such as shift patterns for consecutive days or staff combinations. The templates can extract a variety of constraints by changing the number of days and the number of staff members to focus on and changing the extraction focus to patterns or frequency. In addition, unlike existing constraint extraction techniques, this study incorporates mechanisms to exclude exceptional constraints. The extracted constraints can be employed by a constraint programming solver to create care worker schedules. Experiments demonstrated that our proposed method successfully created schedules that satisfied all hard constraints and reduced the number of violations for soft constraints by circumventing the extraction of exceptional constraints.

</details>


### [19] [Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem](https://arxiv.org/abs/2512.24873)
*Weixun Wang,XiaoXiao Xu,Wanhe An,Fangwen Dai,Wei Gao,Yancheng He,Ju Huang,Qiang Ji,Hanqi Jin,Xiaoyang Li,Yang Li,Zhongwen Li,Shirong Lin,Jiashun Liu,Zenan Liu,Tao Luo,Dilxat Muhtar,Yuanbin Qu,Jiaqiang Shi,Qinghui Sun,Yingshui Tan,Hao Tang,Runze Wang,Yi Wang,Zhaoguo Wang,Yanan Wu,Shaopan Xiong,Binchen Xu,Xander Xu,Yuchi Xu,Qipeng Zhang,Xixia Zhang,Haizhou Zhao,Jie Zhao,Shuaibing Zhao,Baihui Zheng,Jianhui Zheng,Suhang Zheng,Yanni Zhu,Mengze Cai,Kerui Cao,Xitong Chen,Yue Dai,Lifan Du,Tao Feng,Tao He,Jin Hu,Yijie Hu,Ziyu Jiang,Cheng Li,Xiang Li,Jing Liang,Chonghuan Liu,ZhenDong Liu,Haodong Mi,Yanhu Mo,Junjia Ni,Shixin Pei,Jingyu Shen,XiaoShuai Song,Cecilia Wang,Chaofan Wang,Kangyu Wang,Pei Wang,Tao Wang,Wei Wang,Ke Xiao,Mingyu Xu,Tiange Xu,Nan Ya,Siran Yang,Jianan Ye,Yaxing Zang,Duo Zhang,Junbo Zhang,Boren Zheng,Wanxi Deng,Ling Pan,Lin Qu,Wenbo Su,Jiamang Wang,Wei Wang,Hu Wei,Minggang Wu,Cheng Yu,Bing Zhao,Zhicheng Zheng,Bo Zheng*

Main category: cs.AI

TL;DR: ALE是一个端到端的智能体开发生态系统，包含ROLL权重优化框架、ROCK沙盒环境管理和iFlow CLI上下文工程工具。基于ALE训练的ROME智能体在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开源社区缺乏系统化的智能体开发基础设施，无法有效支持多轮次、实时环境操作的智能体训练和部署。

Method: 提出ALE生态系统，包含三个组件：ROLL用于权重优化，ROCK用于轨迹生成环境管理，iFlow CLI用于上下文工程。开发了ROME智能体，采用数据组合协议合成复杂行为，并提出IPA算法进行语义交互块级别的策略优化。

Result: ROME智能体在SWE-bench Verified和Terminal Bench等基准测试中表现出色，证明了ALE基础设施的有效性。同时发布了改进的Terminal Bench Pro基准。

Conclusion: ALE提供了一个系统化的智能体开发基础设施，能够有效支持复杂、多轮次的智能体训练和部署，ROME的成功验证了该框架的实用价值。

Abstract: Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce the Agentic Learning Ecosystem (ALE), a foundational infrastructure that optimizes the production pipeline for agent LLMs. ALE consists of three components: ROLL, a post-training framework for weight optimization; ROCK, a sandbox environment manager for trajectory generation; and iFlow CLI, an agent framework for efficient context engineering. We release ROME (ROME is Obviously an Agentic Model), an open-source agent grounded by ALE and trained on over one million trajectories. Our approach includes data composition protocols for synthesizing complex behaviors and a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks rather than individual tokens to improve long-horizon training stability. Empirically, we evaluate ROME within a structured setting and introduce Terminal Bench Pro, a benchmark with improved scale and contamination control. ROME demonstrates strong performance across benchmarks like SWE-bench Verified and Terminal Bench, proving the effectiveness of the ALE infrastructure.

</details>


### [20] [Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing](https://arxiv.org/abs/2512.24896)
*Andrii Gamalii,Daniel Górniak,Robert Nowak,Bartłomiej Olber,Krystian Radlak,Jakub Winter*

Main category: cs.AI

TL;DR: 开发了一个半自动数据标注流水线，用于在波兰驾驶条件下创建大规模多模态数据集，通过人机协同方法显著减少标注成本和时间。


<details>
  <summary>Details</summary>
Motivation: DARTS项目需要创建波兰驾驶条件的大规模多模态数据集，但手动标注异构数据成本高、耗时长，需要更高效的解决方案。

Method: 采用人机协同方法，结合人工智能与人类专业知识，系统自动生成初始标注，支持迭代模型重训练，包含数据匿名化和领域适应技术，核心基于3D目标检测算法。

Result: 开发的工具和方法实现了显著的时间节省，同时确保跨不同传感器模态的一致高质量标注，直接支持DARTS项目加速准备大规模标注数据集。

Conclusion: 该半自动标注流水线有效解决了大规模驾驶数据集标注的效率和成本问题，为波兰自动驾驶研究提供了技术基础，通过人机协同方法实现了高质量标注的规模化生产。

Abstract: This report presents the design and implementation of a semi-automated data annotation pipeline developed within the DARTS project, whose goal is to create a large-scale, multimodal dataset of driving scenarios recorded in Polish conditions. Manual annotation of such heterogeneous data is both costly and time-consuming. To address this challenge, the proposed solution adopts a human-in-the-loop approach that combines artificial intelligence with human expertise to reduce annotation cost and duration. The system automatically generates initial annotations, enables iterative model retraining, and incorporates data anonymization and domain adaptation techniques. At its core, the tool relies on 3D object detection algorithms to produce preliminary annotations. Overall, the developed tools and methodology result in substantial time savings while ensuring consistent, high-quality annotations across different sensor modalities. The solution directly supports the DARTS project by accelerating the preparation of large annotated dataset in the project's standardized format, strengthening the technological base for autonomous vehicle research in Poland.

</details>


### [21] [Iterative Deployment Improves Planning Skills in LLMs](https://arxiv.org/abs/2512.24940)
*Augusto B. Corrêa,Yoav Gelberg,Luckeciano C. Melo,Ilia Shumailov,André G. Pereira,Yarin Gal*

Main category: cs.AI

TL;DR: 迭代部署LLM并通过用户数据筛选进行微调，可以显著改变模型特性，在规划任务中实现性能提升和泛化能力，这本质上是一种隐式强化学习机制。


<details>
  <summary>Details</summary>
Motivation: 研究迭代部署大型语言模型时，用户从先前模型部署中精心筛选数据来微调后续模型，这种机制如何影响模型特性的变化。

Method: 在多个规划领域测试迭代部署机制：每个新模型基于用户从前一模型部署中精心筛选的数据进行微调，观察模型规划能力的变化。

Result: 观察到规划技能显著提升，后续模型展现出涌现的泛化能力，能够发现比初始模型长得多的规划方案。

Conclusion: 迭代部署本质上实现了外层循环的强化学习训练，具有隐式奖励函数。这对AI安全有重要启示（奖励函数未明确定义），同时提供了一种基于数据筛选而非显式奖励的替代训练机制。

Abstract: We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.

</details>


### [22] [AMAP Agentic Planning Technical Report](https://arxiv.org/abs/2512.24957)
*Yulan Hu,Xiangwen Zhang,Sheng Ouyang,Hao Yi,Lu Xu,Qinglin Lang,Lide Tan,Xiang Cheng,Tianchen Ye,Zhicong Li,Ge Chen,Wenjin Yang,Zheng Pan,Shaopan Xiong,Siran Yang,Ju Huang,Yan Zhang,Jiamang Wang,Yong Liu,Yinfeng Huang,Tucheng Lin,Xin Li,Ning Guo*

Main category: cs.AI

TL;DR: STAgent是一个专门用于时空理解的智能体大语言模型，通过工具交互解决复杂时空任务，同时保持通用能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂的时空任务，如受限兴趣点发现和行程规划，需要专门设计的智能体模型，能够在时空场景中与多种工具交互，同时不损失通用能力。

Method: 采用三个关键贡献：1）支持10+领域特定工具的稳定工具环境；2）分层数据筛选框架，以1:10,000的比例筛选高质量查询；3）级联训练方法，包括种子SFT阶段、高确定性查询的SFT阶段和低确定性数据的RL阶段。

Result: STAgent在TravelBench上表现出色，同时在广泛的通用基准测试中保持了通用能力，证明了所提出的智能体模型的有效性。

Conclusion: STAgent通过专门的工具环境、高质量数据筛选和级联训练方法，成功创建了一个既能处理复杂时空任务又能保持通用能力的智能体大语言模型。

Abstract: We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.

</details>
